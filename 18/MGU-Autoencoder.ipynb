{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "J_Y9UFYhKbuE"
   },
   "outputs": [],
   "source": [
    "# For plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "# For conversion\n",
    "from skimage.color import lab2rgb, rgb2lab, rgb2gray\n",
    "from skimage import io\n",
    "# For everything\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# For our model\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torchmetrics import MeanSquaredError, PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
    "from PIL import Image\n",
    "# For utilities\n",
    "import os, shutil, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3345d0b121945c98\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3345d0b121945c98\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab i kaggle jeszcze nie testowane\n",
    "colab = False\n",
    "kaggle = False\n",
    "test_number = '12_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_imgs = 'outputs/color/'\n",
    "gray_imgs = 'outputs/gray/'\n",
    "checkpoints = 'checkpoints'\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    dataset = '/content/drive/MyDrive/MGU/cifar10/'\n",
    "    \n",
    "    color_imgs = f'/content/drive/MyDrive/MGU/{test_number}/{color_imgs}'\n",
    "    gray_imgs = f'/content/drive/MyDrive/MGU/{test_number}/{gray_imgs}'\n",
    "    checkpoints = f'/content/drive/MyDrive/MGU/{test_number}/{checkpoints}'\n",
    "elif kaggle:\n",
    "    dataset = '/kaggle/input/cifar10/'\n",
    "    \n",
    "    color_imgs = f'{test_number}/{color_imgs}'\n",
    "    gray_imgs = f'{test_number}/{gray_imgs}'\n",
    "    checkpoints = f'{test_number}/{checkpoints}'\n",
    "else:\n",
    "    dataset = '../../datasets/cifar10/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ckNmKA5VwSh1"
   },
   "outputs": [],
   "source": [
    "# Make folders and set parameters\n",
    "os.makedirs(color_imgs, exist_ok=True)\n",
    "os.makedirs(gray_imgs, exist_ok=True)\n",
    "os.makedirs(checkpoints, exist_ok=True)\n",
    "save_images = True\n",
    "best_losses = [1e10, 1e10, 1e10]\n",
    "best_epoch = -1\n",
    "patience = 50\n",
    "epochs = 500\n",
    "batch_size = 128\n",
    "SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gMolrzKA_1uJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print(use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "05NviQfzU2Mv"
   },
   "outputs": [],
   "source": [
    "class LabImageFolder(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths, split='train'):\n",
    "        if split == 'train':\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.Resize((SIZE, SIZE), transforms.InterpolationMode.BICUBIC),\n",
    "                transforms.RandomCrop(SIZE),\n",
    "                transforms.RandomHorizontalFlip(),  \n",
    "            ])\n",
    "        elif split == 'val':\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.Resize((SIZE, SIZE), transforms.InterpolationMode.BICUBIC), \n",
    "                transforms.RandomCrop(SIZE), \n",
    "            ])\n",
    "            \n",
    "        self.split = split\n",
    "        self.size = SIZE\n",
    "        self.paths = [os.path.join(paths, file) for file in os.listdir(paths) if os.path.isfile(\n",
    "            os.path.join(paths, file))]\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.paths[index]).convert(\"RGB\")\n",
    "        img_original = self.transforms(img)\n",
    "        img_original = np.asarray(img_original)\n",
    "        img_lab = rgb2lab(img_original)\n",
    "        img_lab = (img_lab + 128) / 255\n",
    "        img_ab = img_lab[:, :, 1:3]\n",
    "        img_ab = torch.from_numpy(img_ab.transpose((2, 0, 1))).float()\n",
    "        img_gray = rgb2gray(img_original)\n",
    "        img_gray = torch.from_numpy(img_gray).unsqueeze(0).float()\n",
    "        return img_gray, img_ab\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "train_imagefolder = LabImageFolder(dataset + 'train')\n",
    "train_loader = torch.utils.data.DataLoader(train_imagefolder, batch_size=batch_size, shuffle=True)\n",
    "# Validation \n",
    "val_imagefolder = LabImageFolder(dataset + 'val' , 'val')\n",
    "val_loader = torch.utils.data.DataLoader(val_imagefolder, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NOQfP1feNkfS"
   },
   "outputs": [],
   "source": [
    "kernel_size=3\n",
    "stride_en=1\n",
    "stride_de=1\n",
    "padding=1\n",
    "scale_factor=2\n",
    "padding_mode='zeros'\n",
    "channels_base = 128\n",
    "p1 = .5\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, channels_base, kernel_size=kernel_size, stride=stride_en, padding=padding, padding_mode=padding_mode)\n",
    "        self.conv2 = nn.Conv2d(channels_base, channels_base * 2, kernel_size=kernel_size, stride=stride_en, padding=padding, padding_mode=padding_mode)\n",
    "\n",
    "        self.convtrans1 = nn.ConvTranspose2d(channels_base * 2, channels_base, kernel_size=kernel_size, stride=stride_de, padding=padding, padding_mode=padding_mode)\n",
    "        self.convtrans2 = nn.ConvTranspose2d(channels_base, channels_base // 2, kernel_size=kernel_size, stride=stride_de, padding=padding, padding_mode=padding_mode)\n",
    "        self.convtrans3 = nn.ConvTranspose2d(channels_base // 2, 2, kernel_size=kernel_size, stride=stride_de, padding=padding, padding_mode=padding_mode)\n",
    "\n",
    "        self.batchnorm1 = nn.BatchNorm2d(channels_base)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(channels_base * 2)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(channels_base)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(channels_base // 2)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # encoder\n",
    "        x = F.leaky_relu(self.batchnorm1(self.conv1(input)), negative_slope=0.1)\n",
    "        x = F.dropout(x, p=p1)\n",
    "        x = F.avg_pool2d(x, kernel_size=3, stride=2, padding=1)\n",
    "        x = F.leaky_relu(self.batchnorm2(self.conv2(x)), negative_slope=0.1)\n",
    "        x = F.dropout(x, p=p1)\n",
    "        x = F.avg_pool2d(x, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # decoder\n",
    "        x = F.leaky_relu(self.batchnorm3(self.convtrans1(x)), negative_slope=0.1)\n",
    "        x = F.dropout(x, p=p1)\n",
    "        x = F.interpolate(x, scale_factor=scale_factor)\n",
    "        x = F.leaky_relu(self.batchnorm4(self.convtrans2(x)), negative_slope=0.1)\n",
    "        x = F.dropout(x, p=p1)\n",
    "        x = F.interpolate(self.convtrans3(x), scale_factor=scale_factor)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OtRkAkIjTeq1"
   },
   "outputs": [],
   "source": [
    "model = Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = [MeanSquaredError(), PeakSignalNoiseRatio(data_range=1.0), StructuralSimilarityIndexMeasure(data_range=1.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "j3YZ3977TTl4"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "eeHK3BUtANrw"
   },
   "outputs": [],
   "source": [
    "# # Move model and loss function to GPU\n",
    "if use_gpu: \n",
    "    criterion = [criterion[0].to(\"cuda\"), criterion[1].to(\"cuda\"), criterion[2].to(\"cuda\")]\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 128, 32, 32]           1,280\n",
      "       BatchNorm2d-2          [-1, 128, 32, 32]             256\n",
      "            Conv2d-3          [-1, 256, 16, 16]         295,168\n",
      "       BatchNorm2d-4          [-1, 256, 16, 16]             512\n",
      "   ConvTranspose2d-5            [-1, 128, 8, 8]         295,040\n",
      "       BatchNorm2d-6            [-1, 128, 8, 8]             256\n",
      "   ConvTranspose2d-7           [-1, 64, 16, 16]          73,792\n",
      "       BatchNorm2d-8           [-1, 64, 16, 16]             128\n",
      "   ConvTranspose2d-9            [-1, 2, 16, 16]           1,154\n",
      "================================================================\n",
      "Total params: 667,586\n",
      "Trainable params: 667,586\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.38\n",
      "Params size (MB): 2.55\n",
      "Estimated Total Size (MB): 5.93\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if use_gpu: \n",
    "    from torchsummary import summary\n",
    "    summary(model, (1, SIZE, SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2FDRt12jsIkr"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    '''A handy class from the PyTorch ImageNet tutorial''' \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def to_rgb(grayscale_input, ab_input, save_path=None, save_name=None):\n",
    "    '''Show/save rgb image from grayscale and ab channels\n",
    "       Input save_path in the form {'grayscale': '/path/', 'colorized': '/path/'}'''\n",
    "    plt.clf() # clear matplotlib \n",
    "    color_image = torch.cat((grayscale_input, ab_input), 0).numpy() # combine channels\n",
    "    color_image = color_image.transpose((1, 2, 0))  # rescale for matplotlib\n",
    "    color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100\n",
    "    color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128   \n",
    "    color_image = lab2rgb(color_image.astype(np.float64))\n",
    "    grayscale_input = grayscale_input.squeeze().numpy()\n",
    "    if save_path is not None and save_name is not None: \n",
    "        plt.imsave(arr=grayscale_input, fname='{}{}'.format(save_path['grayscale'], save_name), cmap='gray')\n",
    "        plt.imsave(arr=color_image, fname='{}{}'.format(save_path['colorized'], save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "M_OTbyOcrh9J"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, save_images, epoch):\n",
    "    _loss = [AverageMeter(), AverageMeter(), AverageMeter()]\n",
    "\n",
    "    model.eval()\n",
    "    already_saved_images = False\n",
    "    for gray, ab in val_loader:\n",
    "        if use_gpu: \n",
    "            gray, ab = gray.cuda(), ab.cuda()\n",
    "\n",
    "        # Run model and record loss\n",
    "        output_ab = model(gray) # throw away class predictions\n",
    "        loss = [criterion[0](output_ab, ab), criterion[1](output_ab, ab), criterion[2](output_ab, ab)]\n",
    "        \n",
    "        _loss[0].update(loss[0].item(), gray.size(0))\n",
    "        _loss[1].update(loss[1].item(), gray.size(0))\n",
    "        _loss[2].update(loss[2].item(), gray.size(0))\n",
    "\n",
    "        # Save images to file\n",
    "        if save_images and not already_saved_images:\n",
    "            already_saved_images = True\n",
    "            for j in range(min(len(output_ab), 10)): # save at most 5 images\n",
    "                save_path = {'grayscale': gray_imgs, 'colorized': color_imgs}\n",
    "                save_name = 'img-{}-epoch-{}.jpg'.format(j, epoch)\n",
    "                to_rgb(gray[j].cpu(), ab_input=output_ab[j].detach().cpu(), save_path=save_path, save_name=save_name)\n",
    "\n",
    "    print(f'Validate: MSE {_loss[0].val:.8f} ({_loss[0].avg:.8f}), PSNR {_loss[1].val:.8f} ({_loss[1].avg:.8f}), SSIM {_loss[2].val:.8f} ({_loss[2].avg:.8f})')\n",
    "\n",
    "    print('Finished validation.')\n",
    "    if epoch >= 0:\n",
    "        writer.add_scalar(\"MSE/test\", _loss[0].avg, epoch)\n",
    "        writer.add_scalar(\"PSNR/test\", _loss[1].avg, epoch)\n",
    "        writer.add_scalar(\"SSIM/test\", _loss[2].avg, epoch)\n",
    "    return _loss[0].avg, _loss[1].avg, _loss[2].avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "FOo__iEnvLMB"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    print(f'Starting training epoch {epoch}')\n",
    "    _loss = [AverageMeter(), AverageMeter(), AverageMeter()]\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for gray, ab in train_loader:\n",
    "        if use_gpu: \n",
    "            gray, ab = gray.cuda(), ab.cuda()\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_ab = model(gray) \n",
    "        loss = [criterion[0](output_ab, ab), criterion[1](output_ab, ab), criterion[2](output_ab, ab)]\n",
    "        \n",
    "        loss[0].backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _loss[0].update(loss[0].item(), gray.size(0))\n",
    "        _loss[1].update(loss[1].item(), gray.size(0))\n",
    "        _loss[2].update(loss[2].item(), gray.size(0))\n",
    "        \n",
    "    print(f'Epoch: {epoch}, MSE {_loss[0].val:.8f} ({_loss[0].avg:.8f}), PSNR {_loss[1].val:.8f} ({_loss[1].avg:.8f}), SSIM {_loss[2].val:.8f} ({_loss[2].avg:.8f})')\n",
    "\n",
    "    print(f'Finished training epoch {epoch}')\n",
    "    if epoch >= 0:\n",
    "        writer.add_scalar(\"MSE/train\", _loss[0].avg, epoch)\n",
    "        writer.add_scalar(\"PSNR/train\", _loss[1].avg, epoch)\n",
    "        writer.add_scalar(\"SSIM/train\", _loss[2].avg, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "id": "XUR6ALi3AZoO",
    "outputId": "4b274c7b-fc1d-4e14-dc1f-a7ef93f3663f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training epoch 0\n",
      "Epoch: 0, MSE 0.02916720 (0.38829882), PSNR 15.35105133 (10.59457897), SSIM 0.20734680 (0.08966022)\n",
      "Finished training epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konrad/.local/lib/python3.10/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 11 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/konrad/.local/lib/python3.10/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 168 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/konrad/.local/lib/python3.10/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 30 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/konrad/.local/lib/python3.10/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 129 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/konrad/.local/lib/python3.10/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 3 pixels\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: MSE 0.02092643 (0.02644649), PSNR 16.79304886 (16.19417045), SSIM 0.20732050 (0.23772692)\n",
      "Finished validation.\n",
      "Starting training epoch 1\n",
      "Epoch: 1, MSE 0.01262744 (0.01908631), PSNR 18.98684692 (17.31953516), SSIM 0.44489661 (0.36887943)\n",
      "Finished training epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konrad/.local/lib/python3.10/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 4 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/konrad/.local/lib/python3.10/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 69 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/konrad/.local/lib/python3.10/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 64 pixels\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: MSE 0.01156333 (0.01340942), PSNR 19.36917114 (19.15479425), SSIM 0.39115527 (0.47178007)\n",
      "Finished validation.\n",
      "Starting training epoch 2\n",
      "Epoch: 2, MSE 0.00666875 (0.00927439), PSNR 21.75955391 (20.39528914), SSIM 0.57224143 (0.53197104)\n",
      "Finished training epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konrad/.local/lib/python3.10/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 17 pixels\n",
      "  return func(*args, **kwargs)\n",
      "/home/konrad/.local/lib/python3.10/site-packages/skimage/_shared/utils.py:394: UserWarning: Color data out of range: Z < 0 in 8 pixels\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: MSE 0.00614754 (0.00678292), PSNR 22.11298180 (21.95434063), SSIM 0.50415671 (0.58415780)\n",
      "Finished validation.\n",
      "Starting training epoch 3\n",
      "Epoch: 3, MSE 0.00484345 (0.00556961), PSNR 23.14845276 (22.57599741), SSIM 0.63046855 (0.60796991)\n",
      "Finished training epoch 3\n",
      "Validate: MSE 0.00474490 (0.00458517), PSNR 23.23772621 (23.54005370), SSIM 0.55923456 (0.63643679)\n",
      "Finished validation.\n",
      "Starting training epoch 4\n",
      "Epoch: 4, MSE 0.00447742 (0.00400242), PSNR 23.48972130 (23.99835506), SSIM 0.65504521 (0.65327613)\n",
      "Finished training epoch 4\n",
      "Validate: MSE 0.00399562 (0.00361373), PSNR 23.98415184 (24.51925462), SSIM 0.59514278 (0.66987835)\n",
      "Finished validation.\n",
      "Starting training epoch 5\n",
      "Epoch: 5, MSE 0.00306398 (0.00330274), PSNR 25.13714409 (24.82894593), SSIM 0.70654970 (0.68654506)\n",
      "Finished training epoch 5\n",
      "Validate: MSE 0.00329992 (0.00309517), PSNR 24.81497002 (25.17464638), SSIM 0.63795096 (0.70105374)\n",
      "Finished validation.\n",
      "Starting training epoch 6\n",
      "Epoch: 6, MSE 0.00213688 (0.00298780), PSNR 26.70220566 (25.26493819), SSIM 0.75025231 (0.71250951)\n",
      "Finished training epoch 6\n",
      "Validate: MSE 0.00335406 (0.00292033), PSNR 24.74429131 (25.41194760), SSIM 0.65790927 (0.72460584)\n",
      "Finished validation.\n",
      "Starting training epoch 7\n",
      "Epoch: 7, MSE 0.00294297 (0.00284802), PSNR 25.31213570 (25.47463674), SSIM 0.72718656 (0.73223630)\n",
      "Finished training epoch 7\n",
      "Validate: MSE 0.00313284 (0.00280256), PSNR 25.04061699 (25.60213369), SSIM 0.67637914 (0.74083760)\n",
      "Finished validation.\n",
      "Starting training epoch 8\n",
      "Epoch: 8, MSE 0.00267599 (0.00278310), PSNR 25.72515488 (25.57905471), SSIM 0.73959601 (0.74598285)\n",
      "Finished training epoch 8\n",
      "Validate: MSE 0.00312637 (0.00274256), PSNR 25.04960060 (25.69517045), SSIM 0.68713439 (0.75210679)\n",
      "Finished validation.\n",
      "Starting training epoch 9\n",
      "Epoch: 9, MSE 0.00270811 (0.00275201), PSNR 25.67333984 (25.62574141), SSIM 0.76314157 (0.75494597)\n",
      "Finished training epoch 9\n",
      "Validate: MSE 0.00307853 (0.00271377), PSNR 25.11656570 (25.74011075), SSIM 0.69236976 (0.75922281)\n",
      "Finished validation.\n",
      "Starting training epoch 10\n",
      "Epoch: 10, MSE 0.00251906 (0.00272914), PSNR 25.98761940 (25.66014259), SSIM 0.77442527 (0.76003756)\n",
      "Finished training epoch 10\n",
      "Validate: MSE 0.00305435 (0.00268410), PSNR 25.15081024 (25.78589286), SSIM 0.69482070 (0.76362416)\n",
      "Finished validation.\n",
      "Starting training epoch 11\n",
      "Epoch: 11, MSE 0.00274005 (0.00273042), PSNR 25.62242126 (25.65805809), SSIM 0.76289392 (0.76150527)\n",
      "Finished training epoch 11\n",
      "Validate: MSE 0.00315278 (0.00273287), PSNR 25.01305580 (25.69851969), SSIM 0.69653249 (0.76144022)\n",
      "Finished validation.\n",
      "Starting training epoch 12\n",
      "Epoch: 12, MSE 0.00249892 (0.00267416), PSNR 26.02247238 (25.75101669), SSIM 0.75416362 (0.76331420)\n",
      "Finished training epoch 12\n",
      "Validate: MSE 0.00302305 (0.00264065), PSNR 25.19554710 (25.86104015), SSIM 0.70024729 (0.76659529)\n",
      "Finished validation.\n",
      "Starting training epoch 13\n",
      "Epoch: 13, MSE 0.00322548 (0.00264974), PSNR 24.91405869 (25.78817943), SSIM 0.74593604 (0.76372056)\n",
      "Finished training epoch 13\n",
      "Validate: MSE 0.00302597 (0.00264227), PSNR 25.19135094 (25.85973329), SSIM 0.70232236 (0.76899498)\n",
      "Finished validation.\n",
      "Starting training epoch 14\n",
      "Epoch: 14, MSE 0.00306666 (0.00262857), PSNR 25.13334274 (25.82380838), SSIM 0.75392789 (0.76418780)\n",
      "Finished training epoch 14\n",
      "Validate: MSE 0.00316358 (0.00264399), PSNR 24.99820518 (25.84534991), SSIM 0.69491160 (0.76604198)\n",
      "Finished validation.\n",
      "Starting training epoch 15\n",
      "Epoch: 15, MSE 0.00230796 (0.00262449), PSNR 26.36772156 (25.83341189), SSIM 0.79836386 (0.76411261)\n",
      "Finished training epoch 15\n",
      "Validate: MSE 0.00294736 (0.00262042), PSNR 25.30567360 (25.88598915), SSIM 0.70272774 (0.76725799)\n",
      "Finished validation.\n",
      "Starting training epoch 16\n",
      "Epoch: 16, MSE 0.00263442 (0.00261242), PSNR 25.79314804 (25.85217996), SSIM 0.77340925 (0.76469231)\n",
      "Finished training epoch 16\n",
      "Validate: MSE 0.00289877 (0.00264831), PSNR 25.37786293 (25.85693127), SSIM 0.70405734 (0.77150270)\n",
      "Finished validation.\n",
      "Starting training epoch 17\n",
      "Epoch: 17, MSE 0.00220005 (0.00259224), PSNR 26.57567978 (25.88409982), SSIM 0.76512772 (0.76515084)\n",
      "Finished training epoch 17\n",
      "Validate: MSE 0.00283257 (0.00260436), PSNR 25.47819710 (25.91722063), SSIM 0.70444447 (0.76795162)\n",
      "Finished validation.\n",
      "Starting training epoch 18\n",
      "Epoch: 18, MSE 0.00257455 (0.00260422), PSNR 25.89298820 (25.86789321), SSIM 0.75251400 (0.76520213)\n",
      "Finished training epoch 18\n",
      "Validate: MSE 0.00286527 (0.00271127), PSNR 25.42834854 (25.76421907), SSIM 0.70186549 (0.76711205)\n",
      "Finished validation.\n",
      "Starting training epoch 19\n",
      "Epoch: 19, MSE 0.00278396 (0.00258365), PSNR 25.55336761 (25.90162412), SSIM 0.76915145 (0.76546141)\n",
      "Finished training epoch 19\n",
      "Validate: MSE 0.00309597 (0.00263641), PSNR 25.09202766 (25.85646160), SSIM 0.70261896 (0.76467058)\n",
      "Finished validation.\n",
      "Starting training epoch 20\n",
      "Epoch: 20, MSE 0.00204043 (0.00257582), PSNR 26.90278435 (25.91327424), SSIM 0.78222513 (0.76609580)\n",
      "Finished training epoch 20\n",
      "Validate: MSE 0.00282973 (0.00268376), PSNR 25.48255157 (25.80733314), SSIM 0.70262337 (0.76617494)\n",
      "Finished validation.\n",
      "Starting training epoch 21\n",
      "Epoch: 21, MSE 0.00231404 (0.00256552), PSNR 26.35629463 (25.93024617), SSIM 0.77396190 (0.76655783)\n",
      "Finished training epoch 21\n",
      "Validate: MSE 0.00297613 (0.00280301), PSNR 25.26348305 (25.59357406), SSIM 0.69378769 (0.74843392)\n",
      "Finished validation.\n",
      "Starting training epoch 22\n",
      "Epoch: 22, MSE 0.00244206 (0.00254715), PSNR 26.12244034 (25.96555894), SSIM 0.76004618 (0.76663617)\n",
      "Finished training epoch 22\n",
      "Validate: MSE 0.00294374 (0.00280974), PSNR 25.31099892 (25.61351645), SSIM 0.70034540 (0.76553497)\n",
      "Finished validation.\n",
      "Starting training epoch 23\n",
      "Epoch: 23, MSE 0.00221767 (0.00253514), PSNR 26.54102325 (25.98338975), SSIM 0.78141272 (0.76728567)\n",
      "Finished training epoch 23\n",
      "Validate: MSE 0.00308945 (0.00280949), PSNR 25.10118484 (25.59754959), SSIM 0.69713831 (0.76710540)\n",
      "Finished validation.\n",
      "Starting training epoch 24\n",
      "Epoch: 24, MSE 0.00263187 (0.00251994), PSNR 25.79736328 (26.00682921), SSIM 0.76507986 (0.76811766)\n",
      "Finished training epoch 24\n",
      "Validate: MSE 0.00346089 (0.00322705), PSNR 24.60811806 (25.00391520), SSIM 0.69044912 (0.75463704)\n",
      "Finished validation.\n",
      "Starting training epoch 25\n",
      "Epoch: 25, MSE 0.00244113 (0.00249881), PSNR 26.12409401 (26.04412430), SSIM 0.76474631 (0.76917829)\n",
      "Finished training epoch 25\n",
      "Validate: MSE 0.00300505 (0.00280318), PSNR 25.22147560 (25.62737577), SSIM 0.69660723 (0.76566719)\n",
      "Finished validation.\n",
      "Starting training epoch 26\n",
      "Epoch: 26, MSE 0.00247264 (0.00248908), PSNR 26.06839752 (26.06066237), SSIM 0.77078688 (0.76964148)\n",
      "Finished training epoch 26\n",
      "Validate: MSE 0.00316243 (0.00266327), PSNR 24.99978447 (25.82622617), SSIM 0.70247674 (0.77098791)\n",
      "Finished validation.\n",
      "Starting training epoch 27\n",
      "Epoch: 27, MSE 0.00242067 (0.00248338), PSNR 26.16064262 (26.07119367), SSIM 0.75697458 (0.77047773)\n",
      "Finished training epoch 27\n",
      "Validate: MSE 0.00278421 (0.00250391), PSNR 25.55297852 (26.08032065), SSIM 0.70299578 (0.76929891)\n",
      "Finished validation.\n",
      "Starting training epoch 28\n",
      "Epoch: 28, MSE 0.00255677 (0.00247526), PSNR 25.92307281 (26.08744100), SSIM 0.76444805 (0.77083295)\n",
      "Finished training epoch 28\n",
      "Validate: MSE 0.00301172 (0.00263013), PSNR 25.21185112 (25.87230341), SSIM 0.70341426 (0.76976360)\n",
      "Finished validation.\n",
      "Starting training epoch 29\n",
      "Epoch: 29, MSE 0.00246459 (0.00246167), PSNR 26.08254433 (26.11138035), SSIM 0.75324792 (0.77132956)\n",
      "Finished training epoch 29\n",
      "Validate: MSE 0.00283553 (0.00265411), PSNR 25.47365761 (25.85719701), SSIM 0.71063864 (0.77186380)\n",
      "Finished validation.\n",
      "Starting training epoch 30\n",
      "Epoch: 30, MSE 0.00221132 (0.00243444), PSNR 26.55348206 (26.15927355), SSIM 0.77307767 (0.77193746)\n",
      "Finished training epoch 30\n",
      "Validate: MSE 0.00268264 (0.00267683), PSNR 25.71437836 (25.82156122), SSIM 0.70245302 (0.76398720)\n",
      "Finished validation.\n",
      "Starting training epoch 31\n",
      "Epoch: 31, MSE 0.00217459 (0.00244102), PSNR 26.62621880 (26.14781269), SSIM 0.77721184 (0.77196610)\n",
      "Finished training epoch 31\n",
      "Validate: MSE 0.00278868 (0.00283447), PSNR 25.54600525 (25.61077046), SSIM 0.70761794 (0.76649727)\n",
      "Finished validation.\n",
      "Starting training epoch 32\n",
      "Epoch: 32, MSE 0.00260401 (0.00242958), PSNR 25.84357834 (26.16711965), SSIM 0.76637566 (0.77229859)\n",
      "Finished training epoch 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate: MSE 0.00297700 (0.00260771), PSNR 25.26221275 (25.91218177), SSIM 0.70430648 (0.77081634)\n",
      "Finished validation.\n",
      "Starting training epoch 33\n",
      "Epoch: 33, MSE 0.00272175 (0.00243364), PSNR 25.65152359 (26.16130111), SSIM 0.76764506 (0.77244201)\n",
      "Finished training epoch 33\n",
      "Validate: MSE 0.00308229 (0.00286820), PSNR 25.11126709 (25.51515532), SSIM 0.70424485 (0.76170672)\n",
      "Finished validation.\n",
      "Starting training epoch 34\n",
      "Epoch: 34, MSE 0.00281405 (0.00241529), PSNR 25.50668526 (26.19071497), SSIM 0.73059243 (0.77274635)\n",
      "Finished training epoch 34\n",
      "Validate: MSE 0.00271232 (0.00255030), PSNR 25.66658211 (26.00722002), SSIM 0.70348543 (0.76873732)\n",
      "Finished validation.\n",
      "Starting training epoch 35\n",
      "Epoch: 35, MSE 0.00269273 (0.00241346), PSNR 25.69807625 (26.19529246), SSIM 0.75661647 (0.77255770)\n",
      "Finished training epoch 35\n",
      "Validate: MSE 0.00299970 (0.00251316), PSNR 25.22921371 (26.06989108), SSIM 0.70633471 (0.77071860)\n",
      "Finished validation.\n",
      "Starting training epoch 36\n",
      "Epoch: 36, MSE 0.00272290 (0.00241702), PSNR 25.64968872 (26.18848691), SSIM 0.76086491 (0.77228544)\n",
      "Finished training epoch 36\n",
      "Validate: MSE 0.00277415 (0.00262407), PSNR 25.56869125 (25.89855961), SSIM 0.71031779 (0.76808495)\n",
      "Finished validation.\n",
      "Starting training epoch 37\n",
      "Epoch: 37, MSE 0.00214150 (0.00242307), PSNR 26.69282532 (26.17849534), SSIM 0.78694504 (0.77191399)\n",
      "Finished training epoch 37\n",
      "Validate: MSE 0.00275477 (0.00260761), PSNR 25.59915352 (25.92525108), SSIM 0.70405048 (0.76597028)\n",
      "Finished validation.\n",
      "Starting training epoch 38\n",
      "Epoch: 38, MSE 0.00219865 (0.00240609), PSNR 26.57843208 (26.20924982), SSIM 0.79516989 (0.77212720)\n",
      "Finished training epoch 38\n",
      "Validate: MSE 0.00266287 (0.00287600), PSNR 25.74650383 (25.54034187), SSIM 0.70574391 (0.76395432)\n",
      "Finished validation.\n",
      "Starting training epoch 39\n",
      "Epoch: 39, MSE 0.00251958 (0.00241353), PSNR 25.98672485 (26.19379548), SSIM 0.74817836 (0.77194533)\n",
      "Finished training epoch 39\n",
      "Validate: MSE 0.00265975 (0.00292666), PSNR 25.75159073 (25.48361036), SSIM 0.70935798 (0.76152407)\n",
      "Finished validation.\n",
      "Starting training epoch 40\n",
      "Epoch: 40, MSE 0.00201554 (0.00240578), PSNR 26.95608521 (26.21337978), SSIM 0.78367639 (0.77209281)\n",
      "Finished training epoch 40\n",
      "Validate: MSE 0.00274633 (0.00263653), PSNR 25.61247826 (25.88613868), SSIM 0.70229149 (0.76718680)\n",
      "Finished validation.\n",
      "Starting training epoch 41\n",
      "Epoch: 41, MSE 0.00249209 (0.00239912), PSNR 26.03436279 (26.22112085), SSIM 0.75800389 (0.77257603)\n",
      "Finished training epoch 41\n",
      "Validate: MSE 0.00290172 (0.00258761), PSNR 25.37344170 (25.94427671), SSIM 0.70316374 (0.76899877)\n",
      "Finished validation.\n",
      "Starting training epoch 42\n",
      "Epoch: 42, MSE 0.00233004 (0.00240798), PSNR 26.32636261 (26.20809824), SSIM 0.75751346 (0.77174031)\n",
      "Finished training epoch 42\n",
      "Validate: MSE 0.00285964 (0.00280474), PSNR 25.43688202 (25.59870277), SSIM 0.70111346 (0.75874881)\n",
      "Finished validation.\n",
      "Starting training epoch 43\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "for epoch in range(epochs):\n",
    "    # Train for one epoch, then validate\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "    with torch.no_grad():\n",
    "        losses = validate(val_loader, model, criterion, save_images, epoch)\n",
    "    # Save checkpoint and replace old best model if current model is better\n",
    "    if losses[0] < best_losses[0]:\n",
    "        best_losses[0] = losses[0]\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), f'{checkpoints}/epoch-{epoch}-MSELoss-{losses[0]:.8f}.pth')\n",
    "    if losses[1] < best_losses[1]:\n",
    "        best_losses[1] = losses[1]\n",
    "        torch.save(model.state_dict(), f'{checkpoints}/epoch-{epoch}-PSNRLoss-{losses[1]:.8f}.pth')\n",
    "    if losses[2] < best_losses[2]:\n",
    "        best_losses[2] = losses[2]\n",
    "        torch.save(model.state_dict(), f'{checkpoints}/epoch-{epoch}-SSIMLoss-{losses[2]:.8f}.pth')\n",
    "    \n",
    "    if epoch - best_epoch >= patience and epoch >= 100:\n",
    "        torch.save(model.state_dict(), f'{checkpoints}/epoch-{epoch}-MSELoss-{losses[0]:.8f}-early_stop.pth')\n",
    "        break\n",
    "    \n",
    "    if epoch == epochs - 1:\n",
    "        torch.save(model.state_dict(), f'{checkpoints}/epoch-{epoch}-last-{losses[0]:.8f}-{losses[1]:.8f}-{losses[2]:.8f}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'{checkpoints}/last-{losses[0]:.8f}-{losses[1]:.8f}-{losses[2]:.8f}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1593
    },
    "id": "UcovGnpHMl9D",
    "outputId": "90b7a2b4-dc03-4862-cf02-c7ddbbb7e500"
   },
   "outputs": [],
   "source": [
    "# Validate\n",
    "save_images = True\n",
    "with torch.no_grad():\n",
    "    validate(val_loader, model, criterion, save_images, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show images \n",
    "# image_pairs = []\n",
    "\n",
    "# for i in range(10):\n",
    "#     image_pairs.append((f'{color_imgs}img-{i}-epoch-{best_epoch}.jpg', f'{gray_imgs}img-{i}-epoch-{best_epoch}.jpg'))\n",
    "    \n",
    "# for c, g in image_pairs:\n",
    "#   color = mpimg.imread(c)\n",
    "#   gray  = mpimg.imread(g)\n",
    "#   f, axarr = plt.subplots(1, 2)\n",
    "#   f.set_size_inches(15, 15)\n",
    "#   axarr[0].imshow(gray, cmap='gray')\n",
    "#   axarr[1].imshow(color)\n",
    "#   axarr[0].axis('off'), axarr[1].axis('off')\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
