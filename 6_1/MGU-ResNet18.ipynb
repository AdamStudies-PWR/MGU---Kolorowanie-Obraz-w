{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_Y9UFYhKbuE"
   },
   "outputs": [],
   "source": [
    "# For plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "# For conversion\n",
    "from skimage.color import lab2rgb, rgb2lab, rgb2gray\n",
    "from skimage import io\n",
    "# For everything\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# For our model\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "# For utilities\n",
    "import os, shutil, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMolrzKA_1uJ"
   },
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print(use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05NviQfzU2Mv"
   },
   "outputs": [],
   "source": [
    "SIZE = 64\n",
    "class LabImageFolder(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths, split='train'):\n",
    "        if split == 'train':\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.Resize((SIZE, SIZE), transforms.InterpolationMode.BICUBIC),\n",
    "                transforms.RandomCrop(SIZE),\n",
    "                transforms.RandomHorizontalFlip(), \n",
    "            ])\n",
    "        elif split == 'val':\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.Resize((SIZE, SIZE), transforms.InterpolationMode.BICUBIC), \n",
    "                transforms.RandomCrop(SIZE),\n",
    "            ])\n",
    "            \n",
    "        self.split = split\n",
    "        self.size = SIZE\n",
    "        self.paths = [os.path.join(paths, file) for file in os.listdir(paths) if os.path.isfile(\n",
    "            os.path.join(paths, file))]\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.paths[index]).convert(\"RGB\")\n",
    "        img_original = self.transforms(img)\n",
    "        img_original = np.asarray(img_original)\n",
    "        img_lab = rgb2lab(img_original)\n",
    "        img_lab = (img_lab + 128) / 255\n",
    "        img_ab = img_lab[:, :, 1:3]\n",
    "        img_ab = torch.from_numpy(img_ab.transpose((2, 0, 1))).float()\n",
    "        img_gray = rgb2gray(img_original)\n",
    "        img_gray = torch.from_numpy(img_gray).unsqueeze(0).float()\n",
    "        return img_gray, img_ab\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "batch_size = 128\n",
    "train_imagefolder = LabImageFolder('../../datasets/dataset/train/colour')\n",
    "train_loader = torch.utils.data.DataLoader(train_imagefolder, batch_size=batch_size, shuffle=True)\n",
    "# Validation \n",
    "val_imagefolder = LabImageFolder('../../datasets/dataset/test/colour' , 'val')\n",
    "val_loader = torch.utils.data.DataLoader(val_imagefolder, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOQfP1feNkfS"
   },
   "outputs": [],
   "source": [
    "kernel_size=3\n",
    "stride_en=1\n",
    "stride_de=1\n",
    "padding=1\n",
    "scale_factor=2\n",
    "padding_mode='zeros'\n",
    "class ColorizationNet(nn.Module):\n",
    "  def __init__(self, input_size=128):\n",
    "    super(ColorizationNet, self).__init__()\n",
    "\n",
    "    self.encoder = nn.Sequential(       \n",
    "      nn.Conv2d(1, 16, kernel_size=kernel_size, stride=stride_en, padding=padding, padding_mode=padding_mode),\n",
    "      nn.BatchNorm2d(16),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "      nn.Conv2d(16, 16, kernel_size=kernel_size, stride=stride_en, padding=padding, padding_mode=padding_mode),\n",
    "      nn.BatchNorm2d(16),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.Conv2d(16, 16, kernel_size=kernel_size, stride=stride_en, padding=padding, padding_mode=padding_mode),\n",
    "      nn.BatchNorm2d(16),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.Conv2d(16, 16, kernel_size=kernel_size, stride=stride_en, padding=padding, padding_mode=padding_mode),\n",
    "      nn.BatchNorm2d(16),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.Conv2d(16, 16, kernel_size=kernel_size, stride=stride_en, padding=padding, padding_mode=padding_mode),\n",
    "      nn.BatchNorm2d(16),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.Conv2d(16, 32, kernel_size=kernel_size, stride=stride_en, padding=padding, padding_mode=padding_mode),\n",
    "      nn.BatchNorm2d(32),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "      nn.Conv2d(32, 32, kernel_size=kernel_size, stride=stride_en, padding=padding, padding_mode=padding_mode),\n",
    "      nn.BatchNorm2d(32),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.Conv2d(32, 32, kernel_size=kernel_size, stride=stride_en, padding=padding, padding_mode=padding_mode),\n",
    "      nn.BatchNorm2d(32),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.Conv2d(32, 32, kernel_size=kernel_size, stride=stride_en, padding=padding, padding_mode=padding_mode),\n",
    "      nn.BatchNorm2d(32),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.Conv2d(32, 32, kernel_size=kernel_size, stride=stride_en, padding=padding, padding_mode=padding_mode),\n",
    "      nn.BatchNorm2d(32),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.Conv2d(32, 64, kernel_size=kernel_size, stride=stride_en, padding=padding, padding_mode=padding_mode),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "    )     \n",
    "        \n",
    "    self.decoder = nn.Sequential(  \n",
    "      nn.ConvTranspose2d(64, 64, kernel_size=kernel_size, stride=stride_de, padding=padding, padding_mode=padding_mode),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.ConvTranspose2d(64, 64, kernel_size=kernel_size, stride=stride_de, padding=padding, padding_mode=padding_mode),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.ConvTranspose2d(64, 64, kernel_size=kernel_size, stride=stride_de, padding=padding, padding_mode=padding_mode),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.ConvTranspose2d(64, 64, kernel_size=kernel_size, stride=stride_de, padding=padding, padding_mode=padding_mode),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.ConvTranspose2d(64, 32, kernel_size=kernel_size, stride=stride_de, padding=padding, padding_mode=padding_mode),\n",
    "      nn.BatchNorm2d(32),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.Upsample(scale_factor=scale_factor),   \n",
    "      nn.ConvTranspose2d(32, 16, kernel_size=kernel_size, stride=stride_de, padding=padding, padding_mode=padding_mode),\n",
    "      nn.BatchNorm2d(16),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.Upsample(scale_factor=scale_factor),\n",
    "      nn.ConvTranspose2d(16, 8, kernel_size=kernel_size, stride=stride_de, padding=padding, padding_mode=padding_mode),\n",
    "      nn.BatchNorm2d(8),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.ConvTranspose2d(8, 2, kernel_size=kernel_size, stride=stride_de, padding=padding, padding_mode=padding_mode),\n",
    "      nn.Upsample(scale_factor=scale_factor)\n",
    "    )\n",
    "\n",
    "  def forward(self, input):\n",
    "\n",
    "    encoder = self.encoder(input)\n",
    "    # Upsample to get colors\n",
    "    output = self.decoder(encoder)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OtRkAkIjTeq1"
   },
   "outputs": [],
   "source": [
    "model = ColorizationNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PU0wtkPRasL"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j3YZ3977TTl4"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eeHK3BUtANrw"
   },
   "outputs": [],
   "source": [
    "# # Move model and loss function to GPU\n",
    "if use_gpu: \n",
    "    criterion = criterion.cuda()\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if use_gpu: \n",
    "    from torchsummary import summary\n",
    "\n",
    "    summary(model, (1, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2FDRt12jsIkr"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "  '''A handy class from the PyTorch ImageNet tutorial''' \n",
    "  def __init__(self):\n",
    "    self.reset()\n",
    "  def reset(self):\n",
    "    self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
    "  def update(self, val, n=1):\n",
    "    self.val = val\n",
    "    self.sum += val * n\n",
    "    self.count += n\n",
    "    self.avg = self.sum / self.count\n",
    "\n",
    "def to_rgb(grayscale_input, ab_input, save_path=None, save_name=None):\n",
    "  '''Show/save rgb image from grayscale and ab channels\n",
    "     Input save_path in the form {'grayscale': '/path/', 'colorized': '/path/'}'''\n",
    "  plt.clf() # clear matplotlib \n",
    "  color_image = torch.cat((grayscale_input, ab_input), 0).numpy() # combine channels\n",
    "  color_image = color_image.transpose((1, 2, 0))  # rescale for matplotlib\n",
    "  color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100\n",
    "  color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128   \n",
    "  color_image = lab2rgb(color_image.astype(np.float64))\n",
    "  grayscale_input = grayscale_input.squeeze().numpy()\n",
    "  if save_path is not None and save_name is not None: \n",
    "    plt.imsave(arr=grayscale_input, fname='{}{}'.format(save_path['grayscale'], save_name), cmap='gray')\n",
    "    plt.imsave(arr=color_image, fname='{}{}'.format(save_path['colorized'], save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_imgs = 'outputs/color/'\n",
    "gray_imgs = 'outputs/gray/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_OTbyOcrh9J"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, save_images, epoch):\n",
    "    _loss = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "    already_saved_images = False\n",
    "    for gray, ab in val_loader:\n",
    "        if use_gpu: \n",
    "            gray, ab = gray.cuda(), ab.cuda()\n",
    "\n",
    "        # Run model and record loss\n",
    "        output_ab = model(gray) # throw away class predictions\n",
    "        loss = criterion(output_ab, ab)\n",
    "        \n",
    "        _loss.update(loss.item(), gray.size(0))\n",
    "\n",
    "        # Save images to file\n",
    "        if save_images and not already_saved_images:\n",
    "            already_saved_images = True\n",
    "            for j in range(min(len(output_ab), 10)): # save at most 5 images\n",
    "                save_path = {'grayscale': gray_imgs, 'colorized': color_imgs}\n",
    "                save_name = 'img-{}-epoch-{}.jpg'.format(j, epoch)\n",
    "                to_rgb(gray[j].cpu(), ab_input=output_ab[j].detach().cpu(), save_path=save_path, save_name=save_name)\n",
    "\n",
    "    print('Validate: Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "         loss=_loss))\n",
    "\n",
    "    print('Finished validation.')\n",
    "    if epoch >= 0:\n",
    "        writer.add_scalar(\"Loss/test\", _loss.avg, epoch)\n",
    "    return _loss.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOo__iEnvLMB"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    print(f'Starting training epoch {epoch}')\n",
    "    _loss = AverageMeter()\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for gray, ab in train_loader:\n",
    "        if use_gpu: \n",
    "            gray, ab = gray.cuda(), ab.cuda()\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_ab = model(gray) \n",
    "        loss = criterion(output_ab, ab) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _loss.update(loss.item(), gray.size(0))\n",
    "        \n",
    "    print(f'Epoch: {epoch}, Loss {_loss.val:.4f} ({_loss.avg:.4f})')\n",
    "    \n",
    "    print(f'Finished training epoch {epoch}')\n",
    "    if epoch >= 0:\n",
    "        writer.add_scalar(\"Loss/train\", _loss.avg, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ckNmKA5VwSh1"
   },
   "outputs": [],
   "source": [
    "# Make folders and set parameters\n",
    "checkpoints = 'checkpoints'\n",
    "os.makedirs(color_imgs, exist_ok=True)\n",
    "os.makedirs(gray_imgs, exist_ok=True)\n",
    "os.makedirs(checkpoints, exist_ok=True)\n",
    "save_images = True\n",
    "best_losses = 1e10\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "id": "XUR6ALi3AZoO",
    "outputId": "4b274c7b-fc1d-4e14-dc1f-a7ef93f3663f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "for epoch in range(epochs):\n",
    "    # Train for one epoch, then validate\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "    with torch.no_grad():\n",
    "        losses = validate(val_loader, model, criterion, save_images, epoch)\n",
    "    # Save checkpoint and replace old best model if current model is better\n",
    "    if losses < best_losses:\n",
    "        best_losses = losses\n",
    "        torch.save(model.state_dict(), '{}/model-epoch-{}-losses-{:.6f}.pth'.format(checkpoints,epoch+1,losses))\n",
    "\n",
    "    if epoch == epochs - 1:\n",
    "        torch.save(model.state_dict(), '{}/model-epoch-{}-last-losses-{:.6f}.pth'.format(checkpoints,epoch+1,losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '{}/model-epoch-last-losses-{:.6f}.pth'.format(checkpoints,losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1593
    },
    "id": "UcovGnpHMl9D",
    "outputId": "90b7a2b4-dc03-4862-cf02-c7ddbbb7e500"
   },
   "outputs": [],
   "source": [
    "# Validate\n",
    "save_images = True\n",
    "with torch.no_grad():\n",
    "    validate(val_loader, model, criterion, save_images, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show images \n",
    "# image_pairs = []\n",
    "\n",
    "# for i in range(10):\n",
    "#     image_pairs.append((f'{color_imgs}img-{i}-epoch-{best_epoch}.jpg', f'{gray_imgs}img-{i}-epoch-{best_epoch}.jpg'))\n",
    "    \n",
    "# for c, g in image_pairs:\n",
    "#   color = mpimg.imread(c)\n",
    "#   gray  = mpimg.imread(g)\n",
    "#   f, axarr = plt.subplots(1, 2)\n",
    "#   f.set_size_inches(15, 15)\n",
    "#   axarr[0].imshow(gray, cmap='gray')\n",
    "#   axarr[1].imshow(color)\n",
    "#   axarr[0].axis('off'), axarr[1].axis('off')\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
