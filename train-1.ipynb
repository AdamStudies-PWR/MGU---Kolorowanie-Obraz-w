{"cells":[{"cell_type":"markdown","metadata":{"id":"9nd6lZVqSTu9"},"source":["# Constants that need to be set"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":435,"status":"ok","timestamp":1673909942197,"user":{"displayName":"Leszek Ostek","userId":"01420718588842860711"},"user_tz":-60},"id":"j4lBi-0QSgr-"},"outputs":[],"source":["MODEL_SAVE_PATH = '/content/drive/MyDrive/pwr/sztuczna'\n","DATASET_PATH = '/content/drive/MyDrive/pwr/sztuczna/train'\n","TENSORBOARD_LOG_PATH = '/content/drive/MyDrive/pwr/sztuczna/logs'\n","EPOCHS = 30\n","BATCH_SIZE = 16"]},{"cell_type":"markdown","metadata":{"id":"-60XDfgvSIy4"},"source":["# Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1394,"status":"ok","timestamp":1673909945033,"user":{"displayName":"Leszek Ostek","userId":"01420718588842860711"},"user_tz":-60},"id":"i0tiZqBiSRve"},"outputs":[],"source":["import os\n","import torch\n","import sys\n","import numpy as np\n","\n","from torch import nn, optim\n","from PIL import Image\n","from skimage.color import rgb2lab\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"markdown","metadata":{"id":"59lsPljZSzcQ"},"source":["# Define classes (model & dataset)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1673909945990,"user":{"displayName":"Leszek Ostek","userId":"01420718588842860711"},"user_tz":-60},"id":"4KejmjDsS7ma"},"outputs":[],"source":["class Unet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # First block coding\n","        self.b1_conv2d = nn.Conv2d(1, 25, kernel_size=4, stride=2, padding=1, bias=False)\n","\n","        # Second block coding\n","        self.b2_leaky_relu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n","        self.b2_conv2d = nn.Conv2d(25, 50, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","        self.b2_batch_norm2d_1 = nn.BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","\n","        # Third block coding\n","        self.b3_leaky_relu =  nn.LeakyReLU(negative_slope=0.2, inplace=True)\n","        self.b3_conv2d = nn.Conv2d(50, 100, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","        self.b3_batch_norm2d_1 = nn.BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","\n","        # Fourth block coding\n","        self.b4_leaky_relu =  nn.LeakyReLU(negative_slope=0.2, inplace=True)\n","        self.b4_conv2d = nn.Conv2d(100, 200, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","        self.b4_batch_norm2d_1 = nn.BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","\n","        # Middle block\n","        self.mb_leaky_relu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n","        self.mb_conv2d = nn.Conv2d(200, 200, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","        self.mb_relu = nn.ReLU(inplace=True)\n","        self.mb_conv_transpose2d = nn.ConvTranspose2d(200, 200, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","        self.mb_batch_norm2d = nn.BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","\n","        # Fourth block decoding\n","        self.b4_relu = nn.ReLU(inplace=True)\n","        self.b4_conv_transpose2d = nn.ConvTranspose2d(400, 100, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","        self.b4_batch_norm2d_2 = nn.BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","\n","        # Third block decoding\n","        self.b3_relu = nn.ReLU(inplace=True)\n","        self.b3_conv_transpose2d = nn.ConvTranspose2d(200, 50, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","        self.b3_batch_norm2d_2 = nn.BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","\n","        # Second block decoding\n","        self.b2_relu = nn.ReLU(inplace=True)\n","        self.b2_conv_transpose2d = nn.ConvTranspose2d(100, 25, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","        self.b2_batch_norm2d_2 = nn.BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","\n","        # Third block decoding\n","        self.b1_relu = nn.ReLU(inplace=True)\n","        self.b1_conv_transpose2d = nn.ConvTranspose2d(50, 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","        self.b1_batch_norm2d = nn.BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","\n","        def init_weights(layer):\n","            if isinstance(layer, nn.Conv2d):\n","                nn.init.xavier_uniform_(layer.weight)\n","                if layer.bias is not None:\n","                    nn.init.zeros_(layer.bias)\n","\n","        # Init weights\n","        self.apply(init_weights)\n","    \n","    def forward(self, x):\n","        # First block coding\n","        x = self.b1_conv2d(x)\n","        b1_connection = x\n","\n","        # Second block coding\n","        x = self.b2_leaky_relu(x)\n","        x = self.b2_conv2d(x)\n","        x = self.b2_batch_norm2d_1(x)\n","        b2_connection = x\n","\n","        # Third block coding\n","        x = self.b3_leaky_relu(x)\n","        x = self.b3_conv2d(x)\n","        x = self.b3_batch_norm2d_1(x)\n","        b3_connection = x\n","\n","        # Fourth block coding\n","        x = self.b4_leaky_relu(x)\n","        x = self.b4_conv2d(x)\n","        x = self.b4_batch_norm2d_1(x)\n","        b4_connection = x\n","\n","        # Middle block\n","        x = self.mb_leaky_relu(x)\n","        x = self.mb_conv2d(x)\n","        x = self.mb_relu(x)\n","        x = self.mb_conv_transpose2d(x)\n","        x = self.mb_batch_norm2d(x)\n","\n","        # Fourth block decoding\n","        x = self.b4_relu(torch.cat([b4_connection, x], 1))\n","        x = self.b4_conv_transpose2d(x)\n","        x = self.b4_batch_norm2d_2(x)\n","\n","        # Third block decoding\n","        x = self.b3_relu(torch.cat([b3_connection, x], 1))\n","        x = self.b3_conv_transpose2d(x)\n","        x = self.b3_batch_norm2d_2(x)\n","\n","        # Second block decoding\n","        x = self.b2_relu(torch.cat([b2_connection, x], 1))\n","        x = self.b2_conv_transpose2d(x)\n","        x = self.b2_batch_norm2d_2(x)\n","\n","        # First block decoding\n","        x = self.b1_relu(torch.cat([b1_connection, x], 1))\n","        x = self.b1_conv_transpose2d(x)\n","        x = self.b1_batch_norm2d(x)\n","\n","        return x\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","          nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=True),\n","          nn.LeakyReLU(0.2, True),\n","          nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n","          nn.BatchNorm2d(128),\n","          nn.LeakyReLU(0.2, True),\n","          nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n","          nn.BatchNorm2d(256),\n","          nn.LeakyReLU(0.2, True),\n","          nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=1, bias=False),\n","          nn.BatchNorm2d(512),\n","          nn.LeakyReLU(0.2, True),\n","          nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1, bias=True)\n","        )\n","        \n","        # Initialize weights\n","        for layer in self.model:\n","            if isinstance(layer, nn.Conv2d):\n","                nn.init.xavier_uniform_(layer.weight)\n","                if layer.bias is not None:\n","                    nn.init.zeros_(layer.bias)\n","                \n","\n","    def forward(self, x):\n","        return self.model(x)\n","        \n","class ColorizationDataset(Dataset):\n","    def __init__(self):\n","        self.paths = [os.path.join(DATASET_PATH, file) for file in os.listdir(DATASET_PATH)]\n","    \n","    def __getitem__(self, idx):\n","        img = Image.open(self.paths[idx]).convert(\"RGB\")\n","        img = np.array(img)\n","        img_lab = rgb2lab(img).astype(\"float32\")\n","        img_lab = transforms.ToTensor()(img_lab)\n","        L = img_lab[[0], ...] / 50. - 1.\n","        ab = img_lab[[1, 2], ...] / 110.\n","        return {'L': L, 'ab': ab}\n","    \n","    def __len__(self):\n","        return len(self.paths)"]},{"cell_type":"markdown","metadata":{"id":"hhbepCAiThAq"},"source":["# Init traning"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5972,"status":"ok","timestamp":1673909958143,"user":{"displayName":"Leszek Ostek","userId":"01420718588842860711"},"user_tz":-60},"id":"J3gt5ff3T4mY","outputId":"0f5f59b3-715b-41f0-cf7f-bf8d98bc635c"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["writer = SummaryWriter(TENSORBOARD_LOG_PATH)\n","\n","dataset = ColorizationDataset()\n","data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=4, pin_memory=True)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","generator = Unet().to(device)\n","discriminator = Discriminator().to(device)\n","discriminator_true_output = torch.tensor(1.0).to(device)\n","discriminator_false_output = torch.tensor(0.0).to(device)\n","\n","loss_function = nn.BCEWithLogitsLoss()\n","l1_loss = nn.L1Loss()\n","\n","generator_optimizer = optim.Adam(generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n","discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))"]},{"cell_type":"markdown","metadata":{"id":"_5qGpH5eUFwf"},"source":["# Train"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3328382,"status":"ok","timestamp":1673913286521,"user":{"displayName":"Leszek Ostek","userId":"01420718588842860711"},"user_tz":-60},"id":"Ajw0IuUeUIKc","outputId":"19b93e56-5052-4905-c45f-20d9db0e9120"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mStrumieniowane dane wyjściowe obcięte do 5000 ostatnich wierszy.\u001b[0m\n","\n","Epoch 20/30\n","Iteration 1472/3040\n","Loss gen 11.7354 (14.1853)\n","Loss dis 0.4102 (0.1716)\n","\n","Epoch 20/30\n","Iteration 1504/3040\n","Loss gen 11.5069 (14.1832)\n","Loss dis 0.1444 (0.1706)\n","\n","Epoch 20/30\n","Iteration 1536/3040\n","Loss gen 14.4699 (14.1855)\n","Loss dis 0.0041 (0.1695)\n","\n","Epoch 20/30\n","Iteration 1568/3040\n","Loss gen 12.7917 (14.1849)\n","Loss dis 0.2393 (0.1677)\n","\n","Epoch 20/30\n","Iteration 1600/3040\n","Loss gen 13.3730 (14.1776)\n","Loss dis 0.0223 (0.1669)\n","\n","Epoch 20/30\n","Iteration 1632/3040\n","Loss gen 14.6770 (14.1909)\n","Loss dis 0.0223 (0.1676)\n","\n","Epoch 20/30\n","Iteration 1664/3040\n","Loss gen 12.7604 (14.1810)\n","Loss dis 0.0994 (0.1688)\n","\n","Epoch 20/30\n","Iteration 1696/3040\n","Loss gen 10.7518 (14.1903)\n","Loss dis 0.2373 (0.1676)\n","\n","Epoch 20/30\n","Iteration 1728/3040\n","Loss gen 14.5244 (14.1875)\n","Loss dis 0.2682 (0.1681)\n","\n","Epoch 20/30\n","Iteration 1760/3040\n","Loss gen 16.6604 (14.1819)\n","Loss dis 0.0187 (0.1703)\n","\n","Epoch 20/30\n","Iteration 1792/3040\n","Loss gen 10.2937 (14.1690)\n","Loss dis 0.9714 (0.1710)\n","\n","Epoch 20/30\n","Iteration 1824/3040\n","Loss gen 14.4299 (14.1699)\n","Loss dis 0.0250 (0.1701)\n","\n","Epoch 20/30\n","Iteration 1856/3040\n","Loss gen 14.6078 (14.1652)\n","Loss dis 0.0221 (0.1712)\n","\n","Epoch 20/30\n","Iteration 1888/3040\n","Loss gen 16.0462 (14.1553)\n","Loss dis 0.0040 (0.1704)\n","\n","Epoch 20/30\n","Iteration 1920/3040\n","Loss gen 15.0176 (14.1650)\n","Loss dis 0.3139 (0.1697)\n","\n","Epoch 20/30\n","Iteration 1952/3040\n","Loss gen 13.5499 (14.1661)\n","Loss dis 0.0077 (0.1700)\n","\n","Epoch 20/30\n","Iteration 1984/3040\n","Loss gen 10.9308 (14.1670)\n","Loss dis 0.8379 (0.1699)\n","\n","Epoch 20/30\n","Iteration 2016/3040\n","Loss gen 16.2261 (14.1700)\n","Loss dis 0.0265 (0.1703)\n","\n","Epoch 20/30\n","Iteration 2048/3040\n","Loss gen 13.2836 (14.1673)\n","Loss dis 0.0696 (0.1703)\n","\n","Epoch 20/30\n","Iteration 2080/3040\n","Loss gen 12.9000 (14.1672)\n","Loss dis 0.0635 (0.1705)\n","\n","Epoch 20/30\n","Iteration 2112/3040\n","Loss gen 12.6807 (14.1712)\n","Loss dis 0.0458 (0.1700)\n","\n","Epoch 20/30\n","Iteration 2144/3040\n","Loss gen 14.1890 (14.1784)\n","Loss dis 0.0352 (0.1697)\n","\n","Epoch 20/30\n","Iteration 2176/3040\n","Loss gen 13.8141 (14.1763)\n","Loss dis 0.4008 (0.1692)\n","\n","Epoch 20/30\n","Iteration 2208/3040\n","Loss gen 13.8925 (14.1848)\n","Loss dis 0.6222 (0.1700)\n","\n","Epoch 20/30\n","Iteration 2240/3040\n","Loss gen 16.8579 (14.1786)\n","Loss dis 0.0132 (0.1702)\n","\n","Epoch 20/30\n","Iteration 2272/3040\n","Loss gen 14.1836 (14.1908)\n","Loss dis 0.0048 (0.1702)\n","\n","Epoch 20/30\n","Iteration 2304/3040\n","Loss gen 13.7000 (14.2018)\n","Loss dis 0.0201 (0.1691)\n","\n","Epoch 20/30\n","Iteration 2336/3040\n","Loss gen 11.7700 (14.2008)\n","Loss dis 0.0648 (0.1683)\n","\n","Epoch 20/30\n","Iteration 2368/3040\n","Loss gen 16.3181 (14.2032)\n","Loss dis 0.0042 (0.1673)\n","\n","Epoch 20/30\n","Iteration 2400/3040\n","Loss gen 14.2397 (14.2075)\n","Loss dis 0.0812 (0.1670)\n","\n","Epoch 20/30\n","Iteration 2432/3040\n","Loss gen 15.6767 (14.2058)\n","Loss dis 0.0021 (0.1657)\n","\n","Epoch 20/30\n","Iteration 2464/3040\n","Loss gen 14.4727 (14.2061)\n","Loss dis 0.0081 (0.1672)\n","\n","Epoch 20/30\n","Iteration 2496/3040\n","Loss gen 17.6230 (14.2093)\n","Loss dis 0.0024 (0.1694)\n","\n","Epoch 20/30\n","Iteration 2528/3040\n","Loss gen 12.3095 (14.2080)\n","Loss dis 0.1527 (0.1705)\n","\n","Epoch 20/30\n","Iteration 2560/3040\n","Loss gen 15.2445 (14.2047)\n","Loss dis 1.0512 (0.1707)\n","\n","Epoch 20/30\n","Iteration 2592/3040\n","Loss gen 16.2581 (14.2023)\n","Loss dis 0.1269 (0.1711)\n","\n","Epoch 20/30\n","Iteration 2624/3040\n","Loss gen 12.5141 (14.2027)\n","Loss dis 0.0638 (0.1708)\n","\n","Epoch 20/30\n","Iteration 2656/3040\n","Loss gen 14.8008 (14.1954)\n","Loss dis 0.0167 (0.1705)\n","\n","Epoch 20/30\n","Iteration 2688/3040\n","Loss gen 14.4369 (14.1962)\n","Loss dis 0.0433 (0.1697)\n","\n","Epoch 20/30\n","Iteration 2720/3040\n","Loss gen 11.3383 (14.1844)\n","Loss dis 0.4151 (0.1717)\n","\n","Epoch 20/30\n","Iteration 2752/3040\n","Loss gen 13.7647 (14.1824)\n","Loss dis 0.0651 (0.1716)\n","\n","Epoch 20/30\n","Iteration 2784/3040\n","Loss gen 13.9375 (14.1758)\n","Loss dis 0.0333 (0.1710)\n","\n","Epoch 20/30\n","Iteration 2816/3040\n","Loss gen 15.2496 (14.1672)\n","Loss dis 0.1584 (0.1701)\n","\n","Epoch 20/30\n","Iteration 2848/3040\n","Loss gen 12.7326 (14.1699)\n","Loss dis 0.1645 (0.1704)\n","\n","Epoch 20/30\n","Iteration 2880/3040\n","Loss gen 15.3303 (14.1819)\n","Loss dis 0.0119 (0.1699)\n","\n","Epoch 20/30\n","Iteration 2912/3040\n","Loss gen 13.6907 (14.1906)\n","Loss dis 0.0654 (0.1702)\n","\n","Epoch 20/30\n","Iteration 2944/3040\n","Loss gen 11.8511 (14.1883)\n","Loss dis 0.1739 (0.1707)\n","\n","Epoch 20/30\n","Iteration 2976/3040\n","Loss gen 14.6234 (14.1944)\n","Loss dis 0.0198 (0.1714)\n","\n","Epoch 20/30\n","Iteration 3008/3040\n","Loss gen 11.4765 (14.2044)\n","Loss dis 0.0308 (0.1712)\n","\n","Epoch 20/30\n","Iteration 3040/3040\n","Loss gen 15.4567 (14.2107)\n","Loss dis 0.1044 (0.1729)\n","\n","Epoch 21/30\n","Iteration 32/3040\n","Loss gen 14.4005 (13.9419)\n","Loss dis 0.0529 (0.2551)\n","\n","Epoch 21/30\n","Iteration 64/3040\n","Loss gen 15.1547 (13.8102)\n","Loss dis 0.1191 (0.2070)\n","\n","Epoch 21/30\n","Iteration 96/3040\n","Loss gen 14.4327 (13.9200)\n","Loss dis 0.0065 (0.1890)\n","\n","Epoch 21/30\n","Iteration 128/3040\n","Loss gen 13.6241 (13.8423)\n","Loss dis 0.0363 (0.1873)\n","\n","Epoch 21/30\n","Iteration 160/3040\n","Loss gen 14.4441 (13.8597)\n","Loss dis 0.1589 (0.1760)\n","\n","Epoch 21/30\n","Iteration 192/3040\n","Loss gen 9.8089 (13.8644)\n","Loss dis 1.0514 (0.1786)\n","\n","Epoch 21/30\n","Iteration 224/3040\n","Loss gen 10.6963 (13.8762)\n","Loss dis 0.2423 (0.1755)\n","\n","Epoch 21/30\n","Iteration 256/3040\n","Loss gen 11.7136 (13.9268)\n","Loss dis 0.0369 (0.1742)\n","\n","Epoch 21/30\n","Iteration 288/3040\n","Loss gen 14.6235 (13.8980)\n","Loss dis 0.0107 (0.1728)\n","\n","Epoch 21/30\n","Iteration 320/3040\n","Loss gen 17.4900 (13.9601)\n","Loss dis 0.0083 (0.1702)\n","\n","Epoch 21/30\n","Iteration 352/3040\n","Loss gen 10.9933 (13.9777)\n","Loss dis 0.0604 (0.1638)\n","\n","Epoch 21/30\n","Iteration 384/3040\n","Loss gen 15.2756 (14.0356)\n","Loss dis 0.0033 (0.1692)\n","\n","Epoch 21/30\n","Iteration 416/3040\n","Loss gen 19.5109 (14.1130)\n","Loss dis 0.0003 (0.1664)\n","\n","Epoch 21/30\n","Iteration 448/3040\n","Loss gen 13.3676 (14.1907)\n","Loss dis 0.0250 (0.1648)\n","\n","Epoch 21/30\n","Iteration 480/3040\n","Loss gen 13.9916 (14.2654)\n","Loss dis 0.0211 (0.1722)\n","\n","Epoch 21/30\n","Iteration 512/3040\n","Loss gen 13.8295 (14.2144)\n","Loss dis 2.3901 (0.1923)\n","\n","Epoch 21/30\n","Iteration 544/3040\n","Loss gen 13.8496 (14.1612)\n","Loss dis 0.4445 (0.2022)\n","\n","Epoch 21/30\n","Iteration 576/3040\n","Loss gen 12.8131 (14.1549)\n","Loss dis 0.5903 (0.2024)\n","\n","Epoch 21/30\n","Iteration 608/3040\n","Loss gen 13.2003 (14.1240)\n","Loss dis 0.0580 (0.2033)\n","\n","Epoch 21/30\n","Iteration 640/3040\n","Loss gen 13.3523 (14.0959)\n","Loss dis 0.1762 (0.2025)\n","\n","Epoch 21/30\n","Iteration 672/3040\n","Loss gen 10.5704 (14.0944)\n","Loss dis 0.2729 (0.2071)\n","\n","Epoch 21/30\n","Iteration 704/3040\n","Loss gen 14.0414 (14.0859)\n","Loss dis 0.0803 (0.2064)\n","\n","Epoch 21/30\n","Iteration 736/3040\n","Loss gen 14.5571 (14.0664)\n","Loss dis 0.1941 (0.2029)\n","\n","Epoch 21/30\n","Iteration 768/3040\n","Loss gen 10.1163 (14.0502)\n","Loss dis 0.2807 (0.2022)\n","\n","Epoch 21/30\n","Iteration 800/3040\n","Loss gen 15.0646 (14.0420)\n","Loss dis 0.0540 (0.1990)\n","\n","Epoch 21/30\n","Iteration 832/3040\n","Loss gen 14.7554 (14.0273)\n","Loss dis 0.3953 (0.1985)\n","\n","Epoch 21/30\n","Iteration 864/3040\n","Loss gen 11.4700 (14.0383)\n","Loss dis 0.1492 (0.2003)\n","\n","Epoch 21/30\n","Iteration 896/3040\n","Loss gen 13.9778 (14.0147)\n","Loss dis 0.0062 (0.1989)\n","\n","Epoch 21/30\n","Iteration 928/3040\n","Loss gen 15.1771 (13.9983)\n","Loss dis 0.0964 (0.1974)\n","\n","Epoch 21/30\n","Iteration 960/3040\n","Loss gen 15.6233 (13.9923)\n","Loss dis 0.5489 (0.1956)\n","\n","Epoch 21/30\n","Iteration 992/3040\n","Loss gen 15.1472 (13.9816)\n","Loss dis 0.0199 (0.1966)\n","\n","Epoch 21/30\n","Iteration 1024/3040\n","Loss gen 13.9247 (13.9843)\n","Loss dis 0.0293 (0.1975)\n","\n","Epoch 21/30\n","Iteration 1056/3040\n","Loss gen 12.9571 (13.9891)\n","Loss dis 0.3306 (0.1962)\n","\n","Epoch 21/30\n","Iteration 1088/3040\n","Loss gen 13.9869 (13.9907)\n","Loss dis 0.0691 (0.1948)\n","\n","Epoch 21/30\n","Iteration 1120/3040\n","Loss gen 14.4969 (13.9859)\n","Loss dis 0.0416 (0.1947)\n","\n","Epoch 21/30\n","Iteration 1152/3040\n","Loss gen 14.2473 (13.9844)\n","Loss dis 0.1545 (0.1928)\n","\n","Epoch 21/30\n","Iteration 1184/3040\n","Loss gen 15.4197 (13.9966)\n","Loss dis 0.0422 (0.1917)\n","\n","Epoch 21/30\n","Iteration 1216/3040\n","Loss gen 13.4461 (13.9965)\n","Loss dis 0.2289 (0.1919)\n","\n","Epoch 21/30\n","Iteration 1248/3040\n","Loss gen 12.4596 (14.0089)\n","Loss dis 0.0760 (0.1904)\n","\n","Epoch 21/30\n","Iteration 1280/3040\n","Loss gen 13.4768 (14.0138)\n","Loss dis 0.2953 (0.1888)\n","\n","Epoch 21/30\n","Iteration 1312/3040\n","Loss gen 14.9148 (14.0108)\n","Loss dis 0.0890 (0.1873)\n","\n","Epoch 21/30\n","Iteration 1344/3040\n","Loss gen 14.2491 (14.0187)\n","Loss dis 0.0197 (0.1857)\n","\n","Epoch 21/30\n","Iteration 1376/3040\n","Loss gen 14.7358 (14.0332)\n","Loss dis 0.0805 (0.1852)\n","\n","Epoch 21/30\n","Iteration 1408/3040\n","Loss gen 16.4793 (14.0382)\n","Loss dis 0.0017 (0.1834)\n","\n","Epoch 21/30\n","Iteration 1440/3040\n","Loss gen 17.4649 (14.0550)\n","Loss dis 0.0226 (0.1823)\n","\n","Epoch 21/30\n","Iteration 1472/3040\n","Loss gen 12.9904 (14.0617)\n","Loss dis 0.0382 (0.1824)\n","\n","Epoch 21/30\n","Iteration 1504/3040\n","Loss gen 10.9288 (14.0686)\n","Loss dis 0.0678 (0.1816)\n","\n","Epoch 21/30\n","Iteration 1536/3040\n","Loss gen 14.7337 (14.0783)\n","Loss dis 0.0278 (0.1796)\n","\n","Epoch 21/30\n","Iteration 1568/3040\n","Loss gen 17.6129 (14.0847)\n","Loss dis 1.3250 (0.1810)\n","\n","Epoch 21/30\n","Iteration 1600/3040\n","Loss gen 15.0427 (14.0798)\n","Loss dis 0.4725 (0.1832)\n","\n","Epoch 21/30\n","Iteration 1632/3040\n","Loss gen 13.7718 (14.0846)\n","Loss dis 0.0220 (0.1819)\n","\n","Epoch 21/30\n","Iteration 1664/3040\n","Loss gen 15.0845 (14.0779)\n","Loss dis 0.1824 (0.1838)\n","\n","Epoch 21/30\n","Iteration 1696/3040\n","Loss gen 11.1422 (14.0845)\n","Loss dis 0.1968 (0.1823)\n","\n","Epoch 21/30\n","Iteration 1728/3040\n","Loss gen 14.1196 (14.0807)\n","Loss dis 0.0381 (0.1809)\n","\n","Epoch 21/30\n","Iteration 1760/3040\n","Loss gen 17.6786 (14.0810)\n","Loss dis 0.0016 (0.1826)\n","\n","Epoch 21/30\n","Iteration 1792/3040\n","Loss gen 12.2420 (14.0741)\n","Loss dis 0.1864 (0.1847)\n","\n","Epoch 21/30\n","Iteration 1824/3040\n","Loss gen 10.2741 (14.0677)\n","Loss dis 2.0558 (0.1874)\n","\n","Epoch 21/30\n","Iteration 1856/3040\n","Loss gen 16.4109 (14.0599)\n","Loss dis 0.3596 (0.1896)\n","\n","Epoch 21/30\n","Iteration 1888/3040\n","Loss gen 13.6538 (14.0452)\n","Loss dis 0.0128 (0.1879)\n","\n","Epoch 21/30\n","Iteration 1920/3040\n","Loss gen 15.0570 (14.0402)\n","Loss dis 0.1581 (0.1878)\n","\n","Epoch 21/30\n","Iteration 1952/3040\n","Loss gen 13.8465 (14.0242)\n","Loss dis 0.0711 (0.1888)\n","\n","Epoch 21/30\n","Iteration 1984/3040\n","Loss gen 14.8355 (14.0189)\n","Loss dis 0.4551 (0.1883)\n","\n","Epoch 21/30\n","Iteration 2016/3040\n","Loss gen 13.1741 (14.0188)\n","Loss dis 0.1045 (0.1872)\n","\n","Epoch 21/30\n","Iteration 2048/3040\n","Loss gen 11.2231 (14.0087)\n","Loss dis 0.2000 (0.1862)\n","\n","Epoch 21/30\n","Iteration 2080/3040\n","Loss gen 13.2618 (14.0157)\n","Loss dis 0.0668 (0.1854)\n","\n","Epoch 21/30\n","Iteration 2112/3040\n","Loss gen 11.2870 (14.0301)\n","Loss dis 0.2669 (0.1839)\n","\n","Epoch 21/30\n","Iteration 2144/3040\n","Loss gen 12.6360 (14.0370)\n","Loss dis 0.0297 (0.1857)\n","\n","Epoch 21/30\n","Iteration 2176/3040\n","Loss gen 12.5164 (14.0399)\n","Loss dis 0.2670 (0.1849)\n","\n","Epoch 21/30\n","Iteration 2208/3040\n","Loss gen 17.7164 (14.0405)\n","Loss dis 0.0571 (0.1842)\n","\n","Epoch 21/30\n","Iteration 2240/3040\n","Loss gen 16.2924 (14.0425)\n","Loss dis 0.0108 (0.1832)\n","\n","Epoch 21/30\n","Iteration 2272/3040\n","Loss gen 12.7235 (14.0463)\n","Loss dis 0.2144 (0.1827)\n","\n","Epoch 21/30\n","Iteration 2304/3040\n","Loss gen 13.2933 (14.0591)\n","Loss dis 0.0665 (0.1818)\n","\n","Epoch 21/30\n","Iteration 2336/3040\n","Loss gen 10.4463 (14.0699)\n","Loss dis 0.3320 (0.1809)\n","\n","Epoch 21/30\n","Iteration 2368/3040\n","Loss gen 13.4150 (14.0830)\n","Loss dis 0.0308 (0.1797)\n","\n","Epoch 21/30\n","Iteration 2400/3040\n","Loss gen 13.1289 (14.0871)\n","Loss dis 0.1984 (0.1795)\n","\n","Epoch 21/30\n","Iteration 2432/3040\n","Loss gen 13.5592 (14.0847)\n","Loss dis 0.0332 (0.1788)\n","\n","Epoch 21/30\n","Iteration 2464/3040\n","Loss gen 18.1910 (14.0848)\n","Loss dis 0.0037 (0.1793)\n","\n","Epoch 21/30\n","Iteration 2496/3040\n","Loss gen 13.3618 (14.0831)\n","Loss dis 0.0960 (0.1786)\n","\n","Epoch 21/30\n","Iteration 2528/3040\n","Loss gen 13.0721 (14.0827)\n","Loss dis 0.0400 (0.1787)\n","\n","Epoch 21/30\n","Iteration 2560/3040\n","Loss gen 15.4635 (14.0838)\n","Loss dis 0.0172 (0.1778)\n","\n","Epoch 21/30\n","Iteration 2592/3040\n","Loss gen 13.1654 (14.0818)\n","Loss dis 1.2473 (0.1784)\n","\n","Epoch 21/30\n","Iteration 2624/3040\n","Loss gen 14.0466 (14.0913)\n","Loss dis 0.0487 (0.1794)\n","\n","Epoch 21/30\n","Iteration 2656/3040\n","Loss gen 13.8998 (14.0867)\n","Loss dis 0.1399 (0.1810)\n","\n","Epoch 21/30\n","Iteration 2688/3040\n","Loss gen 13.0423 (14.0841)\n","Loss dis 0.1095 (0.1804)\n","\n","Epoch 21/30\n","Iteration 2720/3040\n","Loss gen 11.7499 (14.0804)\n","Loss dis 0.1783 (0.1801)\n","\n","Epoch 21/30\n","Iteration 2752/3040\n","Loss gen 13.8528 (14.0771)\n","Loss dis 0.0847 (0.1807)\n","\n","Epoch 21/30\n","Iteration 2784/3040\n","Loss gen 11.5324 (14.0776)\n","Loss dis 1.0893 (0.1805)\n","\n","Epoch 21/30\n","Iteration 2816/3040\n","Loss gen 17.6315 (14.0941)\n","Loss dis 0.0029 (0.1828)\n","\n","Epoch 21/30\n","Iteration 2848/3040\n","Loss gen 14.3034 (14.0885)\n","Loss dis 0.0279 (0.1823)\n","\n","Epoch 21/30\n","Iteration 2880/3040\n","Loss gen 14.6867 (14.0918)\n","Loss dis 0.0848 (0.1813)\n","\n","Epoch 21/30\n","Iteration 2912/3040\n","Loss gen 13.4170 (14.0875)\n","Loss dis 0.3072 (0.1820)\n","\n","Epoch 21/30\n","Iteration 2944/3040\n","Loss gen 9.5743 (14.0793)\n","Loss dis 0.3011 (0.1822)\n","\n","Epoch 21/30\n","Iteration 2976/3040\n","Loss gen 11.9780 (14.0844)\n","Loss dis 0.1889 (0.1821)\n","\n","Epoch 21/30\n","Iteration 3008/3040\n","Loss gen 11.2728 (14.0878)\n","Loss dis 0.0694 (0.1812)\n","\n","Epoch 21/30\n","Iteration 3040/3040\n","Loss gen 15.2052 (14.0835)\n","Loss dis 0.0391 (0.1805)\n","\n","Epoch 22/30\n","Iteration 32/3040\n","Loss gen 15.4627 (13.6612)\n","Loss dis 0.0122 (0.1480)\n","\n","Epoch 22/30\n","Iteration 64/3040\n","Loss gen 13.4164 (13.5409)\n","Loss dis 0.0886 (0.1372)\n","\n","Epoch 22/30\n","Iteration 96/3040\n","Loss gen 14.4714 (13.6976)\n","Loss dis 0.0049 (0.1332)\n","\n","Epoch 22/30\n","Iteration 128/3040\n","Loss gen 12.9035 (13.6690)\n","Loss dis 0.2615 (0.1546)\n","\n","Epoch 22/30\n","Iteration 160/3040\n","Loss gen 16.4238 (13.9158)\n","Loss dis 0.0060 (0.1500)\n","\n","Epoch 22/30\n","Iteration 192/3040\n","Loss gen 13.4344 (13.9345)\n","Loss dis 0.1767 (0.1502)\n","\n","Epoch 22/30\n","Iteration 224/3040\n","Loss gen 13.9714 (13.9463)\n","Loss dis 0.0965 (0.1419)\n","\n","Epoch 22/30\n","Iteration 256/3040\n","Loss gen 11.4166 (14.0088)\n","Loss dis 0.1312 (0.1373)\n","\n","Epoch 22/30\n","Iteration 288/3040\n","Loss gen 12.6816 (14.0519)\n","Loss dis 0.0376 (0.1456)\n","\n","Epoch 22/30\n","Iteration 320/3040\n","Loss gen 16.3105 (14.0810)\n","Loss dis 0.0371 (0.1498)\n","\n","Epoch 22/30\n","Iteration 352/3040\n","Loss gen 12.5995 (14.1457)\n","Loss dis 0.1375 (0.1427)\n","\n","Epoch 22/30\n","Iteration 384/3040\n","Loss gen 13.5799 (14.2185)\n","Loss dis 0.0879 (0.1470)\n","\n","Epoch 22/30\n","Iteration 416/3040\n","Loss gen 15.3535 (14.2215)\n","Loss dis 0.0099 (0.1495)\n","\n","Epoch 22/30\n","Iteration 448/3040\n","Loss gen 16.0082 (14.2835)\n","Loss dis 0.0029 (0.1555)\n","\n","Epoch 22/30\n","Iteration 480/3040\n","Loss gen 15.9992 (14.2776)\n","Loss dis 0.0181 (0.1523)\n","\n","Epoch 22/30\n","Iteration 512/3040\n","Loss gen 13.2616 (14.3155)\n","Loss dis 0.5233 (0.1607)\n","\n","Epoch 22/30\n","Iteration 544/3040\n","Loss gen 15.8655 (14.3288)\n","Loss dis 0.4142 (0.1637)\n","\n","Epoch 22/30\n","Iteration 576/3040\n","Loss gen 14.0772 (14.3074)\n","Loss dis 0.0663 (0.1640)\n","\n","Epoch 22/30\n","Iteration 608/3040\n","Loss gen 13.9675 (14.2801)\n","Loss dis 0.0211 (0.1613)\n","\n","Epoch 22/30\n","Iteration 640/3040\n","Loss gen 15.7511 (14.2769)\n","Loss dis 0.7818 (0.1615)\n","\n","Epoch 22/30\n","Iteration 672/3040\n","Loss gen 13.3167 (14.2956)\n","Loss dis 0.0503 (0.1579)\n","\n","Epoch 22/30\n","Iteration 704/3040\n","Loss gen 13.0178 (14.2619)\n","Loss dis 0.0589 (0.1549)\n","\n","Epoch 22/30\n","Iteration 736/3040\n","Loss gen 15.4244 (14.2580)\n","Loss dis 0.0174 (0.1533)\n","\n","Epoch 22/30\n","Iteration 768/3040\n","Loss gen 12.6226 (14.2494)\n","Loss dis 0.1646 (0.1530)\n","\n","Epoch 22/30\n","Iteration 800/3040\n","Loss gen 12.3977 (14.2582)\n","Loss dis 0.1377 (0.1539)\n","\n","Epoch 22/30\n","Iteration 832/3040\n","Loss gen 13.0738 (14.2395)\n","Loss dis 0.0784 (0.1556)\n","\n","Epoch 22/30\n","Iteration 864/3040\n","Loss gen 11.9980 (14.2197)\n","Loss dis 0.0364 (0.1529)\n","\n","Epoch 22/30\n","Iteration 896/3040\n","Loss gen 14.3961 (14.2113)\n","Loss dis 0.0034 (0.1560)\n","\n","Epoch 22/30\n","Iteration 928/3040\n","Loss gen 10.9580 (14.1765)\n","Loss dis 1.1934 (0.1584)\n","\n","Epoch 22/30\n","Iteration 960/3040\n","Loss gen 13.9345 (14.1583)\n","Loss dis 0.0183 (0.1576)\n","\n","Epoch 22/30\n","Iteration 992/3040\n","Loss gen 14.2510 (14.1381)\n","Loss dis 0.0418 (0.1573)\n","\n","Epoch 22/30\n","Iteration 1024/3040\n","Loss gen 14.0141 (14.1334)\n","Loss dis 0.0457 (0.1558)\n","\n","Epoch 22/30\n","Iteration 1056/3040\n","Loss gen 13.8745 (14.1145)\n","Loss dis 0.0386 (0.1559)\n","\n","Epoch 22/30\n","Iteration 1088/3040\n","Loss gen 15.8051 (14.1152)\n","Loss dis 0.3761 (0.1565)\n","\n","Epoch 22/30\n","Iteration 1120/3040\n","Loss gen 10.1987 (14.1050)\n","Loss dis 0.0281 (0.1551)\n","\n","Epoch 22/30\n","Iteration 1152/3040\n","Loss gen 16.3990 (14.1003)\n","Loss dis 0.3690 (0.1536)\n","\n","Epoch 22/30\n","Iteration 1184/3040\n","Loss gen 13.2574 (14.1102)\n","Loss dis 0.0966 (0.1549)\n","\n","Epoch 22/30\n","Iteration 1216/3040\n","Loss gen 15.5622 (14.1247)\n","Loss dis 0.2977 (0.1546)\n","\n","Epoch 22/30\n","Iteration 1248/3040\n","Loss gen 16.1462 (14.1414)\n","Loss dis 0.0131 (0.1558)\n","\n","Epoch 22/30\n","Iteration 1280/3040\n","Loss gen 13.4366 (14.1544)\n","Loss dis 0.1106 (0.1594)\n","\n","Epoch 22/30\n","Iteration 1312/3040\n","Loss gen 18.2866 (14.1526)\n","Loss dis 0.0016 (0.1591)\n","\n","Epoch 22/30\n","Iteration 1344/3040\n","Loss gen 15.8179 (14.1487)\n","Loss dis 0.2323 (0.1576)\n","\n","Epoch 22/30\n","Iteration 1376/3040\n","Loss gen 14.8404 (14.1620)\n","Loss dis 0.1594 (0.1570)\n","\n","Epoch 22/30\n","Iteration 1408/3040\n","Loss gen 13.0475 (14.1588)\n","Loss dis 0.0362 (0.1562)\n","\n","Epoch 22/30\n","Iteration 1440/3040\n","Loss gen 14.5834 (14.1556)\n","Loss dis 0.0804 (0.1539)\n","\n","Epoch 22/30\n","Iteration 1472/3040\n","Loss gen 12.9306 (14.1521)\n","Loss dis 0.1375 (0.1545)\n","\n","Epoch 22/30\n","Iteration 1504/3040\n","Loss gen 14.1146 (14.1573)\n","Loss dis 0.0639 (0.1556)\n","\n","Epoch 22/30\n","Iteration 1536/3040\n","Loss gen 14.3107 (14.1613)\n","Loss dis 0.0069 (0.1560)\n","\n","Epoch 22/30\n","Iteration 1568/3040\n","Loss gen 16.3228 (14.1685)\n","Loss dis 0.0237 (0.1549)\n","\n","Epoch 22/30\n","Iteration 1600/3040\n","Loss gen 14.3878 (14.1833)\n","Loss dis 0.1771 (0.1568)\n","\n","Epoch 22/30\n","Iteration 1632/3040\n","Loss gen 13.8563 (14.1877)\n","Loss dis 0.0415 (0.1551)\n","\n","Epoch 22/30\n","Iteration 1664/3040\n","Loss gen 14.3926 (14.1741)\n","Loss dis 0.0408 (0.1548)\n","\n","Epoch 22/30\n","Iteration 1696/3040\n","Loss gen 13.9936 (14.1758)\n","Loss dis 0.0336 (0.1534)\n","\n","Epoch 22/30\n","Iteration 1728/3040\n","Loss gen 12.5261 (14.1821)\n","Loss dis 0.1206 (0.1527)\n","\n","Epoch 22/30\n","Iteration 1760/3040\n","Loss gen 19.6806 (14.1876)\n","Loss dis 0.0003 (0.1515)\n","\n","Epoch 22/30\n","Iteration 1792/3040\n","Loss gen 16.8014 (14.1953)\n","Loss dis 0.1815 (0.1520)\n","\n","Epoch 22/30\n","Iteration 1824/3040\n","Loss gen 16.0259 (14.2045)\n","Loss dis 0.0112 (0.1535)\n","\n","Epoch 22/30\n","Iteration 1856/3040\n","Loss gen 15.4009 (14.2015)\n","Loss dis 0.0090 (0.1533)\n","\n","Epoch 22/30\n","Iteration 1888/3040\n","Loss gen 13.2112 (14.1903)\n","Loss dis 0.0276 (0.1523)\n","\n","Epoch 22/30\n","Iteration 1920/3040\n","Loss gen 14.2120 (14.1952)\n","Loss dis 0.1570 (0.1511)\n","\n","Epoch 22/30\n","Iteration 1952/3040\n","Loss gen 16.5790 (14.1955)\n","Loss dis 0.0060 (0.1535)\n","\n","Epoch 22/30\n","Iteration 1984/3040\n","Loss gen 12.8349 (14.1921)\n","Loss dis 0.2038 (0.1558)\n","\n","Epoch 22/30\n","Iteration 2016/3040\n","Loss gen 15.1948 (14.1927)\n","Loss dis 0.6492 (0.1564)\n","\n","Epoch 22/30\n","Iteration 2048/3040\n","Loss gen 16.6627 (14.1935)\n","Loss dis 0.0036 (0.1553)\n","\n","Epoch 22/30\n","Iteration 2080/3040\n","Loss gen 11.5235 (14.1883)\n","Loss dis 0.0418 (0.1547)\n","\n","Epoch 22/30\n","Iteration 2112/3040\n","Loss gen 15.1800 (14.2025)\n","Loss dis 0.0249 (0.1545)\n","\n","Epoch 22/30\n","Iteration 2144/3040\n","Loss gen 14.8830 (14.2170)\n","Loss dis 0.2948 (0.1569)\n","\n","Epoch 22/30\n","Iteration 2176/3040\n","Loss gen 13.1448 (14.2237)\n","Loss dis 0.5068 (0.1571)\n","\n","Epoch 22/30\n","Iteration 2208/3040\n","Loss gen 16.4173 (14.2193)\n","Loss dis 0.0139 (0.1569)\n","\n","Epoch 22/30\n","Iteration 2240/3040\n","Loss gen 15.6722 (14.2218)\n","Loss dis 0.0109 (0.1557)\n","\n","Epoch 22/30\n","Iteration 2272/3040\n","Loss gen 12.9992 (14.2300)\n","Loss dis 0.0307 (0.1558)\n","\n","Epoch 22/30\n","Iteration 2304/3040\n","Loss gen 13.7343 (14.2462)\n","Loss dis 0.0758 (0.1560)\n","\n","Epoch 22/30\n","Iteration 2336/3040\n","Loss gen 8.8971 (14.2470)\n","Loss dis 0.5817 (0.1554)\n","\n","Epoch 22/30\n","Iteration 2368/3040\n","Loss gen 14.8105 (14.2550)\n","Loss dis 0.0362 (0.1555)\n","\n","Epoch 22/30\n","Iteration 2400/3040\n","Loss gen 10.6116 (14.2535)\n","Loss dis 0.2559 (0.1555)\n","\n","Epoch 22/30\n","Iteration 2432/3040\n","Loss gen 14.0961 (14.2645)\n","Loss dis 0.0871 (0.1568)\n","\n","Epoch 22/30\n","Iteration 2464/3040\n","Loss gen 14.3623 (14.2660)\n","Loss dis 0.0350 (0.1568)\n","\n","Epoch 22/30\n","Iteration 2496/3040\n","Loss gen 14.8325 (14.2663)\n","Loss dis 0.0555 (0.1579)\n","\n","Epoch 22/30\n","Iteration 2528/3040\n","Loss gen 13.7664 (14.2683)\n","Loss dis 0.0764 (0.1592)\n","\n","Epoch 22/30\n","Iteration 2560/3040\n","Loss gen 13.1789 (14.2713)\n","Loss dis 0.1309 (0.1593)\n","\n","Epoch 22/30\n","Iteration 2592/3040\n","Loss gen 15.7441 (14.2645)\n","Loss dis 0.0154 (0.1592)\n","\n","Epoch 22/30\n","Iteration 2624/3040\n","Loss gen 14.0685 (14.2707)\n","Loss dis 0.1595 (0.1606)\n","\n","Epoch 22/30\n","Iteration 2656/3040\n","Loss gen 12.8749 (14.2676)\n","Loss dis 0.1363 (0.1600)\n","\n","Epoch 22/30\n","Iteration 2688/3040\n","Loss gen 11.3602 (14.2670)\n","Loss dis 0.4701 (0.1609)\n","\n","Epoch 22/30\n","Iteration 2720/3040\n","Loss gen 12.6885 (14.2733)\n","Loss dis 0.0230 (0.1610)\n","\n","Epoch 22/30\n","Iteration 2752/3040\n","Loss gen 12.9061 (14.2697)\n","Loss dis 0.3220 (0.1605)\n","\n","Epoch 22/30\n","Iteration 2784/3040\n","Loss gen 13.3040 (14.2683)\n","Loss dis 0.0657 (0.1616)\n","\n","Epoch 22/30\n","Iteration 2816/3040\n","Loss gen 18.1991 (14.2630)\n","Loss dis 0.4781 (0.1621)\n","\n","Epoch 22/30\n","Iteration 2848/3040\n","Loss gen 12.5134 (14.2629)\n","Loss dis 0.2662 (0.1619)\n","\n","Epoch 22/30\n","Iteration 2880/3040\n","Loss gen 14.3650 (14.2681)\n","Loss dis 0.0764 (0.1623)\n","\n","Epoch 22/30\n","Iteration 2912/3040\n","Loss gen 15.7956 (14.2684)\n","Loss dis 1.8177 (0.1645)\n","\n","Epoch 22/30\n","Iteration 2944/3040\n","Loss gen 11.6150 (14.2637)\n","Loss dis 0.6024 (0.1647)\n","\n","Epoch 22/30\n","Iteration 2976/3040\n","Loss gen 13.7479 (14.2623)\n","Loss dis 0.0347 (0.1653)\n","\n","Epoch 22/30\n","Iteration 3008/3040\n","Loss gen 12.0427 (14.2617)\n","Loss dis 0.0269 (0.1655)\n","\n","Epoch 22/30\n","Iteration 3040/3040\n","Loss gen 21.0987 (14.2616)\n","Loss dis 0.6149 (0.1659)\n","\n","Epoch 23/30\n","Iteration 32/3040\n","Loss gen 17.0360 (14.1144)\n","Loss dis 0.0020 (0.1779)\n","\n","Epoch 23/30\n","Iteration 64/3040\n","Loss gen 14.3335 (13.9666)\n","Loss dis 0.2379 (0.1388)\n","\n","Epoch 23/30\n","Iteration 96/3040\n","Loss gen 14.1622 (14.2151)\n","Loss dis 0.0221 (0.1282)\n","\n","Epoch 23/30\n","Iteration 128/3040\n","Loss gen 14.0810 (14.2558)\n","Loss dis 0.0989 (0.1439)\n","\n","Epoch 23/30\n","Iteration 160/3040\n","Loss gen 13.7256 (14.3563)\n","Loss dis 0.8571 (0.1860)\n","\n","Epoch 23/30\n","Iteration 192/3040\n","Loss gen 11.3710 (14.2990)\n","Loss dis 1.0717 (0.1793)\n","\n","Epoch 23/30\n","Iteration 224/3040\n","Loss gen 14.1868 (14.2641)\n","Loss dis 2.3790 (0.1845)\n","\n","Epoch 23/30\n","Iteration 256/3040\n","Loss gen 10.4847 (14.2415)\n","Loss dis 0.3119 (0.1773)\n","\n","Epoch 23/30\n","Iteration 288/3040\n","Loss gen 13.1096 (14.2753)\n","Loss dis 0.1011 (0.1652)\n","\n","Epoch 23/30\n","Iteration 320/3040\n","Loss gen 15.6848 (14.2276)\n","Loss dis 0.0314 (0.1699)\n","\n","Epoch 23/30\n","Iteration 352/3040\n","Loss gen 12.4520 (14.2486)\n","Loss dis 0.1162 (0.1688)\n","\n","Epoch 23/30\n","Iteration 384/3040\n","Loss gen 12.7943 (14.2241)\n","Loss dis 0.4826 (0.1684)\n","\n","Epoch 23/30\n","Iteration 416/3040\n","Loss gen 12.1984 (14.1869)\n","Loss dis 0.1693 (0.1647)\n","\n","Epoch 23/30\n","Iteration 448/3040\n","Loss gen 16.3744 (14.2656)\n","Loss dis 1.2999 (0.1647)\n","\n","Epoch 23/30\n","Iteration 480/3040\n","Loss gen 16.8500 (14.3299)\n","Loss dis 0.0027 (0.1659)\n","\n","Epoch 23/30\n","Iteration 512/3040\n","Loss gen 13.2713 (14.3403)\n","Loss dis 0.1156 (0.1653)\n","\n","Epoch 23/30\n","Iteration 544/3040\n","Loss gen 13.6685 (14.3365)\n","Loss dis 0.3151 (0.1627)\n","\n","Epoch 23/30\n","Iteration 576/3040\n","Loss gen 9.6381 (14.3340)\n","Loss dis 1.6147 (0.1586)\n","\n","Epoch 23/30\n","Iteration 608/3040\n","Loss gen 15.7667 (14.3049)\n","Loss dis 0.0168 (0.1599)\n","\n","Epoch 23/30\n","Iteration 640/3040\n","Loss gen 14.7821 (14.2923)\n","Loss dis 0.4469 (0.1634)\n","\n","Epoch 23/30\n","Iteration 672/3040\n","Loss gen 12.9817 (14.3158)\n","Loss dis 0.4594 (0.1596)\n","\n","Epoch 23/30\n","Iteration 704/3040\n","Loss gen 11.3865 (14.2766)\n","Loss dis 0.0590 (0.1575)\n","\n","Epoch 23/30\n","Iteration 736/3040\n","Loss gen 14.8606 (14.2372)\n","Loss dis 0.0061 (0.1551)\n","\n","Epoch 23/30\n","Iteration 768/3040\n","Loss gen 12.5513 (14.2210)\n","Loss dis 0.0437 (0.1525)\n","\n","Epoch 23/30\n","Iteration 800/3040\n","Loss gen 11.3366 (14.2210)\n","Loss dis 0.3749 (0.1498)\n","\n","Epoch 23/30\n","Iteration 832/3040\n","Loss gen 16.3836 (14.2274)\n","Loss dis 0.0274 (0.1506)\n","\n","Epoch 23/30\n","Iteration 864/3040\n","Loss gen 11.7587 (14.2249)\n","Loss dis 0.1389 (0.1514)\n","\n","Epoch 23/30\n","Iteration 896/3040\n","Loss gen 14.6790 (14.2128)\n","Loss dis 0.0205 (0.1503)\n","\n","Epoch 23/30\n","Iteration 928/3040\n","Loss gen 9.6106 (14.2191)\n","Loss dis 0.0355 (0.1589)\n","\n","Epoch 23/30\n","Iteration 960/3040\n","Loss gen 13.4706 (14.2235)\n","Loss dis 0.0224 (0.1604)\n","\n","Epoch 23/30\n","Iteration 992/3040\n","Loss gen 16.7463 (14.2122)\n","Loss dis 0.0076 (0.1617)\n","\n","Epoch 23/30\n","Iteration 1024/3040\n","Loss gen 13.6114 (14.2089)\n","Loss dis 0.2532 (0.1622)\n","\n","Epoch 23/30\n","Iteration 1056/3040\n","Loss gen 15.2561 (14.2555)\n","Loss dis 0.9518 (0.1652)\n","\n","Epoch 23/30\n","Iteration 1088/3040\n","Loss gen 14.4069 (14.2627)\n","Loss dis 0.0085 (0.1688)\n","\n","Epoch 23/30\n","Iteration 1120/3040\n","Loss gen 11.3458 (14.2477)\n","Loss dis 0.1284 (0.1740)\n","\n","Epoch 23/30\n","Iteration 1152/3040\n","Loss gen 14.2728 (14.2442)\n","Loss dis 0.1289 (0.1742)\n","\n","Epoch 23/30\n","Iteration 1184/3040\n","Loss gen 13.1312 (14.2303)\n","Loss dis 0.0376 (0.1731)\n","\n","Epoch 23/30\n","Iteration 1216/3040\n","Loss gen 13.5598 (14.2232)\n","Loss dis 0.0946 (0.1723)\n","\n","Epoch 23/30\n","Iteration 1248/3040\n","Loss gen 14.4097 (14.2224)\n","Loss dis 0.2004 (0.1708)\n","\n","Epoch 23/30\n","Iteration 1280/3040\n","Loss gen 13.7234 (14.2247)\n","Loss dis 0.0520 (0.1709)\n","\n","Epoch 23/30\n","Iteration 1312/3040\n","Loss gen 18.6618 (14.2271)\n","Loss dis 0.0009 (0.1692)\n","\n","Epoch 23/30\n","Iteration 1344/3040\n","Loss gen 14.5417 (14.2392)\n","Loss dis 0.4696 (0.1694)\n","\n","Epoch 23/30\n","Iteration 1376/3040\n","Loss gen 14.7178 (14.2469)\n","Loss dis 0.4163 (0.1713)\n","\n","Epoch 23/30\n","Iteration 1408/3040\n","Loss gen 12.9139 (14.2538)\n","Loss dis 0.0163 (0.1713)\n","\n","Epoch 23/30\n","Iteration 1440/3040\n","Loss gen 14.3485 (14.2512)\n","Loss dis 0.0741 (0.1693)\n","\n","Epoch 23/30\n","Iteration 1472/3040\n","Loss gen 15.0961 (14.2550)\n","Loss dis 0.0059 (0.1682)\n","\n","Epoch 23/30\n","Iteration 1504/3040\n","Loss gen 13.8921 (14.2562)\n","Loss dis 0.0701 (0.1702)\n","\n","Epoch 23/30\n","Iteration 1536/3040\n","Loss gen 14.7189 (14.2645)\n","Loss dis 0.0585 (0.1706)\n","\n","Epoch 23/30\n","Iteration 1568/3040\n","Loss gen 16.4580 (14.2659)\n","Loss dis 0.0666 (0.1696)\n","\n","Epoch 23/30\n","Iteration 1600/3040\n","Loss gen 12.4272 (14.2684)\n","Loss dis 0.0693 (0.1684)\n","\n","Epoch 23/30\n","Iteration 1632/3040\n","Loss gen 12.6887 (14.2723)\n","Loss dis 0.1190 (0.1683)\n","\n","Epoch 23/30\n","Iteration 1664/3040\n","Loss gen 13.1104 (14.2672)\n","Loss dis 0.2058 (0.1684)\n","\n","Epoch 23/30\n","Iteration 1696/3040\n","Loss gen 14.1210 (14.2669)\n","Loss dis 0.0395 (0.1674)\n","\n","Epoch 23/30\n","Iteration 1728/3040\n","Loss gen 12.9257 (14.2599)\n","Loss dis 1.6231 (0.1675)\n","\n","Epoch 23/30\n","Iteration 1760/3040\n","Loss gen 14.5196 (14.2615)\n","Loss dis 0.0094 (0.1673)\n","\n","Epoch 23/30\n","Iteration 1792/3040\n","Loss gen 13.3012 (14.2851)\n","Loss dis 0.0481 (0.1672)\n","\n","Epoch 23/30\n","Iteration 1824/3040\n","Loss gen 17.5326 (14.3018)\n","Loss dis 0.0161 (0.1669)\n","\n","Epoch 23/30\n","Iteration 1856/3040\n","Loss gen 10.0589 (14.3105)\n","Loss dis 0.3716 (0.1698)\n","\n","Epoch 23/30\n","Iteration 1888/3040\n","Loss gen 15.0020 (14.3000)\n","Loss dis 0.0189 (0.1711)\n","\n","Epoch 23/30\n","Iteration 1920/3040\n","Loss gen 13.5365 (14.2981)\n","Loss dis 0.1030 (0.1709)\n","\n","Epoch 23/30\n","Iteration 1952/3040\n","Loss gen 13.0283 (14.2895)\n","Loss dis 0.0317 (0.1720)\n","\n","Epoch 23/30\n","Iteration 1984/3040\n","Loss gen 12.5704 (14.2806)\n","Loss dis 0.2403 (0.1707)\n","\n","Epoch 23/30\n","Iteration 2016/3040\n","Loss gen 11.4232 (14.2810)\n","Loss dis 1.6235 (0.1699)\n","\n","Epoch 23/30\n","Iteration 2048/3040\n","Loss gen 14.2888 (14.2777)\n","Loss dis 0.0872 (0.1684)\n","\n","Epoch 23/30\n","Iteration 2080/3040\n","Loss gen 10.8187 (14.2770)\n","Loss dis 0.8637 (0.1675)\n","\n","Epoch 23/30\n","Iteration 2112/3040\n","Loss gen 12.6568 (14.2945)\n","Loss dis 0.0826 (0.1690)\n","\n","Epoch 23/30\n","Iteration 2144/3040\n","Loss gen 12.9238 (14.2867)\n","Loss dis 0.0118 (0.1694)\n","\n","Epoch 23/30\n","Iteration 2176/3040\n","Loss gen 10.4769 (14.2793)\n","Loss dis 0.1774 (0.1683)\n","\n","Epoch 23/30\n","Iteration 2208/3040\n","Loss gen 14.6170 (14.2754)\n","Loss dis 0.1015 (0.1678)\n","\n","Epoch 23/30\n","Iteration 2240/3040\n","Loss gen 13.1904 (14.2750)\n","Loss dis 0.0828 (0.1667)\n","\n","Epoch 23/30\n","Iteration 2272/3040\n","Loss gen 13.2487 (14.2783)\n","Loss dis 0.0113 (0.1655)\n","\n","Epoch 23/30\n","Iteration 2304/3040\n","Loss gen 14.0769 (14.2852)\n","Loss dis 0.0376 (0.1653)\n","\n","Epoch 23/30\n","Iteration 2336/3040\n","Loss gen 12.2129 (14.2879)\n","Loss dis 0.1051 (0.1649)\n","\n","Epoch 23/30\n","Iteration 2368/3040\n","Loss gen 13.3078 (14.2980)\n","Loss dis 0.1183 (0.1645)\n","\n","Epoch 23/30\n","Iteration 2400/3040\n","Loss gen 14.0521 (14.2991)\n","Loss dis 0.0304 (0.1646)\n","\n","Epoch 23/30\n","Iteration 2432/3040\n","Loss gen 11.2544 (14.2973)\n","Loss dis 0.3217 (0.1642)\n","\n","Epoch 23/30\n","Iteration 2464/3040\n","Loss gen 15.7214 (14.2976)\n","Loss dis 0.0214 (0.1639)\n","\n","Epoch 23/30\n","Iteration 2496/3040\n","Loss gen 12.8265 (14.2945)\n","Loss dis 0.0570 (0.1650)\n","\n","Epoch 23/30\n","Iteration 2528/3040\n","Loss gen 12.9507 (14.2989)\n","Loss dis 0.0139 (0.1648)\n","\n","Epoch 23/30\n","Iteration 2560/3040\n","Loss gen 16.7895 (14.3036)\n","Loss dis 0.0011 (0.1643)\n","\n","Epoch 23/30\n","Iteration 2592/3040\n","Loss gen 14.9733 (14.2963)\n","Loss dis 0.0050 (0.1644)\n","\n","Epoch 23/30\n","Iteration 2624/3040\n","Loss gen 11.9501 (14.3034)\n","Loss dis 0.6499 (0.1659)\n","\n","Epoch 23/30\n","Iteration 2656/3040\n","Loss gen 16.1933 (14.2936)\n","Loss dis 0.0261 (0.1670)\n","\n","Epoch 23/30\n","Iteration 2688/3040\n","Loss gen 14.6151 (14.3036)\n","Loss dis 0.0093 (0.1670)\n","\n","Epoch 23/30\n","Iteration 2720/3040\n","Loss gen 13.9221 (14.3059)\n","Loss dis 0.0124 (0.1676)\n","\n","Epoch 23/30\n","Iteration 2752/3040\n","Loss gen 17.4985 (14.3046)\n","Loss dis 0.0284 (0.1673)\n","\n","Epoch 23/30\n","Iteration 2784/3040\n","Loss gen 12.5429 (14.2979)\n","Loss dis 0.2703 (0.1682)\n","\n","Epoch 23/30\n","Iteration 2816/3040\n","Loss gen 15.6951 (14.2930)\n","Loss dis 0.0224 (0.1676)\n","\n","Epoch 23/30\n","Iteration 2848/3040\n","Loss gen 11.3795 (14.2876)\n","Loss dis 0.0304 (0.1670)\n","\n","Epoch 23/30\n","Iteration 2880/3040\n","Loss gen 15.5778 (14.2850)\n","Loss dis 0.3174 (0.1663)\n","\n","Epoch 23/30\n","Iteration 2912/3040\n","Loss gen 16.3838 (14.2808)\n","Loss dis 0.5362 (0.1671)\n","\n","Epoch 23/30\n","Iteration 2944/3040\n","Loss gen 9.3015 (14.2735)\n","Loss dis 0.4235 (0.1677)\n","\n","Epoch 23/30\n","Iteration 2976/3040\n","Loss gen 15.1243 (14.2771)\n","Loss dis 0.1992 (0.1682)\n","\n","Epoch 23/30\n","Iteration 3008/3040\n","Loss gen 11.0753 (14.2838)\n","Loss dis 0.3769 (0.1673)\n","\n","Epoch 23/30\n","Iteration 3040/3040\n","Loss gen 14.4911 (14.2824)\n","Loss dis 0.0112 (0.1675)\n","\n","Epoch 24/30\n","Iteration 32/3040\n","Loss gen 15.8735 (13.7699)\n","Loss dis 0.0067 (0.1220)\n","\n","Epoch 24/30\n","Iteration 64/3040\n","Loss gen 12.5434 (13.7507)\n","Loss dis 0.0247 (0.1285)\n","\n","Epoch 24/30\n","Iteration 96/3040\n","Loss gen 16.8598 (13.7644)\n","Loss dis 0.0007 (0.1157)\n","\n","Epoch 24/30\n","Iteration 128/3040\n","Loss gen 12.7092 (13.8613)\n","Loss dis 0.2749 (0.1303)\n","\n","Epoch 24/30\n","Iteration 160/3040\n","Loss gen 14.7325 (13.8720)\n","Loss dis 0.0093 (0.1190)\n","\n","Epoch 24/30\n","Iteration 192/3040\n","Loss gen 14.0064 (13.9448)\n","Loss dis 0.0155 (0.1237)\n","\n","Epoch 24/30\n","Iteration 224/3040\n","Loss gen 13.7538 (14.0445)\n","Loss dis 0.2124 (0.1252)\n","\n","Epoch 24/30\n","Iteration 256/3040\n","Loss gen 15.5303 (14.0956)\n","Loss dis 0.0082 (0.1232)\n","\n","Epoch 24/30\n","Iteration 288/3040\n","Loss gen 12.8506 (14.1307)\n","Loss dis 0.0783 (0.1176)\n","\n","Epoch 24/30\n","Iteration 320/3040\n","Loss gen 18.7123 (14.1724)\n","Loss dis 0.0263 (0.1289)\n","\n","Epoch 24/30\n","Iteration 352/3040\n","Loss gen 14.1571 (14.1833)\n","Loss dis 0.0659 (0.1268)\n","\n","Epoch 24/30\n","Iteration 384/3040\n","Loss gen 14.0550 (14.2151)\n","Loss dis 0.0660 (0.1234)\n","\n","Epoch 24/30\n","Iteration 416/3040\n","Loss gen 15.8593 (14.3147)\n","Loss dis 0.1253 (0.1357)\n","\n","Epoch 24/30\n","Iteration 448/3040\n","Loss gen 14.4745 (14.4074)\n","Loss dis 0.0029 (0.1368)\n","\n","Epoch 24/30\n","Iteration 480/3040\n","Loss gen 17.3577 (14.4641)\n","Loss dis 0.0018 (0.1417)\n","\n","Epoch 24/30\n","Iteration 512/3040\n","Loss gen 14.2698 (14.4806)\n","Loss dis 0.0533 (0.1408)\n","\n","Epoch 24/30\n","Iteration 544/3040\n","Loss gen 13.6927 (14.4855)\n","Loss dis 0.0291 (0.1528)\n","\n","Epoch 24/30\n","Iteration 576/3040\n","Loss gen 13.1263 (14.4494)\n","Loss dis 0.0720 (0.1529)\n","\n","Epoch 24/30\n","Iteration 608/3040\n","Loss gen 12.5381 (14.4338)\n","Loss dis 0.0268 (0.1528)\n","\n","Epoch 24/30\n","Iteration 640/3040\n","Loss gen 12.6308 (14.4047)\n","Loss dis 0.0478 (0.1576)\n","\n","Epoch 24/30\n","Iteration 672/3040\n","Loss gen 12.4651 (14.3868)\n","Loss dis 0.1824 (0.1578)\n","\n","Epoch 24/30\n","Iteration 704/3040\n","Loss gen 13.6141 (14.3478)\n","Loss dis 0.0119 (0.1591)\n","\n","Epoch 24/30\n","Iteration 736/3040\n","Loss gen 14.6452 (14.3284)\n","Loss dis 0.0160 (0.1580)\n","\n","Epoch 24/30\n","Iteration 768/3040\n","Loss gen 14.5801 (14.3218)\n","Loss dis 0.0206 (0.1587)\n","\n","Epoch 24/30\n","Iteration 800/3040\n","Loss gen 15.6707 (14.3383)\n","Loss dis 0.0238 (0.1618)\n","\n","Epoch 24/30\n","Iteration 832/3040\n","Loss gen 14.5446 (14.3620)\n","Loss dis 0.0302 (0.1585)\n","\n","Epoch 24/30\n","Iteration 864/3040\n","Loss gen 13.1222 (14.3602)\n","Loss dis 0.0880 (0.1549)\n","\n","Epoch 24/30\n","Iteration 896/3040\n","Loss gen 15.1988 (14.3693)\n","Loss dis 0.1007 (0.1642)\n","\n","Epoch 24/30\n","Iteration 928/3040\n","Loss gen 10.8994 (14.3448)\n","Loss dis 0.7264 (0.1667)\n","\n","Epoch 24/30\n","Iteration 960/3040\n","Loss gen 15.2725 (14.3257)\n","Loss dis 0.0144 (0.1707)\n","\n","Epoch 24/30\n","Iteration 992/3040\n","Loss gen 15.2678 (14.2929)\n","Loss dis 0.4819 (0.1706)\n","\n","Epoch 24/30\n","Iteration 1024/3040\n","Loss gen 13.1711 (14.2799)\n","Loss dis 0.0259 (0.1684)\n","\n","Epoch 24/30\n","Iteration 1056/3040\n","Loss gen 13.1809 (14.2438)\n","Loss dis 0.0662 (0.1690)\n","\n","Epoch 24/30\n","Iteration 1088/3040\n","Loss gen 15.1032 (14.2393)\n","Loss dis 0.0146 (0.1707)\n","\n","Epoch 24/30\n","Iteration 1120/3040\n","Loss gen 14.0653 (14.2457)\n","Loss dis 0.0081 (0.1699)\n","\n","Epoch 24/30\n","Iteration 1152/3040\n","Loss gen 15.2721 (14.2340)\n","Loss dis 0.3235 (0.1713)\n","\n","Epoch 24/30\n","Iteration 1184/3040\n","Loss gen 14.6825 (14.2214)\n","Loss dis 0.0926 (0.1718)\n","\n","Epoch 24/30\n","Iteration 1216/3040\n","Loss gen 13.8847 (14.2161)\n","Loss dis 0.0117 (0.1714)\n","\n","Epoch 24/30\n","Iteration 1248/3040\n","Loss gen 15.0430 (14.2105)\n","Loss dis 0.0091 (0.1692)\n","\n","Epoch 24/30\n","Iteration 1280/3040\n","Loss gen 15.2816 (14.2018)\n","Loss dis 0.1571 (0.1680)\n","\n","Epoch 24/30\n","Iteration 1312/3040\n","Loss gen 15.2764 (14.1970)\n","Loss dis 0.0022 (0.1679)\n","\n","Epoch 24/30\n","Iteration 1344/3040\n","Loss gen 12.0396 (14.1781)\n","Loss dis 0.1355 (0.1674)\n","\n","Epoch 24/30\n","Iteration 1376/3040\n","Loss gen 15.9295 (14.1920)\n","Loss dis 0.0042 (0.1660)\n","\n","Epoch 24/30\n","Iteration 1408/3040\n","Loss gen 13.9056 (14.2014)\n","Loss dis 0.0927 (0.1657)\n","\n","Epoch 24/30\n","Iteration 1440/3040\n","Loss gen 15.8571 (14.2192)\n","Loss dis 0.0690 (0.1672)\n","\n","Epoch 24/30\n","Iteration 1472/3040\n","Loss gen 13.8354 (14.2178)\n","Loss dis 0.0309 (0.1690)\n","\n","Epoch 24/30\n","Iteration 1504/3040\n","Loss gen 12.7985 (14.2056)\n","Loss dis 0.1049 (0.1693)\n","\n","Epoch 24/30\n","Iteration 1536/3040\n","Loss gen 15.1995 (14.2018)\n","Loss dis 0.0038 (0.1674)\n","\n","Epoch 24/30\n","Iteration 1568/3040\n","Loss gen 13.4872 (14.2053)\n","Loss dis 0.2568 (0.1660)\n","\n","Epoch 24/30\n","Iteration 1600/3040\n","Loss gen 10.2245 (14.1913)\n","Loss dis 0.5211 (0.1675)\n","\n","Epoch 24/30\n","Iteration 1632/3040\n","Loss gen 14.9852 (14.1927)\n","Loss dis 0.0138 (0.1686)\n","\n","Epoch 24/30\n","Iteration 1664/3040\n","Loss gen 14.4616 (14.1856)\n","Loss dis 0.1046 (0.1674)\n","\n","Epoch 24/30\n","Iteration 1696/3040\n","Loss gen 12.3689 (14.1864)\n","Loss dis 0.0827 (0.1666)\n","\n","Epoch 24/30\n","Iteration 1728/3040\n","Loss gen 16.3832 (14.1842)\n","Loss dis 0.9032 (0.1667)\n","\n","Epoch 24/30\n","Iteration 1760/3040\n","Loss gen 14.3631 (14.1769)\n","Loss dis 0.2322 (0.1669)\n","\n","Epoch 24/30\n","Iteration 1792/3040\n","Loss gen 13.6324 (14.1707)\n","Loss dis 0.0748 (0.1695)\n","\n","Epoch 24/30\n","Iteration 1824/3040\n","Loss gen 11.6392 (14.1677)\n","Loss dis 0.2043 (0.1682)\n","\n","Epoch 24/30\n","Iteration 1856/3040\n","Loss gen 15.0042 (14.1542)\n","Loss dis 0.0316 (0.1689)\n","\n","Epoch 24/30\n","Iteration 1888/3040\n","Loss gen 13.4477 (14.1492)\n","Loss dis 0.0114 (0.1678)\n","\n","Epoch 24/30\n","Iteration 1920/3040\n","Loss gen 13.5075 (14.1569)\n","Loss dis 0.3726 (0.1689)\n","\n","Epoch 24/30\n","Iteration 1952/3040\n","Loss gen 15.6230 (14.1557)\n","Loss dis 0.0027 (0.1703)\n","\n","Epoch 24/30\n","Iteration 1984/3040\n","Loss gen 11.3691 (14.1539)\n","Loss dis 0.4712 (0.1692)\n","\n","Epoch 24/30\n","Iteration 2016/3040\n","Loss gen 13.7577 (14.1529)\n","Loss dis 0.3358 (0.1699)\n","\n","Epoch 24/30\n","Iteration 2048/3040\n","Loss gen 14.5903 (14.1417)\n","Loss dis 0.2538 (0.1697)\n","\n","Epoch 24/30\n","Iteration 2080/3040\n","Loss gen 12.9292 (14.1521)\n","Loss dis 0.0893 (0.1676)\n","\n","Epoch 24/30\n","Iteration 2112/3040\n","Loss gen 9.2954 (14.1638)\n","Loss dis 0.9192 (0.1676)\n","\n","Epoch 24/30\n","Iteration 2144/3040\n","Loss gen 17.5472 (14.1703)\n","Loss dis 0.0009 (0.1682)\n","\n","Epoch 24/30\n","Iteration 2176/3040\n","Loss gen 14.6883 (14.1637)\n","Loss dis 0.8885 (0.1679)\n","\n","Epoch 24/30\n","Iteration 2208/3040\n","Loss gen 14.1706 (14.1636)\n","Loss dis 0.0294 (0.1674)\n","\n","Epoch 24/30\n","Iteration 2240/3040\n","Loss gen 13.8499 (14.1660)\n","Loss dis 0.0278 (0.1677)\n","\n","Epoch 24/30\n","Iteration 2272/3040\n","Loss gen 12.6408 (14.1686)\n","Loss dis 0.0692 (0.1671)\n","\n","Epoch 24/30\n","Iteration 2304/3040\n","Loss gen 12.5772 (14.1798)\n","Loss dis 0.0594 (0.1668)\n","\n","Epoch 24/30\n","Iteration 2336/3040\n","Loss gen 10.0609 (14.1803)\n","Loss dis 0.9016 (0.1673)\n","\n","Epoch 24/30\n","Iteration 2368/3040\n","Loss gen 11.9561 (14.1747)\n","Loss dis 0.3604 (0.1681)\n","\n","Epoch 24/30\n","Iteration 2400/3040\n","Loss gen 13.5093 (14.1776)\n","Loss dis 0.1592 (0.1673)\n","\n","Epoch 24/30\n","Iteration 2432/3040\n","Loss gen 14.9138 (14.1814)\n","Loss dis 0.0067 (0.1667)\n","\n","Epoch 24/30\n","Iteration 2464/3040\n","Loss gen 14.8378 (14.1837)\n","Loss dis 0.1831 (0.1667)\n","\n","Epoch 24/30\n","Iteration 2496/3040\n","Loss gen 18.1253 (14.1861)\n","Loss dis 0.0149 (0.1667)\n","\n","Epoch 24/30\n","Iteration 2528/3040\n","Loss gen 12.7247 (14.1819)\n","Loss dis 0.0917 (0.1662)\n","\n","Epoch 24/30\n","Iteration 2560/3040\n","Loss gen 13.5207 (14.1866)\n","Loss dis 0.0217 (0.1672)\n","\n","Epoch 24/30\n","Iteration 2592/3040\n","Loss gen 16.3942 (14.1794)\n","Loss dis 0.0065 (0.1661)\n","\n","Epoch 24/30\n","Iteration 2624/3040\n","Loss gen 14.8147 (14.1840)\n","Loss dis 0.0242 (0.1657)\n","\n","Epoch 24/30\n","Iteration 2656/3040\n","Loss gen 15.2282 (14.1865)\n","Loss dis 0.0125 (0.1644)\n","\n","Epoch 24/30\n","Iteration 2688/3040\n","Loss gen 13.8794 (14.2045)\n","Loss dis 0.0123 (0.1629)\n","\n","Epoch 24/30\n","Iteration 2720/3040\n","Loss gen 16.0883 (14.2168)\n","Loss dis 0.9770 (0.1630)\n","\n","Epoch 24/30\n","Iteration 2752/3040\n","Loss gen 16.0839 (14.2108)\n","Loss dis 0.0100 (0.1640)\n","\n","Epoch 24/30\n","Iteration 2784/3040\n","Loss gen 13.5527 (14.2180)\n","Loss dis 0.4048 (0.1657)\n","\n","Epoch 24/30\n","Iteration 2816/3040\n","Loss gen 15.2601 (14.2129)\n","Loss dis 0.0309 (0.1664)\n","\n","Epoch 24/30\n","Iteration 2848/3040\n","Loss gen 12.3321 (14.2178)\n","Loss dis 0.1958 (0.1657)\n","\n","Epoch 24/30\n","Iteration 2880/3040\n","Loss gen 14.8864 (14.2163)\n","Loss dis 0.0139 (0.1654)\n","\n","Epoch 24/30\n","Iteration 2912/3040\n","Loss gen 12.1627 (14.2148)\n","Loss dis 0.5288 (0.1660)\n","\n","Epoch 24/30\n","Iteration 2944/3040\n","Loss gen 11.6860 (14.2128)\n","Loss dis 0.0490 (0.1652)\n","\n","Epoch 24/30\n","Iteration 2976/3040\n","Loss gen 14.6160 (14.2123)\n","Loss dis 0.0410 (0.1668)\n","\n","Epoch 24/30\n","Iteration 3008/3040\n","Loss gen 18.4393 (14.2151)\n","Loss dis 0.0051 (0.1668)\n","\n","Epoch 24/30\n","Iteration 3040/3040\n","Loss gen 16.7386 (14.2206)\n","Loss dis 0.0033 (0.1673)\n","\n","Epoch 25/30\n","Iteration 32/3040\n","Loss gen 15.8528 (14.3307)\n","Loss dis 0.0095 (0.1916)\n","\n","Epoch 25/30\n","Iteration 64/3040\n","Loss gen 18.3122 (14.0924)\n","Loss dis 0.1974 (0.2554)\n","\n","Epoch 25/30\n","Iteration 96/3040\n","Loss gen 14.3896 (14.2469)\n","Loss dis 0.0115 (0.2134)\n","\n","Epoch 25/30\n","Iteration 128/3040\n","Loss gen 10.8210 (14.2248)\n","Loss dis 0.3405 (0.2100)\n","\n","Epoch 25/30\n","Iteration 160/3040\n","Loss gen 14.5462 (14.2635)\n","Loss dis 0.0316 (0.1955)\n","\n","Epoch 25/30\n","Iteration 192/3040\n","Loss gen 12.7273 (14.1674)\n","Loss dis 0.0209 (0.1870)\n","\n","Epoch 25/30\n","Iteration 224/3040\n","Loss gen 12.3868 (14.0427)\n","Loss dis 0.1005 (0.1834)\n","\n","Epoch 25/30\n","Iteration 256/3040\n","Loss gen 12.6433 (14.0637)\n","Loss dis 0.3165 (0.1742)\n","\n","Epoch 25/30\n","Iteration 288/3040\n","Loss gen 13.8196 (14.0666)\n","Loss dis 0.0200 (0.1651)\n","\n","Epoch 25/30\n","Iteration 320/3040\n","Loss gen 16.3803 (14.1012)\n","Loss dis 0.0111 (0.1626)\n","\n","Epoch 25/30\n","Iteration 352/3040\n","Loss gen 11.4976 (14.1303)\n","Loss dis 0.1484 (0.1615)\n","\n","Epoch 25/30\n","Iteration 384/3040\n","Loss gen 13.5251 (14.1369)\n","Loss dis 0.0716 (0.1591)\n","\n","Epoch 25/30\n","Iteration 416/3040\n","Loss gen 16.4194 (14.1457)\n","Loss dis 0.0083 (0.1534)\n","\n","Epoch 25/30\n","Iteration 448/3040\n","Loss gen 14.4790 (14.1849)\n","Loss dis 0.0077 (0.1506)\n","\n","Epoch 25/30\n","Iteration 480/3040\n","Loss gen 15.8652 (14.2010)\n","Loss dis 0.0106 (0.1543)\n","\n","Epoch 25/30\n","Iteration 512/3040\n","Loss gen 13.6433 (14.2702)\n","Loss dis 0.5044 (0.1630)\n","\n","Epoch 25/30\n","Iteration 544/3040\n","Loss gen 10.7124 (14.2660)\n","Loss dis 0.2703 (0.1637)\n","\n","Epoch 25/30\n","Iteration 576/3040\n","Loss gen 11.6106 (14.2694)\n","Loss dis 0.3759 (0.1614)\n","\n","Epoch 25/30\n","Iteration 608/3040\n","Loss gen 13.3931 (14.2426)\n","Loss dis 0.0310 (0.1586)\n","\n","Epoch 25/30\n","Iteration 640/3040\n","Loss gen 13.0153 (14.2333)\n","Loss dis 0.1394 (0.1558)\n","\n","Epoch 25/30\n","Iteration 672/3040\n","Loss gen 14.3204 (14.2564)\n","Loss dis 0.0227 (0.1566)\n","\n","Epoch 25/30\n","Iteration 704/3040\n","Loss gen 13.5501 (14.2394)\n","Loss dis 0.0046 (0.1577)\n","\n","Epoch 25/30\n","Iteration 736/3040\n","Loss gen 16.1593 (14.2304)\n","Loss dis 0.1729 (0.1578)\n","\n","Epoch 25/30\n","Iteration 768/3040\n","Loss gen 14.1913 (14.2625)\n","Loss dis 0.0487 (0.1570)\n","\n","Epoch 25/30\n","Iteration 800/3040\n","Loss gen 13.1093 (14.2622)\n","Loss dis 0.1550 (0.1553)\n","\n","Epoch 25/30\n","Iteration 832/3040\n","Loss gen 14.0336 (14.2649)\n","Loss dis 0.2674 (0.1539)\n","\n","Epoch 25/30\n","Iteration 864/3040\n","Loss gen 11.5144 (14.2526)\n","Loss dis 0.0190 (0.1535)\n","\n","Epoch 25/30\n","Iteration 896/3040\n","Loss gen 21.8049 (14.2446)\n","Loss dis 0.0063 (0.1574)\n","\n","Epoch 25/30\n","Iteration 928/3040\n","Loss gen 12.7376 (14.2454)\n","Loss dis 0.2599 (0.1611)\n","\n","Epoch 25/30\n","Iteration 960/3040\n","Loss gen 13.8400 (14.2345)\n","Loss dis 0.0135 (0.1592)\n","\n","Epoch 25/30\n","Iteration 992/3040\n","Loss gen 17.5591 (14.2302)\n","Loss dis 0.5459 (0.1612)\n","\n","Epoch 25/30\n","Iteration 1024/3040\n","Loss gen 17.5763 (14.2493)\n","Loss dis 0.1163 (0.1593)\n","\n","Epoch 25/30\n","Iteration 1056/3040\n","Loss gen 14.0744 (14.2508)\n","Loss dis 0.0327 (0.1622)\n","\n","Epoch 25/30\n","Iteration 1088/3040\n","Loss gen 15.1419 (14.2389)\n","Loss dis 0.0496 (0.1619)\n","\n","Epoch 25/30\n","Iteration 1120/3040\n","Loss gen 13.3753 (14.2645)\n","Loss dis 0.0184 (0.1621)\n","\n","Epoch 25/30\n","Iteration 1152/3040\n","Loss gen 12.2159 (14.2534)\n","Loss dis 0.2268 (0.1618)\n","\n","Epoch 25/30\n","Iteration 1184/3040\n","Loss gen 13.4842 (14.2340)\n","Loss dis 0.0705 (0.1623)\n","\n","Epoch 25/30\n","Iteration 1216/3040\n","Loss gen 11.1618 (14.2239)\n","Loss dis 0.4291 (0.1617)\n","\n","Epoch 25/30\n","Iteration 1248/3040\n","Loss gen 13.7064 (14.2222)\n","Loss dis 0.0125 (0.1604)\n","\n","Epoch 25/30\n","Iteration 1280/3040\n","Loss gen 15.1636 (14.2157)\n","Loss dis 0.0301 (0.1594)\n","\n","Epoch 25/30\n","Iteration 1312/3040\n","Loss gen 14.9258 (14.2138)\n","Loss dis 0.0608 (0.1588)\n","\n","Epoch 25/30\n","Iteration 1344/3040\n","Loss gen 11.9640 (14.1971)\n","Loss dis 0.0633 (0.1573)\n","\n","Epoch 25/30\n","Iteration 1376/3040\n","Loss gen 14.6268 (14.2037)\n","Loss dis 0.0206 (0.1567)\n","\n","Epoch 25/30\n","Iteration 1408/3040\n","Loss gen 16.8904 (14.2204)\n","Loss dis 0.0330 (0.1566)\n","\n","Epoch 25/30\n","Iteration 1440/3040\n","Loss gen 16.6469 (14.2235)\n","Loss dis 0.0036 (0.1599)\n","\n","Epoch 25/30\n","Iteration 1472/3040\n","Loss gen 12.0683 (14.2141)\n","Loss dis 0.4124 (0.1617)\n","\n","Epoch 25/30\n","Iteration 1504/3040\n","Loss gen 14.7578 (14.2070)\n","Loss dis 0.0164 (0.1631)\n","\n","Epoch 25/30\n","Iteration 1536/3040\n","Loss gen 14.0129 (14.2024)\n","Loss dis 0.0088 (0.1645)\n","\n","Epoch 25/30\n","Iteration 1568/3040\n","Loss gen 16.6495 (14.2051)\n","Loss dis 0.0298 (0.1638)\n","\n","Epoch 25/30\n","Iteration 1600/3040\n","Loss gen 10.9879 (14.1977)\n","Loss dis 0.1144 (0.1643)\n","\n","Epoch 25/30\n","Iteration 1632/3040\n","Loss gen 13.9540 (14.2076)\n","Loss dis 0.0094 (0.1632)\n","\n","Epoch 25/30\n","Iteration 1664/3040\n","Loss gen 15.0266 (14.1936)\n","Loss dis 0.1942 (0.1652)\n","\n","Epoch 25/30\n","Iteration 1696/3040\n","Loss gen 12.6119 (14.1865)\n","Loss dis 0.0837 (0.1639)\n","\n","Epoch 25/30\n","Iteration 1728/3040\n","Loss gen 15.3409 (14.1850)\n","Loss dis 0.0024 (0.1629)\n","\n","Epoch 25/30\n","Iteration 1760/3040\n","Loss gen 16.5533 (14.1801)\n","Loss dis 0.0278 (0.1646)\n","\n","Epoch 25/30\n","Iteration 1792/3040\n","Loss gen 14.4033 (14.1655)\n","Loss dis 0.0705 (0.1645)\n","\n","Epoch 25/30\n","Iteration 1824/3040\n","Loss gen 12.8868 (14.1676)\n","Loss dis 0.1713 (0.1635)\n","\n","Epoch 25/30\n","Iteration 1856/3040\n","Loss gen 15.1310 (14.1619)\n","Loss dis 0.2210 (0.1632)\n","\n","Epoch 25/30\n","Iteration 1888/3040\n","Loss gen 11.7630 (14.1544)\n","Loss dis 0.1016 (0.1636)\n","\n","Epoch 25/30\n","Iteration 1920/3040\n","Loss gen 20.7667 (14.1658)\n","Loss dis 0.1742 (0.1641)\n","\n","Epoch 25/30\n","Iteration 1952/3040\n","Loss gen 17.7259 (14.1686)\n","Loss dis 0.0011 (0.1657)\n","\n","Epoch 25/30\n","Iteration 1984/3040\n","Loss gen 12.3587 (14.1588)\n","Loss dis 0.0990 (0.1664)\n","\n","Epoch 25/30\n","Iteration 2016/3040\n","Loss gen 13.5685 (14.1525)\n","Loss dis 0.1045 (0.1654)\n","\n","Epoch 25/30\n","Iteration 2048/3040\n","Loss gen 12.4107 (14.1436)\n","Loss dis 0.0302 (0.1660)\n","\n","Epoch 25/30\n","Iteration 2080/3040\n","Loss gen 13.5176 (14.1404)\n","Loss dis 0.0758 (0.1655)\n","\n","Epoch 25/30\n","Iteration 2112/3040\n","Loss gen 13.0668 (14.1428)\n","Loss dis 0.0147 (0.1645)\n","\n","Epoch 25/30\n","Iteration 2144/3040\n","Loss gen 14.4466 (14.1487)\n","Loss dis 0.2769 (0.1659)\n","\n","Epoch 25/30\n","Iteration 2176/3040\n","Loss gen 14.7527 (14.1553)\n","Loss dis 0.8749 (0.1664)\n","\n","Epoch 25/30\n","Iteration 2208/3040\n","Loss gen 17.3636 (14.1490)\n","Loss dis 0.0041 (0.1668)\n","\n","Epoch 25/30\n","Iteration 2240/3040\n","Loss gen 14.9703 (14.1483)\n","Loss dis 0.0138 (0.1654)\n","\n","Epoch 25/30\n","Iteration 2272/3040\n","Loss gen 12.9628 (14.1507)\n","Loss dis 0.0448 (0.1644)\n","\n","Epoch 25/30\n","Iteration 2304/3040\n","Loss gen 14.2466 (14.1553)\n","Loss dis 0.0815 (0.1629)\n","\n","Epoch 25/30\n","Iteration 2336/3040\n","Loss gen 8.0418 (14.1623)\n","Loss dis 1.0142 (0.1632)\n","\n","Epoch 25/30\n","Iteration 2368/3040\n","Loss gen 12.0995 (14.1734)\n","Loss dis 0.1228 (0.1637)\n","\n","Epoch 25/30\n","Iteration 2400/3040\n","Loss gen 13.4908 (14.1712)\n","Loss dis 0.1230 (0.1629)\n","\n","Epoch 25/30\n","Iteration 2432/3040\n","Loss gen 13.0314 (14.1684)\n","Loss dis 0.0157 (0.1623)\n","\n","Epoch 25/30\n","Iteration 2464/3040\n","Loss gen 14.3091 (14.1678)\n","Loss dis 0.0230 (0.1638)\n","\n","Epoch 25/30\n","Iteration 2496/3040\n","Loss gen 16.2952 (14.1624)\n","Loss dis 0.0044 (0.1641)\n","\n","Epoch 25/30\n","Iteration 2528/3040\n","Loss gen 16.3453 (14.1711)\n","Loss dis 0.0285 (0.1629)\n","\n","Epoch 25/30\n","Iteration 2560/3040\n","Loss gen 14.4952 (14.1762)\n","Loss dis 0.0189 (0.1618)\n","\n","Epoch 25/30\n","Iteration 2592/3040\n","Loss gen 12.8878 (14.1758)\n","Loss dis 0.0619 (0.1630)\n","\n","Epoch 25/30\n","Iteration 2624/3040\n","Loss gen 9.5018 (14.1779)\n","Loss dis 0.4208 (0.1627)\n","\n","Epoch 25/30\n","Iteration 2656/3040\n","Loss gen 15.4679 (14.1714)\n","Loss dis 0.0009 (0.1631)\n","\n","Epoch 25/30\n","Iteration 2688/3040\n","Loss gen 13.0363 (14.1668)\n","Loss dis 0.1309 (0.1622)\n","\n","Epoch 25/30\n","Iteration 2720/3040\n","Loss gen 14.1511 (14.1604)\n","Loss dis 0.0605 (0.1624)\n","\n","Epoch 25/30\n","Iteration 2752/3040\n","Loss gen 13.9757 (14.1556)\n","Loss dis 0.0194 (0.1621)\n","\n","Epoch 25/30\n","Iteration 2784/3040\n","Loss gen 14.6352 (14.1535)\n","Loss dis 0.1099 (0.1629)\n","\n","Epoch 25/30\n","Iteration 2816/3040\n","Loss gen 18.0921 (14.1509)\n","Loss dis 0.0020 (0.1632)\n","\n","Epoch 25/30\n","Iteration 2848/3040\n","Loss gen 13.2864 (14.1520)\n","Loss dis 0.0056 (0.1636)\n","\n","Epoch 25/30\n","Iteration 2880/3040\n","Loss gen 18.8680 (14.1630)\n","Loss dis 0.0014 (0.1634)\n","\n","Epoch 25/30\n","Iteration 2912/3040\n","Loss gen 14.7657 (14.1660)\n","Loss dis 0.2597 (0.1641)\n","\n","Epoch 25/30\n","Iteration 2944/3040\n","Loss gen 9.1351 (14.1649)\n","Loss dis 0.5322 (0.1656)\n","\n","Epoch 25/30\n","Iteration 2976/3040\n","Loss gen 14.4023 (14.1651)\n","Loss dis 0.0357 (0.1652)\n","\n","Epoch 25/30\n","Iteration 3008/3040\n","Loss gen 11.8127 (14.1722)\n","Loss dis 0.1017 (0.1645)\n","\n","Epoch 25/30\n","Iteration 3040/3040\n","Loss gen 17.6793 (14.1715)\n","Loss dis 0.0273 (0.1650)\n","\n","Epoch 26/30\n","Iteration 32/3040\n","Loss gen 16.8798 (13.6840)\n","Loss dis 0.0018 (0.1624)\n","\n","Epoch 26/30\n","Iteration 64/3040\n","Loss gen 13.9314 (13.6629)\n","Loss dis 0.0293 (0.1538)\n","\n","Epoch 26/30\n","Iteration 96/3040\n","Loss gen 15.0395 (13.8383)\n","Loss dis 0.0114 (0.1301)\n","\n","Epoch 26/30\n","Iteration 128/3040\n","Loss gen 13.0070 (13.8289)\n","Loss dis 0.0368 (0.1275)\n","\n","Epoch 26/30\n","Iteration 160/3040\n","Loss gen 13.4602 (13.9278)\n","Loss dis 1.1127 (0.1242)\n","\n","Epoch 26/30\n","Iteration 192/3040\n","Loss gen 9.9672 (13.9068)\n","Loss dis 0.8104 (0.1288)\n","\n","Epoch 26/30\n","Iteration 224/3040\n","Loss gen 10.8168 (13.9523)\n","Loss dis 1.1974 (0.1433)\n","\n","Epoch 26/30\n","Iteration 256/3040\n","Loss gen 12.3107 (14.0295)\n","Loss dis 0.0926 (0.1457)\n","\n","Epoch 26/30\n","Iteration 288/3040\n","Loss gen 14.9533 (14.0291)\n","Loss dis 0.0087 (0.1476)\n","\n","Epoch 26/30\n","Iteration 320/3040\n","Loss gen 16.5323 (14.1010)\n","Loss dis 0.1257 (0.1500)\n","\n","Epoch 26/30\n","Iteration 352/3040\n","Loss gen 11.0752 (14.1170)\n","Loss dis 0.0536 (0.1510)\n","\n","Epoch 26/30\n","Iteration 384/3040\n","Loss gen 13.3071 (14.1420)\n","Loss dis 0.4829 (0.1571)\n","\n","Epoch 26/30\n","Iteration 416/3040\n","Loss gen 13.1273 (14.1100)\n","Loss dis 0.0305 (0.1604)\n","\n","Epoch 26/30\n","Iteration 448/3040\n","Loss gen 11.9118 (14.1153)\n","Loss dis 1.2602 (0.1695)\n","\n","Epoch 26/30\n","Iteration 480/3040\n","Loss gen 16.2711 (14.1351)\n","Loss dis 0.0053 (0.1648)\n","\n","Epoch 26/30\n","Iteration 512/3040\n","Loss gen 10.4122 (14.1560)\n","Loss dis 0.3651 (0.1679)\n","\n","Epoch 26/30\n","Iteration 544/3040\n","Loss gen 10.0015 (14.1230)\n","Loss dis 0.9194 (0.1687)\n","\n","Epoch 26/30\n","Iteration 576/3040\n","Loss gen 11.4590 (14.0831)\n","Loss dis 0.1387 (0.1661)\n","\n","Epoch 26/30\n","Iteration 608/3040\n","Loss gen 15.2323 (14.0486)\n","Loss dis 0.0894 (0.1680)\n","\n","Epoch 26/30\n","Iteration 640/3040\n","Loss gen 11.4986 (14.0385)\n","Loss dis 0.0994 (0.1660)\n","\n","Epoch 26/30\n","Iteration 672/3040\n","Loss gen 14.3400 (14.0221)\n","Loss dis 0.0761 (0.1652)\n","\n","Epoch 26/30\n","Iteration 704/3040\n","Loss gen 13.8691 (13.9950)\n","Loss dis 0.0242 (0.1612)\n","\n","Epoch 26/30\n","Iteration 736/3040\n","Loss gen 14.0546 (13.9656)\n","Loss dis 0.0171 (0.1577)\n","\n","Epoch 26/30\n","Iteration 768/3040\n","Loss gen 12.5225 (13.9801)\n","Loss dis 0.0891 (0.1588)\n","\n","Epoch 26/30\n","Iteration 800/3040\n","Loss gen 11.8836 (13.9761)\n","Loss dis 0.6134 (0.1570)\n","\n","Epoch 26/30\n","Iteration 832/3040\n","Loss gen 18.8450 (14.0239)\n","Loss dis 0.4206 (0.1603)\n","\n","Epoch 26/30\n","Iteration 864/3040\n","Loss gen 11.9771 (14.0524)\n","Loss dis 0.0146 (0.1597)\n","\n","Epoch 26/30\n","Iteration 896/3040\n","Loss gen 12.1948 (14.0316)\n","Loss dis 0.0375 (0.1584)\n","\n","Epoch 26/30\n","Iteration 928/3040\n","Loss gen 12.8371 (14.0102)\n","Loss dis 0.0864 (0.1609)\n","\n","Epoch 26/30\n","Iteration 960/3040\n","Loss gen 14.3967 (14.0135)\n","Loss dis 0.0250 (0.1599)\n","\n","Epoch 26/30\n","Iteration 992/3040\n","Loss gen 16.3059 (14.0098)\n","Loss dis 0.1526 (0.1593)\n","\n","Epoch 26/30\n","Iteration 1024/3040\n","Loss gen 13.6666 (14.0187)\n","Loss dis 0.0288 (0.1619)\n","\n","Epoch 26/30\n","Iteration 1056/3040\n","Loss gen 11.2831 (14.0128)\n","Loss dis 0.5615 (0.1600)\n","\n","Epoch 26/30\n","Iteration 1088/3040\n","Loss gen 15.2054 (14.0082)\n","Loss dis 0.0427 (0.1593)\n","\n","Epoch 26/30\n","Iteration 1120/3040\n","Loss gen 12.0569 (14.0037)\n","Loss dis 0.0244 (0.1598)\n","\n","Epoch 26/30\n","Iteration 1152/3040\n","Loss gen 13.9412 (13.9975)\n","Loss dis 0.0289 (0.1601)\n","\n","Epoch 26/30\n","Iteration 1184/3040\n","Loss gen 12.8971 (14.0034)\n","Loss dis 0.0747 (0.1603)\n","\n","Epoch 26/30\n","Iteration 1216/3040\n","Loss gen 13.5877 (13.9984)\n","Loss dis 0.1366 (0.1612)\n","\n","Epoch 26/30\n","Iteration 1248/3040\n","Loss gen 13.6891 (14.0038)\n","Loss dis 0.0089 (0.1617)\n","\n","Epoch 26/30\n","Iteration 1280/3040\n","Loss gen 13.9128 (13.9961)\n","Loss dis 0.2231 (0.1624)\n","\n","Epoch 26/30\n","Iteration 1312/3040\n","Loss gen 16.3771 (13.9990)\n","Loss dis 0.0104 (0.1604)\n","\n","Epoch 26/30\n","Iteration 1344/3040\n","Loss gen 13.7655 (13.9994)\n","Loss dis 0.0431 (0.1593)\n","\n","Epoch 26/30\n","Iteration 1376/3040\n","Loss gen 15.5294 (14.0080)\n","Loss dis 0.0075 (0.1591)\n","\n","Epoch 26/30\n","Iteration 1408/3040\n","Loss gen 16.0083 (14.0286)\n","Loss dis 0.0152 (0.1579)\n","\n","Epoch 26/30\n","Iteration 1440/3040\n","Loss gen 15.2541 (14.0393)\n","Loss dis 0.0909 (0.1572)\n","\n","Epoch 26/30\n","Iteration 1472/3040\n","Loss gen 11.0970 (14.0189)\n","Loss dis 0.2763 (0.1575)\n","\n","Epoch 26/30\n","Iteration 1504/3040\n","Loss gen 11.5375 (14.0175)\n","Loss dis 0.2041 (0.1580)\n","\n","Epoch 26/30\n","Iteration 1536/3040\n","Loss gen 17.2722 (14.0224)\n","Loss dis 0.0045 (0.1564)\n","\n","Epoch 26/30\n","Iteration 1568/3040\n","Loss gen 17.4464 (14.0393)\n","Loss dis 0.0298 (0.1555)\n","\n","Epoch 26/30\n","Iteration 1600/3040\n","Loss gen 12.4407 (14.0289)\n","Loss dis 0.0526 (0.1545)\n","\n","Epoch 26/30\n","Iteration 1632/3040\n","Loss gen 14.0612 (14.0367)\n","Loss dis 0.0102 (0.1529)\n","\n","Epoch 26/30\n","Iteration 1664/3040\n","Loss gen 12.6161 (14.0370)\n","Loss dis 0.0814 (0.1539)\n","\n","Epoch 26/30\n","Iteration 1696/3040\n","Loss gen 12.8929 (14.0394)\n","Loss dis 0.0178 (0.1520)\n","\n","Epoch 26/30\n","Iteration 1728/3040\n","Loss gen 14.2510 (14.0248)\n","Loss dis 0.0063 (0.1525)\n","\n","Epoch 26/30\n","Iteration 1760/3040\n","Loss gen 14.8774 (14.0168)\n","Loss dis 0.0212 (0.1517)\n","\n","Epoch 26/30\n","Iteration 1792/3040\n","Loss gen 12.7121 (14.0301)\n","Loss dis 0.0860 (0.1514)\n","\n","Epoch 26/30\n","Iteration 1824/3040\n","Loss gen 13.4418 (14.0341)\n","Loss dis 0.0654 (0.1504)\n","\n","Epoch 26/30\n","Iteration 1856/3040\n","Loss gen 19.1512 (14.0405)\n","Loss dis 0.0390 (0.1510)\n","\n","Epoch 26/30\n","Iteration 1888/3040\n","Loss gen 15.0423 (14.0485)\n","Loss dis 0.0024 (0.1495)\n","\n","Epoch 26/30\n","Iteration 1920/3040\n","Loss gen 13.5465 (14.0576)\n","Loss dis 0.0655 (0.1485)\n","\n","Epoch 26/30\n","Iteration 1952/3040\n","Loss gen 14.6114 (14.0655)\n","Loss dis 0.1066 (0.1491)\n","\n","Epoch 26/30\n","Iteration 1984/3040\n","Loss gen 13.2719 (14.0771)\n","Loss dis 0.0382 (0.1496)\n","\n","Epoch 26/30\n","Iteration 2016/3040\n","Loss gen 13.0363 (14.0957)\n","Loss dis 0.0616 (0.1494)\n","\n","Epoch 26/30\n","Iteration 2048/3040\n","Loss gen 13.9693 (14.0995)\n","Loss dis 0.0182 (0.1492)\n","\n","Epoch 26/30\n","Iteration 2080/3040\n","Loss gen 14.4874 (14.1127)\n","Loss dis 0.1145 (0.1490)\n","\n","Epoch 26/30\n","Iteration 2112/3040\n","Loss gen 13.6477 (14.1246)\n","Loss dis 0.0206 (0.1483)\n","\n","Epoch 26/30\n","Iteration 2144/3040\n","Loss gen 15.6776 (14.1255)\n","Loss dis 0.4883 (0.1479)\n","\n","Epoch 26/30\n","Iteration 2176/3040\n","Loss gen 13.5258 (14.1401)\n","Loss dis 0.1253 (0.1482)\n","\n","Epoch 26/30\n","Iteration 2208/3040\n","Loss gen 12.9382 (14.1382)\n","Loss dis 0.2028 (0.1492)\n","\n","Epoch 26/30\n","Iteration 2240/3040\n","Loss gen 15.4296 (14.1540)\n","Loss dis 0.0041 (0.1502)\n","\n","Epoch 26/30\n","Iteration 2272/3040\n","Loss gen 15.6279 (14.1644)\n","Loss dis 0.0021 (0.1503)\n","\n","Epoch 26/30\n","Iteration 2304/3040\n","Loss gen 13.0316 (14.1707)\n","Loss dis 0.0795 (0.1490)\n","\n","Epoch 26/30\n","Iteration 2336/3040\n","Loss gen 10.6337 (14.1713)\n","Loss dis 0.4025 (0.1496)\n","\n","Epoch 26/30\n","Iteration 2368/3040\n","Loss gen 15.5974 (14.1750)\n","Loss dis 0.1008 (0.1499)\n","\n","Epoch 26/30\n","Iteration 2400/3040\n","Loss gen 12.9668 (14.1807)\n","Loss dis 0.2928 (0.1494)\n","\n","Epoch 26/30\n","Iteration 2432/3040\n","Loss gen 11.6950 (14.1841)\n","Loss dis 0.2746 (0.1489)\n","\n","Epoch 26/30\n","Iteration 2464/3040\n","Loss gen 16.4975 (14.1965)\n","Loss dis 0.0490 (0.1483)\n","\n","Epoch 26/30\n","Iteration 2496/3040\n","Loss gen 14.5290 (14.1938)\n","Loss dis 0.2405 (0.1486)\n","\n","Epoch 26/30\n","Iteration 2528/3040\n","Loss gen 13.8754 (14.1853)\n","Loss dis 0.2221 (0.1494)\n","\n","Epoch 26/30\n","Iteration 2560/3040\n","Loss gen 13.8933 (14.1896)\n","Loss dis 0.1782 (0.1493)\n","\n","Epoch 26/30\n","Iteration 2592/3040\n","Loss gen 16.9292 (14.1833)\n","Loss dis 0.0102 (0.1488)\n","\n","Epoch 26/30\n","Iteration 2624/3040\n","Loss gen 13.0017 (14.1900)\n","Loss dis 0.0987 (0.1496)\n","\n","Epoch 26/30\n","Iteration 2656/3040\n","Loss gen 14.5935 (14.1850)\n","Loss dis 0.2795 (0.1494)\n","\n","Epoch 26/30\n","Iteration 2688/3040\n","Loss gen 14.8178 (14.1893)\n","Loss dis 0.0523 (0.1488)\n","\n","Epoch 26/30\n","Iteration 2720/3040\n","Loss gen 11.6751 (14.1780)\n","Loss dis 0.0334 (0.1502)\n","\n","Epoch 26/30\n","Iteration 2752/3040\n","Loss gen 16.7749 (14.1734)\n","Loss dis 0.0089 (0.1504)\n","\n","Epoch 26/30\n","Iteration 2784/3040\n","Loss gen 15.8220 (14.1747)\n","Loss dis 0.1315 (0.1522)\n","\n","Epoch 26/30\n","Iteration 2816/3040\n","Loss gen 16.8695 (14.1782)\n","Loss dis 0.0035 (0.1519)\n","\n","Epoch 26/30\n","Iteration 2848/3040\n","Loss gen 11.4263 (14.1766)\n","Loss dis 0.2234 (0.1516)\n","\n","Epoch 26/30\n","Iteration 2880/3040\n","Loss gen 15.1071 (14.1916)\n","Loss dis 0.0075 (0.1509)\n","\n","Epoch 26/30\n","Iteration 2912/3040\n","Loss gen 15.5839 (14.1950)\n","Loss dis 0.2370 (0.1523)\n","\n","Epoch 26/30\n","Iteration 2944/3040\n","Loss gen 9.6904 (14.1965)\n","Loss dis 0.8359 (0.1521)\n","\n","Epoch 26/30\n","Iteration 2976/3040\n","Loss gen 14.9183 (14.2022)\n","Loss dis 0.0080 (0.1523)\n","\n","Epoch 26/30\n","Iteration 3008/3040\n","Loss gen 13.6815 (14.2169)\n","Loss dis 0.0141 (0.1520)\n","\n","Epoch 26/30\n","Iteration 3040/3040\n","Loss gen 16.3653 (14.2288)\n","Loss dis 0.0033 (0.1526)\n","\n","Epoch 27/30\n","Iteration 32/3040\n","Loss gen 14.8330 (14.3305)\n","Loss dis 0.0627 (0.2143)\n","\n","Epoch 27/30\n","Iteration 64/3040\n","Loss gen 16.0064 (14.2235)\n","Loss dis 0.0214 (0.1574)\n","\n","Epoch 27/30\n","Iteration 96/3040\n","Loss gen 17.2132 (14.5608)\n","Loss dis 0.0114 (0.1315)\n","\n","Epoch 27/30\n","Iteration 128/3040\n","Loss gen 13.2678 (14.6655)\n","Loss dis 0.1373 (0.1373)\n","\n","Epoch 27/30\n","Iteration 160/3040\n","Loss gen 16.4513 (14.7627)\n","Loss dis 0.0103 (0.1713)\n","\n","Epoch 27/30\n","Iteration 192/3040\n","Loss gen 12.4993 (14.5235)\n","Loss dis 0.0292 (0.1818)\n","\n","Epoch 27/30\n","Iteration 224/3040\n","Loss gen 12.0652 (14.3975)\n","Loss dis 0.2107 (0.1855)\n","\n","Epoch 27/30\n","Iteration 256/3040\n","Loss gen 11.9852 (14.3714)\n","Loss dis 0.0566 (0.1789)\n","\n","Epoch 27/30\n","Iteration 288/3040\n","Loss gen 13.7839 (14.3349)\n","Loss dis 0.0667 (0.1822)\n","\n","Epoch 27/30\n","Iteration 320/3040\n","Loss gen 16.8757 (14.3444)\n","Loss dis 0.0194 (0.1747)\n","\n","Epoch 27/30\n","Iteration 352/3040\n","Loss gen 11.8454 (14.3127)\n","Loss dis 0.0782 (0.1733)\n","\n","Epoch 27/30\n","Iteration 384/3040\n","Loss gen 14.9365 (14.2580)\n","Loss dis 0.0251 (0.1708)\n","\n","Epoch 27/30\n","Iteration 416/3040\n","Loss gen 15.1196 (14.2405)\n","Loss dis 0.0091 (0.1632)\n","\n","Epoch 27/30\n","Iteration 448/3040\n","Loss gen 14.0863 (14.2469)\n","Loss dis 0.6673 (0.1707)\n","\n","Epoch 27/30\n","Iteration 480/3040\n","Loss gen 17.8033 (14.2914)\n","Loss dis 0.0010 (0.1670)\n","\n","Epoch 27/30\n","Iteration 512/3040\n","Loss gen 13.8895 (14.2832)\n","Loss dis 0.0201 (0.1672)\n","\n","Epoch 27/30\n","Iteration 544/3040\n","Loss gen 12.8895 (14.2870)\n","Loss dis 0.0366 (0.1626)\n","\n","Epoch 27/30\n","Iteration 576/3040\n","Loss gen 15.4121 (14.3483)\n","Loss dis 0.0350 (0.1606)\n","\n","Epoch 27/30\n","Iteration 608/3040\n","Loss gen 15.6942 (14.3936)\n","Loss dis 0.0334 (0.1565)\n","\n","Epoch 27/30\n","Iteration 640/3040\n","Loss gen 12.8322 (14.4033)\n","Loss dis 0.0273 (0.1629)\n","\n","Epoch 27/30\n","Iteration 672/3040\n","Loss gen 13.5829 (14.4171)\n","Loss dis 0.0660 (0.1600)\n","\n","Epoch 27/30\n","Iteration 704/3040\n","Loss gen 11.5499 (14.3482)\n","Loss dis 0.2794 (0.1619)\n","\n","Epoch 27/30\n","Iteration 736/3040\n","Loss gen 14.7031 (14.3126)\n","Loss dis 0.0546 (0.1586)\n","\n","Epoch 27/30\n","Iteration 768/3040\n","Loss gen 11.9622 (14.2922)\n","Loss dis 0.1016 (0.1563)\n","\n","Epoch 27/30\n","Iteration 800/3040\n","Loss gen 13.4726 (14.3025)\n","Loss dis 0.1382 (0.1548)\n","\n","Epoch 27/30\n","Iteration 832/3040\n","Loss gen 17.0587 (14.3052)\n","Loss dis 1.5987 (0.1607)\n","\n","Epoch 27/30\n","Iteration 864/3040\n","Loss gen 13.6603 (14.2936)\n","Loss dis 0.3102 (0.1612)\n","\n","Epoch 27/30\n","Iteration 896/3040\n","Loss gen 15.3769 (14.2750)\n","Loss dis 0.0033 (0.1596)\n","\n","Epoch 27/30\n","Iteration 928/3040\n","Loss gen 13.7112 (14.2613)\n","Loss dis 0.0533 (0.1590)\n","\n","Epoch 27/30\n","Iteration 960/3040\n","Loss gen 14.7351 (14.2548)\n","Loss dis 0.1680 (0.1579)\n","\n","Epoch 27/30\n","Iteration 992/3040\n","Loss gen 16.7355 (14.2484)\n","Loss dis 0.0013 (0.1557)\n","\n","Epoch 27/30\n","Iteration 1024/3040\n","Loss gen 18.6382 (14.2844)\n","Loss dis 0.0002 (0.1554)\n","\n","Epoch 27/30\n","Iteration 1056/3040\n","Loss gen 13.7735 (14.2687)\n","Loss dis 0.0168 (0.1597)\n","\n","Epoch 27/30\n","Iteration 1088/3040\n","Loss gen 13.5835 (14.2585)\n","Loss dis 0.0237 (0.1612)\n","\n","Epoch 27/30\n","Iteration 1120/3040\n","Loss gen 12.1638 (14.2527)\n","Loss dis 0.2509 (0.1612)\n","\n","Epoch 27/30\n","Iteration 1152/3040\n","Loss gen 12.2736 (14.2594)\n","Loss dis 0.0798 (0.1602)\n","\n","Epoch 27/30\n","Iteration 1184/3040\n","Loss gen 13.8838 (14.2614)\n","Loss dis 0.0612 (0.1607)\n","\n","Epoch 27/30\n","Iteration 1216/3040\n","Loss gen 13.8805 (14.2561)\n","Loss dis 0.0203 (0.1603)\n","\n","Epoch 27/30\n","Iteration 1248/3040\n","Loss gen 13.6095 (14.2604)\n","Loss dis 0.0784 (0.1608)\n","\n","Epoch 27/30\n","Iteration 1280/3040\n","Loss gen 13.6328 (14.2574)\n","Loss dis 0.0655 (0.1598)\n","\n","Epoch 27/30\n","Iteration 1312/3040\n","Loss gen 17.2294 (14.2547)\n","Loss dis 0.3164 (0.1587)\n","\n","Epoch 27/30\n","Iteration 1344/3040\n","Loss gen 11.0358 (14.2552)\n","Loss dis 0.0511 (0.1570)\n","\n","Epoch 27/30\n","Iteration 1376/3040\n","Loss gen 13.9148 (14.2646)\n","Loss dis 0.0496 (0.1594)\n","\n","Epoch 27/30\n","Iteration 1408/3040\n","Loss gen 14.5024 (14.2851)\n","Loss dis 0.0518 (0.1594)\n","\n","Epoch 27/30\n","Iteration 1440/3040\n","Loss gen 16.0128 (14.2826)\n","Loss dis 0.0099 (0.1587)\n","\n","Epoch 27/30\n","Iteration 1472/3040\n","Loss gen 12.0942 (14.2650)\n","Loss dis 0.0700 (0.1573)\n","\n","Epoch 27/30\n","Iteration 1504/3040\n","Loss gen 13.1385 (14.2564)\n","Loss dis 0.1085 (0.1571)\n","\n","Epoch 27/30\n","Iteration 1536/3040\n","Loss gen 14.5837 (14.2560)\n","Loss dis 0.0036 (0.1565)\n","\n","Epoch 27/30\n","Iteration 1568/3040\n","Loss gen 17.6607 (14.2653)\n","Loss dis 0.3119 (0.1550)\n","\n","Epoch 27/30\n","Iteration 1600/3040\n","Loss gen 12.4350 (14.2826)\n","Loss dis 0.7768 (0.1543)\n","\n","Epoch 27/30\n","Iteration 1632/3040\n","Loss gen 14.7589 (14.2841)\n","Loss dis 0.0196 (0.1543)\n","\n","Epoch 27/30\n","Iteration 1664/3040\n","Loss gen 13.8803 (14.2908)\n","Loss dis 0.0407 (0.1541)\n","\n","Epoch 27/30\n","Iteration 1696/3040\n","Loss gen 12.2667 (14.2946)\n","Loss dis 0.6334 (0.1526)\n","\n","Epoch 27/30\n","Iteration 1728/3040\n","Loss gen 14.8601 (14.2869)\n","Loss dis 0.0099 (0.1538)\n","\n","Epoch 27/30\n","Iteration 1760/3040\n","Loss gen 13.6437 (14.2716)\n","Loss dis 0.4976 (0.1552)\n","\n","Epoch 27/30\n","Iteration 1792/3040\n","Loss gen 13.4145 (14.2723)\n","Loss dis 0.0893 (0.1564)\n","\n","Epoch 27/30\n","Iteration 1824/3040\n","Loss gen 14.6848 (14.2747)\n","Loss dis 0.3004 (0.1551)\n","\n","Epoch 27/30\n","Iteration 1856/3040\n","Loss gen 13.4053 (14.2798)\n","Loss dis 0.0577 (0.1573)\n","\n","Epoch 27/30\n","Iteration 1888/3040\n","Loss gen 11.1307 (14.2776)\n","Loss dis 0.2526 (0.1575)\n","\n","Epoch 27/30\n","Iteration 1920/3040\n","Loss gen 12.2772 (14.2790)\n","Loss dis 0.3215 (0.1571)\n","\n","Epoch 27/30\n","Iteration 1952/3040\n","Loss gen 13.3107 (14.2597)\n","Loss dis 0.0966 (0.1582)\n","\n","Epoch 27/30\n","Iteration 1984/3040\n","Loss gen 11.4919 (14.2595)\n","Loss dis 0.2254 (0.1591)\n","\n","Epoch 27/30\n","Iteration 2016/3040\n","Loss gen 14.0970 (14.2573)\n","Loss dis 0.4616 (0.1589)\n","\n","Epoch 27/30\n","Iteration 2048/3040\n","Loss gen 15.7271 (14.2477)\n","Loss dis 0.0486 (0.1593)\n","\n","Epoch 27/30\n","Iteration 2080/3040\n","Loss gen 14.5294 (14.2425)\n","Loss dis 0.3952 (0.1620)\n","\n","Epoch 27/30\n","Iteration 2112/3040\n","Loss gen 13.7991 (14.2499)\n","Loss dis 0.0130 (0.1623)\n","\n","Epoch 27/30\n","Iteration 2144/3040\n","Loss gen 16.1609 (14.2496)\n","Loss dis 0.0016 (0.1630)\n","\n","Epoch 27/30\n","Iteration 2176/3040\n","Loss gen 12.5590 (14.2537)\n","Loss dis 0.0752 (0.1649)\n","\n","Epoch 27/30\n","Iteration 2208/3040\n","Loss gen 15.3446 (14.2482)\n","Loss dis 0.0275 (0.1638)\n","\n","Epoch 27/30\n","Iteration 2240/3040\n","Loss gen 16.6819 (14.2412)\n","Loss dis 0.0048 (0.1634)\n","\n","Epoch 27/30\n","Iteration 2272/3040\n","Loss gen 12.1638 (14.2425)\n","Loss dis 0.4337 (0.1634)\n","\n","Epoch 27/30\n","Iteration 2304/3040\n","Loss gen 10.8850 (14.2533)\n","Loss dis 0.4055 (0.1624)\n","\n","Epoch 27/30\n","Iteration 2336/3040\n","Loss gen 14.5676 (14.2608)\n","Loss dis 0.0116 (0.1614)\n","\n","Epoch 27/30\n","Iteration 2368/3040\n","Loss gen 13.8127 (14.2634)\n","Loss dis 0.5522 (0.1644)\n","\n","Epoch 27/30\n","Iteration 2400/3040\n","Loss gen 14.1864 (14.2573)\n","Loss dis 0.8689 (0.1665)\n","\n","Epoch 27/30\n","Iteration 2432/3040\n","Loss gen 10.9971 (14.2513)\n","Loss dis 0.0457 (0.1657)\n","\n","Epoch 27/30\n","Iteration 2464/3040\n","Loss gen 14.9772 (14.2435)\n","Loss dis 0.0168 (0.1660)\n","\n","Epoch 27/30\n","Iteration 2496/3040\n","Loss gen 15.6815 (14.2371)\n","Loss dis 0.0048 (0.1674)\n","\n","Epoch 27/30\n","Iteration 2528/3040\n","Loss gen 15.1898 (14.2346)\n","Loss dis 0.2605 (0.1669)\n","\n","Epoch 27/30\n","Iteration 2560/3040\n","Loss gen 14.0795 (14.2267)\n","Loss dis 0.1403 (0.1668)\n","\n","Epoch 27/30\n","Iteration 2592/3040\n","Loss gen 16.4159 (14.2214)\n","Loss dis 0.0072 (0.1658)\n","\n","Epoch 27/30\n","Iteration 2624/3040\n","Loss gen 13.4836 (14.2222)\n","Loss dis 0.5537 (0.1650)\n","\n","Epoch 27/30\n","Iteration 2656/3040\n","Loss gen 12.4762 (14.2212)\n","Loss dis 0.0203 (0.1644)\n","\n","Epoch 27/30\n","Iteration 2688/3040\n","Loss gen 15.4469 (14.2276)\n","Loss dis 0.0032 (0.1635)\n","\n","Epoch 27/30\n","Iteration 2720/3040\n","Loss gen 15.1964 (14.2275)\n","Loss dis 0.0042 (0.1634)\n","\n","Epoch 27/30\n","Iteration 2752/3040\n","Loss gen 13.8732 (14.2202)\n","Loss dis 0.0634 (0.1628)\n","\n","Epoch 27/30\n","Iteration 2784/3040\n","Loss gen 16.0946 (14.2180)\n","Loss dis 0.3765 (0.1631)\n","\n","Epoch 27/30\n","Iteration 2816/3040\n","Loss gen 13.9757 (14.2198)\n","Loss dis 0.3102 (0.1627)\n","\n","Epoch 27/30\n","Iteration 2848/3040\n","Loss gen 12.7915 (14.2144)\n","Loss dis 0.0481 (0.1621)\n","\n","Epoch 27/30\n","Iteration 2880/3040\n","Loss gen 14.8782 (14.2139)\n","Loss dis 0.0183 (0.1609)\n","\n","Epoch 27/30\n","Iteration 2912/3040\n","Loss gen 11.8237 (14.2069)\n","Loss dis 0.1657 (0.1606)\n","\n","Epoch 27/30\n","Iteration 2944/3040\n","Loss gen 11.9068 (14.2029)\n","Loss dis 0.0481 (0.1597)\n","\n","Epoch 27/30\n","Iteration 2976/3040\n","Loss gen 14.2743 (14.2012)\n","Loss dis 0.0895 (0.1602)\n","\n","Epoch 27/30\n","Iteration 3008/3040\n","Loss gen 12.4607 (14.2068)\n","Loss dis 0.0602 (0.1593)\n","\n","Epoch 27/30\n","Iteration 3040/3040\n","Loss gen 15.9280 (14.2124)\n","Loss dis 0.1023 (0.1588)\n","\n","Epoch 28/30\n","Iteration 32/3040\n","Loss gen 20.7652 (15.0035)\n","Loss dis 0.0001 (0.1567)\n","\n","Epoch 28/30\n","Iteration 64/3040\n","Loss gen 12.6921 (14.7142)\n","Loss dis 0.4526 (0.2126)\n","\n","Epoch 28/30\n","Iteration 96/3040\n","Loss gen 16.2316 (14.6544)\n","Loss dis 0.0007 (0.1884)\n","\n","Epoch 28/30\n","Iteration 128/3040\n","Loss gen 13.9167 (14.5937)\n","Loss dis 0.0095 (0.1699)\n","\n","Epoch 28/30\n","Iteration 160/3040\n","Loss gen 13.7775 (14.4710)\n","Loss dis 0.0735 (0.1601)\n","\n","Epoch 28/30\n","Iteration 192/3040\n","Loss gen 15.7707 (14.5301)\n","Loss dis 0.6102 (0.1682)\n","\n","Epoch 28/30\n","Iteration 224/3040\n","Loss gen 11.8614 (14.4521)\n","Loss dis 0.1035 (0.1646)\n","\n","Epoch 28/30\n","Iteration 256/3040\n","Loss gen 10.9818 (14.4358)\n","Loss dis 0.6393 (0.1639)\n","\n","Epoch 28/30\n","Iteration 288/3040\n","Loss gen 14.2980 (14.4362)\n","Loss dis 0.0127 (0.1536)\n","\n","Epoch 28/30\n","Iteration 320/3040\n","Loss gen 16.8362 (14.4058)\n","Loss dis 0.0273 (0.1601)\n","\n","Epoch 28/30\n","Iteration 352/3040\n","Loss gen 14.6812 (14.4024)\n","Loss dis 0.2972 (0.1599)\n","\n","Epoch 28/30\n","Iteration 384/3040\n","Loss gen 13.3197 (14.3968)\n","Loss dis 0.4301 (0.1590)\n","\n","Epoch 28/30\n","Iteration 416/3040\n","Loss gen 9.7974 (14.4099)\n","Loss dis 0.1815 (0.1659)\n","\n","Epoch 28/30\n","Iteration 448/3040\n","Loss gen 12.5712 (14.4329)\n","Loss dis 0.0613 (0.1625)\n","\n","Epoch 28/30\n","Iteration 480/3040\n","Loss gen 16.1808 (14.4953)\n","Loss dis 0.0163 (0.1584)\n","\n","Epoch 28/30\n","Iteration 512/3040\n","Loss gen 13.5257 (14.5254)\n","Loss dis 0.0916 (0.1647)\n","\n","Epoch 28/30\n","Iteration 544/3040\n","Loss gen 13.9595 (14.4865)\n","Loss dis 0.6457 (0.1730)\n","\n","Epoch 28/30\n","Iteration 576/3040\n","Loss gen 13.0354 (14.4845)\n","Loss dis 0.1174 (0.1805)\n","\n","Epoch 28/30\n","Iteration 608/3040\n","Loss gen 13.7808 (14.4751)\n","Loss dis 0.2028 (0.1804)\n","\n","Epoch 28/30\n","Iteration 640/3040\n","Loss gen 14.5452 (14.4730)\n","Loss dis 0.9951 (0.1860)\n","\n","Epoch 28/30\n","Iteration 672/3040\n","Loss gen 15.5326 (14.5201)\n","Loss dis 0.0458 (0.1838)\n","\n","Epoch 28/30\n","Iteration 704/3040\n","Loss gen 12.4759 (14.4950)\n","Loss dis 0.0588 (0.1798)\n","\n","Epoch 28/30\n","Iteration 736/3040\n","Loss gen 16.2428 (14.5001)\n","Loss dis 0.0120 (0.1783)\n","\n","Epoch 28/30\n","Iteration 768/3040\n","Loss gen 14.6246 (14.4698)\n","Loss dis 0.0038 (0.1786)\n","\n","Epoch 28/30\n","Iteration 800/3040\n","Loss gen 13.8128 (14.4393)\n","Loss dis 0.1080 (0.1804)\n","\n","Epoch 28/30\n","Iteration 832/3040\n","Loss gen 12.4889 (14.4566)\n","Loss dis 0.4153 (0.1790)\n","\n","Epoch 28/30\n","Iteration 864/3040\n","Loss gen 11.8744 (14.4480)\n","Loss dis 0.0970 (0.1776)\n","\n","Epoch 28/30\n","Iteration 896/3040\n","Loss gen 17.3026 (14.4318)\n","Loss dis 0.0010 (0.1817)\n","\n","Epoch 28/30\n","Iteration 928/3040\n","Loss gen 13.6045 (14.4290)\n","Loss dis 0.0067 (0.1817)\n","\n","Epoch 28/30\n","Iteration 960/3040\n","Loss gen 16.2249 (14.4114)\n","Loss dis 0.0027 (0.1793)\n","\n","Epoch 28/30\n","Iteration 992/3040\n","Loss gen 15.4797 (14.3904)\n","Loss dis 0.0920 (0.1777)\n","\n","Epoch 28/30\n","Iteration 1024/3040\n","Loss gen 16.7973 (14.3972)\n","Loss dis 0.9866 (0.1786)\n","\n","Epoch 28/30\n","Iteration 1056/3040\n","Loss gen 12.9519 (14.3855)\n","Loss dis 0.1608 (0.1768)\n","\n","Epoch 28/30\n","Iteration 1088/3040\n","Loss gen 13.2545 (14.3694)\n","Loss dis 0.0731 (0.1752)\n","\n","Epoch 28/30\n","Iteration 1120/3040\n","Loss gen 11.2010 (14.3739)\n","Loss dis 0.0199 (0.1771)\n","\n","Epoch 28/30\n","Iteration 1152/3040\n","Loss gen 14.4311 (14.3640)\n","Loss dis 0.0491 (0.1760)\n","\n","Epoch 28/30\n","Iteration 1184/3040\n","Loss gen 13.1807 (14.3654)\n","Loss dis 0.1172 (0.1759)\n","\n","Epoch 28/30\n","Iteration 1216/3040\n","Loss gen 14.1475 (14.3656)\n","Loss dis 0.0327 (0.1754)\n","\n","Epoch 28/30\n","Iteration 1248/3040\n","Loss gen 11.9441 (14.3752)\n","Loss dis 1.6044 (0.1752)\n","\n","Epoch 28/30\n","Iteration 1280/3040\n","Loss gen 14.7415 (14.3754)\n","Loss dis 0.0133 (0.1739)\n","\n","Epoch 28/30\n","Iteration 1312/3040\n","Loss gen 18.1822 (14.3768)\n","Loss dis 0.0063 (0.1764)\n","\n","Epoch 28/30\n","Iteration 1344/3040\n","Loss gen 11.2336 (14.3663)\n","Loss dis 0.5459 (0.1772)\n","\n","Epoch 28/30\n","Iteration 1376/3040\n","Loss gen 12.7119 (14.3630)\n","Loss dis 0.0926 (0.1758)\n","\n","Epoch 28/30\n","Iteration 1408/3040\n","Loss gen 12.8126 (14.3687)\n","Loss dis 0.1719 (0.1754)\n","\n","Epoch 28/30\n","Iteration 1440/3040\n","Loss gen 16.1263 (14.3730)\n","Loss dis 0.0338 (0.1757)\n","\n","Epoch 28/30\n","Iteration 1472/3040\n","Loss gen 13.7001 (14.3675)\n","Loss dis 0.1253 (0.1743)\n","\n","Epoch 28/30\n","Iteration 1504/3040\n","Loss gen 14.5521 (14.3666)\n","Loss dis 0.2463 (0.1759)\n","\n","Epoch 28/30\n","Iteration 1536/3040\n","Loss gen 13.0324 (14.3544)\n","Loss dis 0.0358 (0.1764)\n","\n","Epoch 28/30\n","Iteration 1568/3040\n","Loss gen 15.9411 (14.3636)\n","Loss dis 0.1487 (0.1769)\n","\n","Epoch 28/30\n","Iteration 1600/3040\n","Loss gen 13.0712 (14.3538)\n","Loss dis 0.1049 (0.1762)\n","\n","Epoch 28/30\n","Iteration 1632/3040\n","Loss gen 14.4006 (14.3481)\n","Loss dis 0.3447 (0.1772)\n","\n","Epoch 28/30\n","Iteration 1664/3040\n","Loss gen 14.9622 (14.3425)\n","Loss dis 0.1161 (0.1754)\n","\n","Epoch 28/30\n","Iteration 1696/3040\n","Loss gen 13.5830 (14.3315)\n","Loss dis 0.0173 (0.1740)\n","\n","Epoch 28/30\n","Iteration 1728/3040\n","Loss gen 14.4544 (14.3276)\n","Loss dis 0.0520 (0.1761)\n","\n","Epoch 28/30\n","Iteration 1760/3040\n","Loss gen 14.4730 (14.3225)\n","Loss dis 0.0499 (0.1753)\n","\n","Epoch 28/30\n","Iteration 1792/3040\n","Loss gen 14.1113 (14.3242)\n","Loss dis 0.0569 (0.1760)\n","\n","Epoch 28/30\n","Iteration 1824/3040\n","Loss gen 17.3204 (14.3231)\n","Loss dis 0.1964 (0.1758)\n","\n","Epoch 28/30\n","Iteration 1856/3040\n","Loss gen 15.5483 (14.3207)\n","Loss dis 0.1466 (0.1753)\n","\n","Epoch 28/30\n","Iteration 1888/3040\n","Loss gen 14.2050 (14.3070)\n","Loss dis 0.0121 (0.1756)\n","\n","Epoch 28/30\n","Iteration 1920/3040\n","Loss gen 13.4077 (14.3141)\n","Loss dis 0.3542 (0.1751)\n","\n","Epoch 28/30\n","Iteration 1952/3040\n","Loss gen 14.8166 (14.3139)\n","Loss dis 0.0028 (0.1736)\n","\n","Epoch 28/30\n","Iteration 1984/3040\n","Loss gen 11.7072 (14.3046)\n","Loss dis 1.2866 (0.1732)\n","\n","Epoch 28/30\n","Iteration 2016/3040\n","Loss gen 15.8446 (14.2993)\n","Loss dis 0.1072 (0.1725)\n","\n","Epoch 28/30\n","Iteration 2048/3040\n","Loss gen 13.9045 (14.2919)\n","Loss dis 0.0300 (0.1722)\n","\n","Epoch 28/30\n","Iteration 2080/3040\n","Loss gen 11.4522 (14.2924)\n","Loss dis 0.0721 (0.1722)\n","\n","Epoch 28/30\n","Iteration 2112/3040\n","Loss gen 12.5366 (14.2912)\n","Loss dis 0.0758 (0.1708)\n","\n","Epoch 28/30\n","Iteration 2144/3040\n","Loss gen 13.2201 (14.2810)\n","Loss dis 0.1075 (0.1706)\n","\n","Epoch 28/30\n","Iteration 2176/3040\n","Loss gen 11.6134 (14.2824)\n","Loss dis 0.2238 (0.1693)\n","\n","Epoch 28/30\n","Iteration 2208/3040\n","Loss gen 12.0639 (14.2734)\n","Loss dis 0.0361 (0.1705)\n","\n","Epoch 28/30\n","Iteration 2240/3040\n","Loss gen 16.9734 (14.2817)\n","Loss dis 0.0022 (0.1716)\n","\n","Epoch 28/30\n","Iteration 2272/3040\n","Loss gen 12.6849 (14.2786)\n","Loss dis 0.0863 (0.1710)\n","\n","Epoch 28/30\n","Iteration 2304/3040\n","Loss gen 12.5451 (14.2896)\n","Loss dis 0.6550 (0.1707)\n","\n","Epoch 28/30\n","Iteration 2336/3040\n","Loss gen 15.7976 (14.2934)\n","Loss dis 0.0210 (0.1704)\n","\n","Epoch 28/30\n","Iteration 2368/3040\n","Loss gen 11.5722 (14.3015)\n","Loss dis 0.0218 (0.1702)\n","\n","Epoch 28/30\n","Iteration 2400/3040\n","Loss gen 13.9980 (14.3033)\n","Loss dis 0.1656 (0.1693)\n","\n","Epoch 28/30\n","Iteration 2432/3040\n","Loss gen 20.4708 (14.3191)\n","Loss dis 0.0002 (0.1693)\n","\n","Epoch 28/30\n","Iteration 2464/3040\n","Loss gen 15.6939 (14.3428)\n","Loss dis 0.0187 (0.1702)\n","\n","Epoch 28/30\n","Iteration 2496/3040\n","Loss gen 19.9745 (14.3613)\n","Loss dis 0.0004 (0.1710)\n","\n","Epoch 28/30\n","Iteration 2528/3040\n","Loss gen 16.3119 (14.3645)\n","Loss dis 0.0754 (0.1722)\n","\n","Epoch 28/30\n","Iteration 2560/3040\n","Loss gen 15.7361 (14.3637)\n","Loss dis 0.0405 (0.1711)\n","\n","Epoch 28/30\n","Iteration 2592/3040\n","Loss gen 13.4039 (14.3581)\n","Loss dis 0.3854 (0.1709)\n","\n","Epoch 28/30\n","Iteration 2624/3040\n","Loss gen 13.6752 (14.3620)\n","Loss dis 0.2874 (0.1711)\n","\n","Epoch 28/30\n","Iteration 2656/3040\n","Loss gen 12.0167 (14.3520)\n","Loss dis 0.1241 (0.1706)\n","\n","Epoch 28/30\n","Iteration 2688/3040\n","Loss gen 14.4986 (14.3538)\n","Loss dis 0.3950 (0.1698)\n","\n","Epoch 28/30\n","Iteration 2720/3040\n","Loss gen 13.6561 (14.3465)\n","Loss dis 0.0719 (0.1705)\n","\n","Epoch 28/30\n","Iteration 2752/3040\n","Loss gen 11.6525 (14.3431)\n","Loss dis 0.4550 (0.1708)\n","\n","Epoch 28/30\n","Iteration 2784/3040\n","Loss gen 14.7242 (14.3369)\n","Loss dis 0.0063 (0.1707)\n","\n","Epoch 28/30\n","Iteration 2816/3040\n","Loss gen 16.8428 (14.3332)\n","Loss dis 0.0340 (0.1712)\n","\n","Epoch 28/30\n","Iteration 2848/3040\n","Loss gen 15.2710 (14.3327)\n","Loss dis 0.1092 (0.1728)\n","\n","Epoch 28/30\n","Iteration 2880/3040\n","Loss gen 16.4810 (14.3320)\n","Loss dis 1.4761 (0.1737)\n","\n","Epoch 28/30\n","Iteration 2912/3040\n","Loss gen 13.9943 (14.3304)\n","Loss dis 0.1004 (0.1746)\n","\n","Epoch 28/30\n","Iteration 2944/3040\n","Loss gen 10.6795 (14.3222)\n","Loss dis 0.1662 (0.1746)\n","\n","Epoch 28/30\n","Iteration 2976/3040\n","Loss gen 14.9070 (14.3229)\n","Loss dis 0.0045 (0.1742)\n","\n","Epoch 28/30\n","Iteration 3008/3040\n","Loss gen 11.8760 (14.3187)\n","Loss dis 0.0426 (0.1731)\n","\n","Epoch 28/30\n","Iteration 3040/3040\n","Loss gen 12.8998 (14.3134)\n","Loss dis 0.1246 (0.1729)\n","\n","Epoch 29/30\n","Iteration 32/3040\n","Loss gen 14.3048 (14.0635)\n","Loss dis 0.0556 (0.1107)\n","\n","Epoch 29/30\n","Iteration 64/3040\n","Loss gen 16.0496 (13.9938)\n","Loss dis 0.0079 (0.1449)\n","\n","Epoch 29/30\n","Iteration 96/3040\n","Loss gen 13.7233 (14.2022)\n","Loss dis 0.0277 (0.1246)\n","\n","Epoch 29/30\n","Iteration 128/3040\n","Loss gen 14.5499 (14.2409)\n","Loss dis 0.0064 (0.1090)\n","\n","Epoch 29/30\n","Iteration 160/3040\n","Loss gen 16.1620 (14.3601)\n","Loss dis 0.0906 (0.1054)\n","\n","Epoch 29/30\n","Iteration 192/3040\n","Loss gen 14.4596 (14.5583)\n","Loss dis 0.0058 (0.0931)\n","\n","Epoch 29/30\n","Iteration 224/3040\n","Loss gen 13.6573 (14.5333)\n","Loss dis 0.0031 (0.0890)\n","\n","Epoch 29/30\n","Iteration 256/3040\n","Loss gen 13.5176 (14.7318)\n","Loss dis 0.0232 (0.0785)\n","\n","Epoch 29/30\n","Iteration 288/3040\n","Loss gen 15.1600 (14.7992)\n","Loss dis 0.0045 (0.0713)\n","\n","Epoch 29/30\n","Iteration 320/3040\n","Loss gen 20.6144 (14.9402)\n","Loss dis 0.0002 (0.0650)\n","\n","Epoch 29/30\n","Iteration 352/3040\n","Loss gen 14.9815 (15.3865)\n","Loss dis 0.0085 (0.0646)\n","\n","Epoch 29/30\n","Iteration 384/3040\n","Loss gen 17.5033 (15.5880)\n","Loss dis 0.0005 (0.0644)\n","\n","Epoch 29/30\n","Iteration 416/3040\n","Loss gen 17.8608 (15.8057)\n","Loss dis 0.0008 (0.0648)\n","\n","Epoch 29/30\n","Iteration 448/3040\n","Loss gen 13.9867 (15.8317)\n","Loss dis 0.2217 (0.0688)\n","\n","Epoch 29/30\n","Iteration 480/3040\n","Loss gen 16.5976 (15.7879)\n","Loss dis 0.0203 (0.0903)\n","\n","Epoch 29/30\n","Iteration 512/3040\n","Loss gen 14.4223 (15.7126)\n","Loss dis 0.1460 (0.1073)\n","\n","Epoch 29/30\n","Iteration 544/3040\n","Loss gen 11.4267 (15.5859)\n","Loss dis 0.6353 (0.1187)\n","\n","Epoch 29/30\n","Iteration 576/3040\n","Loss gen 12.9571 (15.4939)\n","Loss dis 0.2674 (0.1318)\n","\n","Epoch 29/30\n","Iteration 608/3040\n","Loss gen 13.8673 (15.3929)\n","Loss dis 0.0761 (0.1478)\n","\n","Epoch 29/30\n","Iteration 640/3040\n","Loss gen 12.8350 (15.3095)\n","Loss dis 0.0858 (0.1521)\n","\n","Epoch 29/30\n","Iteration 672/3040\n","Loss gen 11.8408 (15.2642)\n","Loss dis 0.5018 (0.1604)\n","\n","Epoch 29/30\n","Iteration 704/3040\n","Loss gen 13.9131 (15.1682)\n","Loss dis 0.3223 (0.1608)\n","\n","Epoch 29/30\n","Iteration 736/3040\n","Loss gen 15.1298 (15.1114)\n","Loss dis 0.0072 (0.1625)\n","\n","Epoch 29/30\n","Iteration 768/3040\n","Loss gen 14.5320 (15.0529)\n","Loss dis 0.0781 (0.1662)\n","\n","Epoch 29/30\n","Iteration 800/3040\n","Loss gen 14.7780 (15.0257)\n","Loss dis 0.2883 (0.1691)\n","\n","Epoch 29/30\n","Iteration 832/3040\n","Loss gen 14.6449 (14.9969)\n","Loss dis 0.6631 (0.1701)\n","\n","Epoch 29/30\n","Iteration 864/3040\n","Loss gen 11.6825 (14.9368)\n","Loss dis 0.0866 (0.1678)\n","\n","Epoch 29/30\n","Iteration 896/3040\n","Loss gen 13.0563 (14.8839)\n","Loss dis 0.0757 (0.1670)\n","\n","Epoch 29/30\n","Iteration 928/3040\n","Loss gen 12.4512 (14.8470)\n","Loss dis 0.0520 (0.1674)\n","\n","Epoch 29/30\n","Iteration 960/3040\n","Loss gen 16.6120 (14.7993)\n","Loss dis 0.0028 (0.1676)\n","\n","Epoch 29/30\n","Iteration 992/3040\n","Loss gen 15.6362 (14.7446)\n","Loss dis 0.2536 (0.1666)\n","\n","Epoch 29/30\n","Iteration 1024/3040\n","Loss gen 12.7314 (14.7193)\n","Loss dis 0.1092 (0.1663)\n","\n","Epoch 29/30\n","Iteration 1056/3040\n","Loss gen 13.0239 (14.6900)\n","Loss dis 0.1013 (0.1660)\n","\n","Epoch 29/30\n","Iteration 1088/3040\n","Loss gen 14.7585 (14.6615)\n","Loss dis 0.1096 (0.1675)\n","\n","Epoch 29/30\n","Iteration 1120/3040\n","Loss gen 11.3511 (14.6345)\n","Loss dis 0.0447 (0.1658)\n","\n","Epoch 29/30\n","Iteration 1152/3040\n","Loss gen 11.4866 (14.6019)\n","Loss dis 0.0381 (0.1649)\n","\n","Epoch 29/30\n","Iteration 1184/3040\n","Loss gen 14.4366 (14.5873)\n","Loss dis 0.6446 (0.1658)\n","\n","Epoch 29/30\n","Iteration 1216/3040\n","Loss gen 13.1802 (14.5633)\n","Loss dis 0.0509 (0.1654)\n","\n","Epoch 29/30\n","Iteration 1248/3040\n","Loss gen 13.2049 (14.5591)\n","Loss dis 0.2741 (0.1644)\n","\n","Epoch 29/30\n","Iteration 1280/3040\n","Loss gen 12.4057 (14.5438)\n","Loss dis 0.0679 (0.1624)\n","\n","Epoch 29/30\n","Iteration 1312/3040\n","Loss gen 19.6809 (14.5271)\n","Loss dis 0.0015 (0.1616)\n","\n","Epoch 29/30\n","Iteration 1344/3040\n","Loss gen 13.5536 (14.5106)\n","Loss dis 0.0137 (0.1601)\n","\n","Epoch 29/30\n","Iteration 1376/3040\n","Loss gen 15.4112 (14.5128)\n","Loss dis 0.0030 (0.1589)\n","\n","Epoch 29/30\n","Iteration 1408/3040\n","Loss gen 13.3633 (14.5037)\n","Loss dis 0.0071 (0.1584)\n","\n","Epoch 29/30\n","Iteration 1440/3040\n","Loss gen 16.4905 (14.5047)\n","Loss dis 0.0239 (0.1585)\n","\n","Epoch 29/30\n","Iteration 1472/3040\n","Loss gen 14.7242 (14.4871)\n","Loss dis 0.0731 (0.1593)\n","\n","Epoch 29/30\n","Iteration 1504/3040\n","Loss gen 13.2795 (14.4703)\n","Loss dis 0.1278 (0.1592)\n","\n","Epoch 29/30\n","Iteration 1536/3040\n","Loss gen 14.5153 (14.4692)\n","Loss dis 0.0219 (0.1589)\n","\n","Epoch 29/30\n","Iteration 1568/3040\n","Loss gen 15.5892 (14.4696)\n","Loss dis 0.0349 (0.1578)\n","\n","Epoch 29/30\n","Iteration 1600/3040\n","Loss gen 14.1945 (14.4667)\n","Loss dis 0.1183 (0.1566)\n","\n","Epoch 29/30\n","Iteration 1632/3040\n","Loss gen 16.0048 (14.4686)\n","Loss dis 0.0038 (0.1571)\n","\n","Epoch 29/30\n","Iteration 1664/3040\n","Loss gen 14.5033 (14.4563)\n","Loss dis 0.0402 (0.1571)\n","\n","Epoch 29/30\n","Iteration 1696/3040\n","Loss gen 11.5742 (14.4480)\n","Loss dis 0.0976 (0.1571)\n","\n","Epoch 29/30\n","Iteration 1728/3040\n","Loss gen 12.6907 (14.4314)\n","Loss dis 0.1362 (0.1557)\n","\n","Epoch 29/30\n","Iteration 1760/3040\n","Loss gen 16.7640 (14.4182)\n","Loss dis 0.3254 (0.1551)\n","\n","Epoch 29/30\n","Iteration 1792/3040\n","Loss gen 13.6707 (14.4150)\n","Loss dis 0.2389 (0.1547)\n","\n","Epoch 29/30\n","Iteration 1824/3040\n","Loss gen 12.8974 (14.4088)\n","Loss dis 0.1734 (0.1535)\n","\n","Epoch 29/30\n","Iteration 1856/3040\n","Loss gen 16.1445 (14.3971)\n","Loss dis 0.0094 (0.1542)\n","\n","Epoch 29/30\n","Iteration 1888/3040\n","Loss gen 15.1686 (14.3992)\n","Loss dis 0.0019 (0.1528)\n","\n","Epoch 29/30\n","Iteration 1920/3040\n","Loss gen 17.4646 (14.4108)\n","Loss dis 0.0011 (0.1525)\n","\n","Epoch 29/30\n","Iteration 1952/3040\n","Loss gen 13.9785 (14.3979)\n","Loss dis 0.0061 (0.1533)\n","\n","Epoch 29/30\n","Iteration 1984/3040\n","Loss gen 13.7472 (14.3866)\n","Loss dis 0.0843 (0.1543)\n","\n","Epoch 29/30\n","Iteration 2016/3040\n","Loss gen 12.6733 (14.3877)\n","Loss dis 0.0599 (0.1553)\n","\n","Epoch 29/30\n","Iteration 2048/3040\n","Loss gen 14.6356 (14.3810)\n","Loss dis 0.0297 (0.1556)\n","\n","Epoch 29/30\n","Iteration 2080/3040\n","Loss gen 12.2627 (14.3727)\n","Loss dis 0.1106 (0.1557)\n","\n","Epoch 29/30\n","Iteration 2112/3040\n","Loss gen 15.8710 (14.3764)\n","Loss dis 0.0485 (0.1568)\n","\n","Epoch 29/30\n","Iteration 2144/3040\n","Loss gen 13.1648 (14.3645)\n","Loss dis 0.0577 (0.1558)\n","\n","Epoch 29/30\n","Iteration 2176/3040\n","Loss gen 12.1349 (14.3547)\n","Loss dis 0.0604 (0.1551)\n","\n","Epoch 29/30\n","Iteration 2208/3040\n","Loss gen 16.1065 (14.3592)\n","Loss dis 0.0223 (0.1540)\n","\n","Epoch 29/30\n","Iteration 2240/3040\n","Loss gen 13.9711 (14.3498)\n","Loss dis 0.0363 (0.1545)\n","\n","Epoch 29/30\n","Iteration 2272/3040\n","Loss gen 15.7243 (14.3521)\n","Loss dis 0.0463 (0.1548)\n","\n","Epoch 29/30\n","Iteration 2304/3040\n","Loss gen 12.1128 (14.3513)\n","Loss dis 0.1974 (0.1541)\n","\n","Epoch 29/30\n","Iteration 2336/3040\n","Loss gen 12.6431 (14.3477)\n","Loss dis 0.0323 (0.1543)\n","\n","Epoch 29/30\n","Iteration 2368/3040\n","Loss gen 11.0137 (14.3433)\n","Loss dis 0.0788 (0.1537)\n","\n","Epoch 29/30\n","Iteration 2400/3040\n","Loss gen 13.2646 (14.3426)\n","Loss dis 0.1782 (0.1536)\n","\n","Epoch 29/30\n","Iteration 2432/3040\n","Loss gen 11.7586 (14.3364)\n","Loss dis 0.0867 (0.1538)\n","\n","Epoch 29/30\n","Iteration 2464/3040\n","Loss gen 14.8273 (14.3375)\n","Loss dis 0.2243 (0.1544)\n","\n","Epoch 29/30\n","Iteration 2496/3040\n","Loss gen 17.9819 (14.3426)\n","Loss dis 0.0021 (0.1556)\n","\n","Epoch 29/30\n","Iteration 2528/3040\n","Loss gen 17.5635 (14.3570)\n","Loss dis 0.0842 (0.1554)\n","\n","Epoch 29/30\n","Iteration 2560/3040\n","Loss gen 13.9900 (14.3592)\n","Loss dis 0.0263 (0.1561)\n","\n","Epoch 29/30\n","Iteration 2592/3040\n","Loss gen 16.3738 (14.3523)\n","Loss dis 0.0073 (0.1559)\n","\n","Epoch 29/30\n","Iteration 2624/3040\n","Loss gen 12.8686 (14.3494)\n","Loss dis 0.0380 (0.1558)\n","\n","Epoch 29/30\n","Iteration 2656/3040\n","Loss gen 13.5253 (14.3384)\n","Loss dis 0.0148 (0.1558)\n","\n","Epoch 29/30\n","Iteration 2688/3040\n","Loss gen 12.8642 (14.3360)\n","Loss dis 0.0549 (0.1552)\n","\n","Epoch 29/30\n","Iteration 2720/3040\n","Loss gen 13.1164 (14.3184)\n","Loss dis 0.1841 (0.1560)\n","\n","Epoch 29/30\n","Iteration 2752/3040\n","Loss gen 13.4285 (14.3090)\n","Loss dis 0.0952 (0.1565)\n","\n","Epoch 29/30\n","Iteration 2784/3040\n","Loss gen 18.9759 (14.3030)\n","Loss dis 0.0428 (0.1562)\n","\n","Epoch 29/30\n","Iteration 2816/3040\n","Loss gen 14.6524 (14.2957)\n","Loss dis 0.0482 (0.1559)\n","\n","Epoch 29/30\n","Iteration 2848/3040\n","Loss gen 13.0602 (14.2898)\n","Loss dis 0.0066 (0.1552)\n","\n","Epoch 29/30\n","Iteration 2880/3040\n","Loss gen 16.9157 (14.2919)\n","Loss dis 0.0016 (0.1552)\n","\n","Epoch 29/30\n","Iteration 2912/3040\n","Loss gen 14.7324 (14.2889)\n","Loss dis 0.0168 (0.1567)\n","\n","Epoch 29/30\n","Iteration 2944/3040\n","Loss gen 10.5472 (14.2860)\n","Loss dis 0.2235 (0.1573)\n","\n","Epoch 29/30\n","Iteration 2976/3040\n","Loss gen 12.9807 (14.2896)\n","Loss dis 0.0110 (0.1562)\n","\n","Epoch 29/30\n","Iteration 3008/3040\n","Loss gen 11.6571 (14.3002)\n","Loss dis 0.3520 (0.1558)\n","\n","Epoch 29/30\n","Iteration 3040/3040\n","Loss gen 15.3106 (14.2976)\n","Loss dis 0.3179 (0.1553)\n","\n","Epoch 30/30\n","Iteration 32/3040\n","Loss gen 14.8756 (13.7087)\n","Loss dis 0.0094 (0.1638)\n","\n","Epoch 30/30\n","Iteration 64/3040\n","Loss gen 13.8558 (13.4685)\n","Loss dis 0.0255 (0.1252)\n","\n","Epoch 30/30\n","Iteration 96/3040\n","Loss gen 15.4628 (13.8684)\n","Loss dis 0.0052 (0.1334)\n","\n","Epoch 30/30\n","Iteration 128/3040\n","Loss gen 11.9003 (13.9404)\n","Loss dis 0.0772 (0.1642)\n","\n","Epoch 30/30\n","Iteration 160/3040\n","Loss gen 17.4099 (14.0774)\n","Loss dis 0.0027 (0.1800)\n","\n","Epoch 30/30\n","Iteration 192/3040\n","Loss gen 13.7256 (14.0742)\n","Loss dis 0.0136 (0.1796)\n","\n","Epoch 30/30\n","Iteration 224/3040\n","Loss gen 12.0097 (13.9805)\n","Loss dis 0.0966 (0.1897)\n","\n","Epoch 30/30\n","Iteration 256/3040\n","Loss gen 14.0543 (14.0274)\n","Loss dis 0.0150 (0.1796)\n","\n","Epoch 30/30\n","Iteration 288/3040\n","Loss gen 14.6325 (14.0360)\n","Loss dis 0.0747 (0.1759)\n","\n","Epoch 30/30\n","Iteration 320/3040\n","Loss gen 16.8590 (14.1232)\n","Loss dis 0.0188 (0.1681)\n","\n","Epoch 30/30\n","Iteration 352/3040\n","Loss gen 14.7167 (14.2256)\n","Loss dis 0.0154 (0.1651)\n","\n","Epoch 30/30\n","Iteration 384/3040\n","Loss gen 15.5497 (14.2310)\n","Loss dis 0.4238 (0.1647)\n","\n","Epoch 30/30\n","Iteration 416/3040\n","Loss gen 15.1867 (14.1905)\n","Loss dis 0.0038 (0.1634)\n","\n","Epoch 30/30\n","Iteration 448/3040\n","Loss gen 12.2884 (14.1986)\n","Loss dis 0.0670 (0.1593)\n","\n","Epoch 30/30\n","Iteration 480/3040\n","Loss gen 15.3397 (14.2048)\n","Loss dis 0.0831 (0.1571)\n","\n","Epoch 30/30\n","Iteration 512/3040\n","Loss gen 16.7959 (14.2454)\n","Loss dis 0.9448 (0.1576)\n","\n","Epoch 30/30\n","Iteration 544/3040\n","Loss gen 13.3142 (14.2592)\n","Loss dis 0.2683 (0.1530)\n","\n","Epoch 30/30\n","Iteration 576/3040\n","Loss gen 11.4909 (14.2635)\n","Loss dis 0.2790 (0.1500)\n","\n","Epoch 30/30\n","Iteration 608/3040\n","Loss gen 12.4662 (14.2758)\n","Loss dis 0.1673 (0.1545)\n","\n","Epoch 30/30\n","Iteration 640/3040\n","Loss gen 11.9229 (14.2580)\n","Loss dis 0.5259 (0.1556)\n","\n","Epoch 30/30\n","Iteration 672/3040\n","Loss gen 13.8154 (14.2801)\n","Loss dis 0.0905 (0.1524)\n","\n","Epoch 30/30\n","Iteration 704/3040\n","Loss gen 13.5223 (14.2282)\n","Loss dis 0.0053 (0.1545)\n","\n","Epoch 30/30\n","Iteration 736/3040\n","Loss gen 15.1045 (14.2041)\n","Loss dis 0.0134 (0.1539)\n","\n","Epoch 30/30\n","Iteration 768/3040\n","Loss gen 13.4695 (14.1908)\n","Loss dis 0.1597 (0.1547)\n","\n","Epoch 30/30\n","Iteration 800/3040\n","Loss gen 18.1561 (14.2075)\n","Loss dis 0.0071 (0.1549)\n","\n","Epoch 30/30\n","Iteration 832/3040\n","Loss gen 16.6405 (14.2496)\n","Loss dis 0.0290 (0.1511)\n","\n","Epoch 30/30\n","Iteration 864/3040\n","Loss gen 16.6565 (14.2412)\n","Loss dis 0.7715 (0.1551)\n","\n","Epoch 30/30\n","Iteration 896/3040\n","Loss gen 15.2862 (14.2339)\n","Loss dis 0.0015 (0.1575)\n","\n","Epoch 30/30\n","Iteration 928/3040\n","Loss gen 14.1278 (14.2061)\n","Loss dis 0.0981 (0.1608)\n","\n","Epoch 30/30\n","Iteration 960/3040\n","Loss gen 13.6440 (14.1812)\n","Loss dis 0.0642 (0.1603)\n","\n","Epoch 30/30\n","Iteration 992/3040\n","Loss gen 18.8102 (14.1817)\n","Loss dis 0.0158 (0.1587)\n","\n","Epoch 30/30\n","Iteration 1024/3040\n","Loss gen 11.7814 (14.2044)\n","Loss dis 0.1978 (0.1574)\n","\n","Epoch 30/30\n","Iteration 1056/3040\n","Loss gen 14.3068 (14.2205)\n","Loss dis 0.0130 (0.1566)\n","\n","Epoch 30/30\n","Iteration 1088/3040\n","Loss gen 14.6630 (14.2191)\n","Loss dis 0.0305 (0.1579)\n","\n","Epoch 30/30\n","Iteration 1120/3040\n","Loss gen 15.9937 (14.2314)\n","Loss dis 0.0039 (0.1575)\n","\n","Epoch 30/30\n","Iteration 1152/3040\n","Loss gen 11.6215 (14.2200)\n","Loss dis 0.0445 (0.1590)\n","\n","Epoch 30/30\n","Iteration 1184/3040\n","Loss gen 12.4144 (14.2346)\n","Loss dis 0.1113 (0.1580)\n","\n","Epoch 30/30\n","Iteration 1216/3040\n","Loss gen 13.4565 (14.2339)\n","Loss dis 0.0485 (0.1586)\n","\n","Epoch 30/30\n","Iteration 1248/3040\n","Loss gen 14.3102 (14.2553)\n","Loss dis 0.0330 (0.1569)\n","\n","Epoch 30/30\n","Iteration 1280/3040\n","Loss gen 14.4713 (14.2667)\n","Loss dis 0.0422 (0.1566)\n","\n","Epoch 30/30\n","Iteration 1312/3040\n","Loss gen 15.7324 (14.2756)\n","Loss dis 0.0123 (0.1552)\n","\n","Epoch 30/30\n","Iteration 1344/3040\n","Loss gen 12.0151 (14.2704)\n","Loss dis 0.1359 (0.1550)\n","\n","Epoch 30/30\n","Iteration 1376/3040\n","Loss gen 13.3342 (14.2727)\n","Loss dis 0.1322 (0.1548)\n","\n","Epoch 30/30\n","Iteration 1408/3040\n","Loss gen 13.8641 (14.2799)\n","Loss dis 0.0758 (0.1550)\n","\n","Epoch 30/30\n","Iteration 1440/3040\n","Loss gen 19.3389 (14.2875)\n","Loss dis 0.0015 (0.1546)\n","\n","Epoch 30/30\n","Iteration 1472/3040\n","Loss gen 13.8626 (14.2976)\n","Loss dis 0.0064 (0.1551)\n","\n","Epoch 30/30\n","Iteration 1504/3040\n","Loss gen 15.0590 (14.2924)\n","Loss dis 0.1802 (0.1553)\n","\n","Epoch 30/30\n","Iteration 1536/3040\n","Loss gen 14.7250 (14.3166)\n","Loss dis 0.0104 (0.1544)\n","\n","Epoch 30/30\n","Iteration 1568/3040\n","Loss gen 16.2712 (14.3221)\n","Loss dis 0.0813 (0.1561)\n","\n","Epoch 30/30\n","Iteration 1600/3040\n","Loss gen 15.2932 (14.3394)\n","Loss dis 0.0010 (0.1556)\n","\n","Epoch 30/30\n","Iteration 1632/3040\n","Loss gen 18.4955 (14.3662)\n","Loss dis 1.2450 (0.1559)\n","\n","Epoch 30/30\n","Iteration 1664/3040\n","Loss gen 17.0731 (14.3723)\n","Loss dis 0.0004 (0.1537)\n","\n","Epoch 30/30\n","Iteration 1696/3040\n","Loss gen 15.1913 (14.3725)\n","Loss dis 0.6934 (0.1558)\n","\n","Epoch 30/30\n","Iteration 1728/3040\n","Loss gen 13.9523 (14.3553)\n","Loss dis 0.0212 (0.1568)\n","\n","Epoch 30/30\n","Iteration 1760/3040\n","Loss gen 16.5202 (14.3467)\n","Loss dis 0.3930 (0.1563)\n","\n","Epoch 30/30\n","Iteration 1792/3040\n","Loss gen 15.6024 (14.3507)\n","Loss dis 0.3930 (0.1571)\n","\n","Epoch 30/30\n","Iteration 1824/3040\n","Loss gen 13.3272 (14.3462)\n","Loss dis 0.3949 (0.1574)\n","\n","Epoch 30/30\n","Iteration 1856/3040\n","Loss gen 15.6612 (14.3419)\n","Loss dis 0.0105 (0.1576)\n","\n","Epoch 30/30\n","Iteration 1888/3040\n","Loss gen 12.3133 (14.3429)\n","Loss dis 0.0226 (0.1571)\n","\n","Epoch 30/30\n","Iteration 1920/3040\n","Loss gen 18.3312 (14.3451)\n","Loss dis 0.0006 (0.1557)\n","\n","Epoch 30/30\n","Iteration 1952/3040\n","Loss gen 13.7283 (14.3379)\n","Loss dis 0.2292 (0.1550)\n","\n","Epoch 30/30\n","Iteration 1984/3040\n","Loss gen 14.7413 (14.3288)\n","Loss dis 0.0306 (0.1543)\n","\n","Epoch 30/30\n","Iteration 2016/3040\n","Loss gen 11.0293 (14.3215)\n","Loss dis 0.3765 (0.1534)\n","\n","Epoch 30/30\n","Iteration 2048/3040\n","Loss gen 15.6741 (14.3086)\n","Loss dis 0.0428 (0.1524)\n","\n","Epoch 30/30\n","Iteration 2080/3040\n","Loss gen 12.7452 (14.2991)\n","Loss dis 0.0269 (0.1514)\n","\n","Epoch 30/30\n","Iteration 2112/3040\n","Loss gen 14.1170 (14.3058)\n","Loss dis 0.2800 (0.1510)\n","\n","Epoch 30/30\n","Iteration 2144/3040\n","Loss gen 13.8295 (14.2990)\n","Loss dis 0.0359 (0.1510)\n","\n","Epoch 30/30\n","Iteration 2176/3040\n","Loss gen 12.4253 (14.3025)\n","Loss dis 0.4944 (0.1514)\n","\n","Epoch 30/30\n","Iteration 2208/3040\n","Loss gen 14.3622 (14.3010)\n","Loss dis 0.0334 (0.1521)\n","\n","Epoch 30/30\n","Iteration 2240/3040\n","Loss gen 14.8015 (14.2998)\n","Loss dis 0.0345 (0.1517)\n","\n","Epoch 30/30\n","Iteration 2272/3040\n","Loss gen 12.9967 (14.3080)\n","Loss dis 0.0833 (0.1514)\n","\n","Epoch 30/30\n","Iteration 2304/3040\n","Loss gen 14.1554 (14.3188)\n","Loss dis 0.1805 (0.1506)\n","\n","Epoch 30/30\n","Iteration 2336/3040\n","Loss gen 9.9164 (14.3260)\n","Loss dis 0.2997 (0.1504)\n","\n","Epoch 30/30\n","Iteration 2368/3040\n","Loss gen 12.9725 (14.3232)\n","Loss dis 0.2320 (0.1508)\n","\n","Epoch 30/30\n","Iteration 2400/3040\n","Loss gen 13.7538 (14.3255)\n","Loss dis 0.0877 (0.1526)\n","\n","Epoch 30/30\n","Iteration 2432/3040\n","Loss gen 12.9814 (14.3271)\n","Loss dis 0.0454 (0.1532)\n","\n","Epoch 30/30\n","Iteration 2464/3040\n","Loss gen 14.8259 (14.3281)\n","Loss dis 0.0331 (0.1526)\n","\n","Epoch 30/30\n","Iteration 2496/3040\n","Loss gen 11.1297 (14.3369)\n","Loss dis 0.6157 (0.1531)\n","\n","Epoch 30/30\n","Iteration 2528/3040\n","Loss gen 13.3208 (14.3329)\n","Loss dis 0.0167 (0.1545)\n","\n","Epoch 30/30\n","Iteration 2560/3040\n","Loss gen 11.6175 (14.3403)\n","Loss dis 0.7528 (0.1547)\n","\n","Epoch 30/30\n","Iteration 2592/3040\n","Loss gen 13.3460 (14.3415)\n","Loss dis 0.3375 (0.1551)\n","\n","Epoch 30/30\n","Iteration 2624/3040\n","Loss gen 13.0262 (14.3386)\n","Loss dis 0.0498 (0.1551)\n","\n","Epoch 30/30\n","Iteration 2656/3040\n","Loss gen 12.6278 (14.3313)\n","Loss dis 0.0223 (0.1551)\n","\n","Epoch 30/30\n","Iteration 2688/3040\n","Loss gen 17.2774 (14.3336)\n","Loss dis 0.0530 (0.1542)\n","\n","Epoch 30/30\n","Iteration 2720/3040\n","Loss gen 11.2849 (14.3304)\n","Loss dis 0.0180 (0.1556)\n","\n","Epoch 30/30\n","Iteration 2752/3040\n","Loss gen 15.2138 (14.3249)\n","Loss dis 0.3959 (0.1560)\n","\n","Epoch 30/30\n","Iteration 2784/3040\n","Loss gen 13.9654 (14.3206)\n","Loss dis 0.0386 (0.1558)\n","\n","Epoch 30/30\n","Iteration 2816/3040\n","Loss gen 15.2790 (14.3218)\n","Loss dis 0.0404 (0.1549)\n","\n","Epoch 30/30\n","Iteration 2848/3040\n","Loss gen 18.0402 (14.3227)\n","Loss dis 0.0002 (0.1551)\n","\n","Epoch 30/30\n","Iteration 2880/3040\n","Loss gen 13.9535 (14.3337)\n","Loss dis 0.1495 (0.1552)\n","\n","Epoch 30/30\n","Iteration 2912/3040\n","Loss gen 15.2305 (14.3449)\n","Loss dis 0.0398 (0.1561)\n","\n","Epoch 30/30\n","Iteration 2944/3040\n","Loss gen 8.9644 (14.3357)\n","Loss dis 0.1080 (0.1579)\n","\n","Epoch 30/30\n","Iteration 2976/3040\n","Loss gen 15.0600 (14.3353)\n","Loss dis 0.0023 (0.1571)\n","\n","Epoch 30/30\n","Iteration 3008/3040\n","Loss gen 12.2557 (14.3344)\n","Loss dis 0.0529 (0.1567)\n","\n","Epoch 30/30\n","Iteration 3040/3040\n","Loss gen 19.4660 (14.3298)\n","Loss dis 0.0001 (0.1561)\n"]}],"source":["for e in range(EPOCHS):\n","    i = 0\n","    generator_loss_sum = 0\n","    generator_loss_count = 0\n","    discriminator_loss_sum = 0\n","    discriminator_loss_count = 0\n","    for data in data_loader:\n","        # Fetch image channels from data\n","        L = data['L'].to(device)\n","        ab = data['ab'].to(device)\n","\n","        # Train discriminator\n","        fake_color = generator(L)\n","        discriminator.train()\n","        for param in discriminator.parameters():\n","            param.requires_grad = True\n","        discriminator_optimizer.zero_grad()\n","        fake_image = torch.cat([L, fake_color], dim=1)\n","        fake_preds = discriminator(fake_image.detach())\n","        discriminator_loss_fake = loss_function(fake_preds, discriminator_true_output.expand_as(fake_preds))\n","        real_image = torch.cat([L, ab], dim=1)\n","        real_preds = discriminator(real_image)\n","        discriminator_loss_real = loss_function(real_preds, discriminator_false_output.expand_as(real_preds))\n","        discriminator_loss = (discriminator_loss_fake + discriminator_loss_real) * 0.5\n","        discriminator_loss.backward()\n","        discriminator_loss_sum += discriminator_loss.item() * L.size(0)\n","        discriminator_loss_count += L.size(0)\n","        discriminator_optimizer.step()\n","\n","        # Train Generator\n","        generator.train()\n","        for param in discriminator.parameters():\n","            param.requires_grad = False\n","        generator_optimizer.zero_grad()\n","        fake_image = torch.cat([L, fake_color], dim=1)\n","        fake_preds = discriminator(fake_image)\n","        generator_loss = loss_function(fake_preds, discriminator_false_output.expand_as(fake_preds))\n","        generator_l1_loss = l1_loss(fake_color, ab) * 100\n","        generator_loss = generator_loss + generator_l1_loss\n","        generator_loss.backward()\n","        generator_loss_sum += generator_loss.item() * L.size(0)\n","        generator_loss_count += L.size(0)\n","        generator_optimizer.step()\n","        \n","        # Print train state every 32 steps\n","        i += 1\n","        if i % 32 != 0:\n","          continue;\n","        print(f\"\\nEpoch {e+1}/{EPOCHS}\")\n","        print(f\"Iteration {i}/{len(data_loader)}\")\n","        # Log current loss and epoch avg loss\n","        print(f\"Loss gen {generator_loss.item():.4f} ({(generator_loss_sum / generator_loss_count):.4f})\")\n","        print(f\"Loss dis {discriminator_loss.item():.4f} ({(discriminator_loss_sum / discriminator_loss_count):.4f})\")\n","\n","    # Log losses\n","    writer.add_scalar(\"Loss/generator\", (generator_loss_sum / generator_loss_count), e)\n","    writer.add_scalar(\"Loss/discriminator\", (discriminator_loss_sum / discriminator_loss_count), e)\n","    writer.flush()"]},{"cell_type":"markdown","metadata":{"id":"u8T1RNt7UNQg"},"source":["# Save model"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":460,"status":"ok","timestamp":1673913446329,"user":{"displayName":"Leszek Ostek","userId":"01420718588842860711"},"user_tz":-60},"id":"14Jx2x7RUPVy"},"outputs":[],"source":["torch.save(generator.state_dict(), MODEL_SAVE_PATH + '/model.pt')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.8 (main, Nov  1 2022, 14:18:21) [GCC 12.2.0]"},"vscode":{"interpreter":{"hash":"93e15679645dcb3524ccf8395a06e39173268072ff243f8f4742438cd6969362"}}},"nbformat":4,"nbformat_minor":0}
